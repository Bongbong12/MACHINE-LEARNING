{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bongbong12/MACHINE-LEARNING/blob/main/MachineLearning_Sesi10_QLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v2Bw_wXXQKaf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyglet==1.5.1\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gym==0.24\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "\n",
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "id": "oYbPDSFYQhwd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twtBNh1WQ3EF",
        "outputId": "2a89d005-91ce-43bb-96b5-00863a28280b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_map = [\n",
        "    \"SFFF\",\n",
        "    \"FHFH\",\n",
        "    \"FFFH\",\n",
        "    \"HFFG\"\n",
        "]\n",
        "\n",
        "env = gym.make('FrozenLake-v1', desc=my_map, is_slippery=False)\n",
        "env.render()\n",
        "env.reset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-hUKLnhQ_pf",
        "outputId": "1ef9b942-eb54-47ad-cf91-7d0ac85a6877"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "print(f'action_space_size = {action_space_size}')\n",
        "print(f'state_space_size = {state_space_size}')\n",
        "print(f'q_table = \\n{q_table}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoAGkxOCUCej",
        "outputId": "a44d9daf-ec49-4335-be4d-c7fe122b973a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_space_size = 4\n",
            "state_space_size = 16\n",
            "q_table = \n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "num_episodes = 1000\n",
        "max_steps_per_episode = 100\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "\n",
        "exploration_rate =1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.05"
      ],
      "metadata": {
        "id": "ravyEYVNVXsq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_all_episodes = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "  state = env.reset()\n",
        "  state = 0\n",
        "  done = False\n",
        "  reward_current_episode = 0\n",
        "\n",
        "  for step in range(max_steps_per_episode):\n",
        "    exploration_rate_threshold = random.uniform(0, 1)\n",
        "    if exploration_rate_threshold > exploration_rate:\n",
        "      action = np.argmax(q_table[state, :])\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    delta_q = ( 1 - learning_rate)+  learning_rate*(reward + discount_rate*np.max(q_table[new_state, :]))\n",
        "\n",
        "    print(f\"We are on {episode} episode and {step} step\")\n",
        "    print(f\"Delta Q = {delta_q}\")\n",
        "    print(f\"Q_table[{state},{action}]_old = {q_table[state, action]}\")\n",
        "\n",
        "    q_table[state, action] = q_table[state, action]*(1 - learning_rate)+\\\n",
        "                            learning_rate*(reward+discount_rate*np.max(q_table[new_state, :]))\n",
        "    print(f\"Q_table[{state, action}]_new = {q_table[state, action]}\")\n",
        "    print(f\"We are on {state} state\")\n",
        "    state = new_state\n",
        "    print(f\"And now we are on {state} state\")\n",
        "    reward_current_episode+= reward\n",
        "    print(f\"We get {reward} reward \")\n",
        "    print(f\"exploration_rate = {exploration_rate}\\n\")\n",
        "\n",
        "    if done == True:\n",
        "        break\n",
        "\n",
        "exploration_rate = min_exploration_rate +\\\n",
        "                 (max_exploration_rate - min_exploration_rate)*np.exp(-exploration_decay_rate*episode)\n",
        "rewards_all_episodes.append(reward_current_episode)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nr48_17XqBk",
        "outputId": "d41805d4-372b-43ab-a556-8d9431eb82c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 3 step\n",
            "Delta Q = 0.93868109203979\n",
            "Q_table[0,1]_old = 0.38085903873061344\n",
            "Q_table[(0, 1)]_new = 0.38145422689734204\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 4 step\n",
            "Delta Q = 0.9377639684628369\n",
            "Q_table[4,3]_old = 0.3667295677975036\n",
            "Q_table[(4, 3)]_new = 0.3678205794805901\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 5 step\n",
            "Delta Q = 0.93868109203979\n",
            "Q_table[0,1]_old = 0.38145422689734204\n",
            "Q_table[(0, 1)]_new = 0.38198989624739776\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 6 step\n",
            "Delta Q = 0.93868109203979\n",
            "Q_table[4,0]_old = 0.37693154094651005\n",
            "Q_table[(4, 0)]_new = 0.37791947889164895\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 7 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[4,1]_old = 0.39071810141201957\n",
            "Q_table[(4, 1)]_new = 0.39164925689992325\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 8 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[8,0]_old = 0.37761177835693965\n",
            "Q_table[(8, 0)]_new = 0.3798535661503513\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 9 step\n",
            "Delta Q = 0.9387732764330924\n",
            "Q_table[8,3]_old = 0.3592148198772353\n",
            "Q_table[(8, 3)]_new = 0.3620666143226042\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 10 step\n",
            "Delta Q = 0.9378169997284924\n",
            "Q_table[4,3]_old = 0.3678205794805901\n",
            "Q_table[(4, 3)]_new = 0.3688555212610235\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 11 step\n",
            "Delta Q = 0.9387732764330924\n",
            "Q_table[0,1]_old = 0.38198989624739776\n",
            "Q_table[(0, 1)]_new = 0.3825641830557504\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 0 step\n",
            "Delta Q = 0.9378738541225193\n",
            "Q_table[0,3]_old = 0.37155607247024286\n",
            "Q_table[(0, 3)]_new = 0.3722743193457379\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 1 step\n",
            "Delta Q = 0.9378738541225193\n",
            "Q_table[0,3]_old = 0.3722743193457379\n",
            "Q_table[(0, 3)]_new = 0.37292074153368343\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 2 step\n",
            "Delta Q = 0.9387732764330924\n",
            "Q_table[0,1]_old = 0.3825641830557504\n",
            "Q_table[(0, 1)]_new = 0.3830810411832678\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 0 step\n",
            "Delta Q = 0.9368797435443874\n",
            "Q_table[0,2]_old = 0.36182859205834583\n",
            "Q_table[(0, 2)]_new = 0.3625254763968987\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 1 step\n",
            "Delta Q = 0.9379250230771435\n",
            "Q_table[1,0]_old = 0.36687882499335667\n",
            "Q_table[(1, 0)]_new = 0.36811596557116455\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 2 step\n",
            "Delta Q = 0.9379250230771435\n",
            "Q_table[0,0]_old = 0.37345618156707977\n",
            "Q_table[(0, 0)]_new = 0.37403558648751534\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 3 step\n",
            "Delta Q = 0.9379250230771435\n",
            "Q_table[0,3]_old = 0.37292074153368343\n",
            "Q_table[(0, 3)]_new = 0.3735536904574586\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 4 step\n",
            "Delta Q = 0.9379250230771435\n",
            "Q_table[0,0]_old = 0.37403558648751534\n",
            "Q_table[(0, 0)]_new = 0.37455705091590735\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 5 step\n",
            "Delta Q = 0.9379250230771435\n",
            "Q_table[0,0]_old = 0.37455705091590735\n",
            "Q_table[(0, 0)]_new = 0.3750263689014601\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 6 step\n",
            "Delta Q = 0.9368797435443874\n",
            "Q_table[0,2]_old = 0.3625254763968987\n",
            "Q_table[(0, 2)]_new = 0.3631526723015962\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 7 step\n",
            "Delta Q = 0.9379250230771435\n",
            "Q_table[1,0]_old = 0.36811596557116455\n",
            "Q_table[(1, 0)]_new = 0.3692293920911916\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 8 step\n",
            "Delta Q = 0.9379250230771435\n",
            "Q_table[0,3]_old = 0.3735536904574586\n",
            "Q_table[(0, 3)]_new = 0.37412334448885626\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 9 step\n",
            "Delta Q = 0.9387732764330924\n",
            "Q_table[0,1]_old = 0.3830810411832678\n",
            "Q_table[(0, 1)]_new = 0.3835462134980335\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 10 step\n",
            "Delta Q = 0.9379710751363053\n",
            "Q_table[4,3]_old = 0.3688555212610235\n",
            "Q_table[(4, 3)]_new = 0.3699410442712265\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 11 step\n",
            "Delta Q = 0.9379710751363053\n",
            "Q_table[0,3]_old = 0.37412334448885626\n",
            "Q_table[(0, 3)]_new = 0.37468208517627594\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 12 step\n",
            "Delta Q = 0.9379710751363053\n",
            "Q_table[0,0]_old = 0.3750263689014601\n",
            "Q_table[(0, 0)]_new = 0.37549480714761946\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 13 step\n",
            "Delta Q = 0.9379710751363053\n",
            "Q_table[0,3]_old = 0.37468208517627594\n",
            "Q_table[(0, 3)]_new = 0.37518495179495365\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 14 step\n",
            "Delta Q = 0.9368797435443874\n",
            "Q_table[0,2]_old = 0.3631526723015962\n",
            "Q_table[(0, 2)]_new = 0.36371714861582405\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 15 step\n",
            "Delta Q = 0.9387760361798266\n",
            "Q_table[1,2]_old = 0.37252266206451934\n",
            "Q_table[(1, 2)]_new = 0.374046432037894\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 16 step\n",
            "Delta Q = 0.9387760361798266\n",
            "Q_table[2,3]_old = 0.3523007544719892\n",
            "Q_table[(2, 3)]_new = 0.3558467152046169\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 17 step\n",
            "Delta Q = 0.9421502841065217\n",
            "Q_table[2,1]_old = 0.3916771331295618\n",
            "Q_table[(2, 1)]_new = 0.3946597039231273\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 18 step\n",
            "Delta Q = 0.9544343368514222\n",
            "Q_table[6,1]_old = 0.42576044552042075\n",
            "Q_table[(6, 1)]_new = 0.4376187378198009\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 19 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 0 step\n",
            "Delta Q = 0.9387732764330924\n",
            "Q_table[0,1]_old = 0.3835462134980335\n",
            "Q_table[(0, 1)]_new = 0.38396486858132256\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 0 step\n",
            "Delta Q = 0.9387732764330924\n",
            "Q_table[0,1]_old = 0.38396486858132256\n",
            "Q_table[(0, 1)]_new = 0.38434165815628274\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 1 step\n",
            "Delta Q = 0.9387732764330924\n",
            "Q_table[4,0]_old = 0.37791947889164895\n",
            "Q_table[(4, 0)]_new = 0.37890080743557647\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 2 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[4,1]_old = 0.39164925689992325\n",
            "Q_table[(4, 1)]_new = 0.39248729683903655\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 3 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[8,0]_old = 0.3798535661503513\n",
            "Q_table[(8, 0)]_new = 0.3818711751644218\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 4 step\n",
            "Delta Q = 0.9388562423870647\n",
            "Q_table[8,3]_old = 0.3620666143226042\n",
            "Q_table[(8, 3)]_new = 0.3647161952774084\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 5 step\n",
            "Delta Q = 0.938049824157472\n",
            "Q_table[4,3]_old = 0.3699410442712265\n",
            "Q_table[(4, 3)]_new = 0.37099676400157583\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 6 step\n",
            "Delta Q = 0.9370305967717515\n",
            "Q_table[0,2]_old = 0.36371714861582405\n",
            "Q_table[(0, 2)]_new = 0.36437603052599316\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 7 step\n",
            "Delta Q = 0.9370305967717515\n",
            "Q_table[1,3]_old = 0.35237788901890976\n",
            "Q_table[(1, 3)]_new = 0.35417069688877034\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 8 step\n",
            "Delta Q = 0.9370305967717515\n",
            "Q_table[1,3]_old = 0.35417069688877034\n",
            "Q_table[(1, 3)]_new = 0.35578422397164483\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 0 step\n",
            "Delta Q = 0.9370305967717515\n",
            "Q_table[0,2]_old = 0.36437603052599316\n",
            "Q_table[(0, 2)]_new = 0.3649690242451454\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 1 step\n",
            "Delta Q = 0.9390713106883897\n",
            "Q_table[1,2]_old = 0.374046432037894\n",
            "Q_table[(1, 2)]_new = 0.3757130995224942\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 2 step\n",
            "Delta Q = 0.9318958248137753\n",
            "Q_table[2,2]_old = 0.2620156783580256\n",
            "Q_table[(2, 2)]_new = 0.2677099353359983\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 3 step\n",
            "Delta Q = 0.9318958248137753\n",
            "Q_table[3,3]_old = 0.24921651375347403\n",
            "Q_table[(3, 3)]_new = 0.25619068719190186\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 4 step\n",
            "Delta Q = 0.9318958248137753\n",
            "Q_table[3,3]_old = 0.25619068719190186\n",
            "Q_table[(3, 3)]_new = 0.2624674432864869\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 5 step\n",
            "Delta Q = 0.9318958248137753\n",
            "Q_table[3,3]_old = 0.2624674432864869\n",
            "Q_table[(3, 3)]_new = 0.2681165237716135\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 6 step\n",
            "Delta Q = 0.9318958248137753\n",
            "Q_table[3,3]_old = 0.2681165237716135\n",
            "Q_table[(3, 3)]_new = 0.2732006962082274\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 7 step\n",
            "Delta Q = 0.9390713106883897\n",
            "Q_table[3,0]_old = 0.3221800486239923\n",
            "Q_table[(3, 0)]_new = 0.32903335444998266\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 8 step\n",
            "Delta Q = 0.9433242550441603\n",
            "Q_table[2,1]_old = 0.3946597039231273\n",
            "Q_table[(2, 1)]_new = 0.3985179885749749\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 0 step\n",
            "Delta Q = 0.938049824157472\n",
            "Q_table[0,3]_old = 0.37518495179495365\n",
            "Q_table[(0, 3)]_new = 0.3757162807729303\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 1 step\n",
            "Delta Q = 0.938049824157472\n",
            "Q_table[0,3]_old = 0.3757162807729303\n",
            "Q_table[(0, 3)]_new = 0.37619447685310925\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 2 step\n",
            "Delta Q = 0.938049824157472\n",
            "Q_table[0,0]_old = 0.37549480714761946\n",
            "Q_table[(0, 0)]_new = 0.3759951505903295\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 3 step\n",
            "Delta Q = 0.938049824157472\n",
            "Q_table[0,0]_old = 0.3759951505903295\n",
            "Q_table[(0, 0)]_new = 0.3764454596887686\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 4 step\n",
            "Delta Q = 0.9388562423870647\n",
            "Q_table[0,1]_old = 0.38434165815628274\n",
            "Q_table[(0, 1)]_new = 0.3847637347277191\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 0 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[0,2]_old = 0.3649690242451454\n",
            "Q_table[(0, 2)]_new = 0.3656677186733578\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 1 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[1,3]_old = 0.35578422397164483\n",
            "Q_table[(1, 3)]_new = 0.3574013984272073\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 2 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[1,3]_old = 0.3574013984272073\n",
            "Q_table[(1, 3)]_new = 0.3588568554372135\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 3 step\n",
            "Delta Q = 0.9380916097380442\n",
            "Q_table[1,0]_old = 0.3692293920911916\n",
            "Q_table[(1, 0)]_new = 0.37039806262011665\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 4 step\n",
            "Delta Q = 0.9388562423870647\n",
            "Q_table[0,1]_old = 0.3847637347277191\n",
            "Q_table[(0, 1)]_new = 0.38514360364201183\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 0 step\n",
            "Delta Q = 0.9381292167605592\n",
            "Q_table[0,3]_old = 0.37619447685310925\n",
            "Q_table[(0, 3)]_new = 0.37670424592835755\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 1 step\n",
            "Delta Q = 0.9381292167605592\n",
            "Q_table[0,3]_old = 0.37670424592835755\n",
            "Q_table[(0, 3)]_new = 0.377163038096081\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 2 step\n",
            "Delta Q = 0.9388562423870647\n",
            "Q_table[0,1]_old = 0.38514360364201183\n",
            "Q_table[(0, 1)]_new = 0.3854854856648753\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 3 step\n",
            "Delta Q = 0.9388562423870647\n",
            "Q_table[4,0]_old = 0.37890080743557647\n",
            "Q_table[(4, 0)]_new = 0.37986696907908346\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 0 step\n",
            "Delta Q = 0.9381630630808226\n",
            "Q_table[0,0]_old = 0.3764454596887686\n",
            "Q_table[(0, 0)]_new = 0.37696397680071436\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 1 step\n",
            "Delta Q = 0.9388562423870647\n",
            "Q_table[0,1]_old = 0.3854854856648753\n",
            "Q_table[(0, 1)]_new = 0.38579317948545233\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 2 step\n",
            "Delta Q = 0.9388562423870647\n",
            "Q_table[4,0]_old = 0.37986696907908346\n",
            "Q_table[(4, 0)]_new = 0.38073651455823976\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 3 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[4,1]_old = 0.39248729683903655\n",
            "Q_table[(4, 1)]_new = 0.3932415327842385\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 4 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[8,0]_old = 0.3818711751644218\n",
            "Q_table[(8, 0)]_new = 0.38368702327708526\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 0 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[0,2]_old = 0.3656677186733578\n",
            "Q_table[(0, 2)]_new = 0.366296543658749\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 0 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[0,2]_old = 0.366296543658749\n",
            "Q_table[(0, 2)]_new = 0.366862486145601\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 0 step\n",
            "Delta Q = 0.9381935247690598\n",
            "Q_table[0,0]_old = 0.37696397680071436\n",
            "Q_table[(0, 0)]_new = 0.3774611038897027\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 1 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[0,2]_old = 0.366862486145601\n",
            "Q_table[(0, 2)]_new = 0.36737183438376786\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 0 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[0,2]_old = 0.36737183438376786\n",
            "Q_table[(0, 2)]_new = 0.367830247798118\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 0 step\n",
            "Delta Q = 0.9381935247690598\n",
            "Q_table[0,0]_old = 0.3774611038897027\n",
            "Q_table[(0, 0)]_new = 0.37790851826979227\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 1 step\n",
            "Delta Q = 0.9389309117456397\n",
            "Q_table[0,1]_old = 0.38579317948545233\n",
            "Q_table[(0, 1)]_new = 0.3861447732825467\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 0 step\n",
            "Delta Q = 0.9389309117456397\n",
            "Q_table[0,1]_old = 0.3861447732825467\n",
            "Q_table[(0, 1)]_new = 0.38646120769993164\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 1 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[4,1]_old = 0.3932415327842385\n",
            "Q_table[(4, 1)]_new = 0.39392034513492025\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 2 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[8,0]_old = 0.38368702327708526\n",
            "Q_table[(8, 0)]_new = 0.38532128657848236\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 3 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[8,0]_old = 0.38532128657848236\n",
            "Q_table[(8, 0)]_new = 0.38679212354973974\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 4 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[8,0]_old = 0.38679212354973974\n",
            "Q_table[(8, 0)]_new = 0.3881158768238714\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 5 step\n",
            "Delta Q = 0.9389981141683571\n",
            "Q_table[8,3]_old = 0.3647161952774084\n",
            "Q_table[(8, 3)]_new = 0.36724268991802467\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 6 step\n",
            "Delta Q = 0.9382596595622933\n",
            "Q_table[4,3]_old = 0.37099676400157583\n",
            "Q_table[(4, 3)]_new = 0.37215674716371144\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 7 step\n",
            "Delta Q = 0.9389981141683571\n",
            "Q_table[0,1]_old = 0.38646120769993164\n",
            "Q_table[(0, 1)]_new = 0.38681320109829564\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 0 step\n",
            "Delta Q = 0.9382945069087313\n",
            "Q_table[0,3]_old = 0.377163038096081\n",
            "Q_table[(0, 3)]_new = 0.37774124119520414\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 1 step\n",
            "Delta Q = 0.9389981141683571\n",
            "Q_table[0,1]_old = 0.38681320109829564\n",
            "Q_table[(0, 1)]_new = 0.3871299951568232\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 0 step\n",
            "Delta Q = 0.9389981141683571\n",
            "Q_table[0,1]_old = 0.3871299951568232\n",
            "Q_table[(0, 1)]_new = 0.387415109809498\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 1 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[4,1]_old = 0.39392034513492025\n",
            "Q_table[(4, 1)]_new = 0.39453127625053386\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 0 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[0,2]_old = 0.367830247798118\n",
            "Q_table[(0, 2)]_new = 0.3682428198710332\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 1 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[1,3]_old = 0.3588568554372135\n",
            "Q_table[(1, 3)]_new = 0.3601667667462191\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 2 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[1,3]_old = 0.3601667667462191\n",
            "Q_table[(1, 3)]_new = 0.36134568692432417\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 3 step\n",
            "Delta Q = 0.9383540958711403\n",
            "Q_table[1,0]_old = 0.37039806262011665\n",
            "Q_table[(1, 0)]_new = 0.3717123522292453\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 4 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[0,2]_old = 0.3682428198710332\n",
            "Q_table[(0, 2)]_new = 0.36861413473665683\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 5 step\n",
            "Delta Q = 0.9383540958711403\n",
            "Q_table[1,0]_old = 0.3717123522292453\n",
            "Q_table[(1, 0)]_new = 0.3728952128774611\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 6 step\n",
            "Delta Q = 0.9390585963488028\n",
            "Q_table[0,1]_old = 0.387415109809498\n",
            "Q_table[(0, 1)]_new = 0.3877321951773511\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 7 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[4,1]_old = 0.39453127625053386\n",
            "Q_table[(4, 1)]_new = 0.3950811142545861\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 8 step\n",
            "Delta Q = 0.9400029656291056\n",
            "Q_table[8,0]_old = 0.3881158768238714\n",
            "Q_table[(8, 0)]_new = 0.38930725477058986\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 9 step\n",
            "Delta Q = 0.9436747028550309\n",
            "Q_table[8,2]_old = 0.4040703598899555\n",
            "Q_table[(8, 2)]_new = 0.40733802675599073\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 10 step\n",
            "Delta Q = 0.9403264646488431\n",
            "Q_table[9,0]_old = 0.31966786172819245\n",
            "Q_table[(9, 0)]_new = 0.3280275402042163\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 11 step\n",
            "Delta Q = 0.9436747028550309\n",
            "Q_table[8,2]_old = 0.40733802675599073\n",
            "Q_table[(8, 2)]_new = 0.41027892693542245\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 12 step\n",
            "Delta Q = 0.945762173647925\n",
            "Q_table[9,1]_old = 0.3380777470457945\n",
            "Q_table[(9, 1)]_new = 0.35003214598914\n",
            "We are on 9 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 13 step\n",
            "Delta Q = 0.9436747028550309\n",
            "Q_table[13,3]_old = 0.27218985003220936\n",
            "Q_table[(13, 3)]_new = 0.28864556788401924\n",
            "We are on 13 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 14 step\n",
            "Delta Q = 0.9544343368514222\n",
            "Q_table[9,2]_old = 0.4411586146972806\n",
            "Q_table[(9, 2)]_new = 0.45147709007897474\n",
            "We are on 9 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 15 step\n",
            "Delta Q = 0.9433242550441603\n",
            "Q_table[10,3]_old = 0.23121009207516988\n",
            "Q_table[(10, 3)]_new = 0.2514133379118132\n",
            "We are on 10 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 16 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 0 step\n",
            "Delta Q = 0.9383854873225578\n",
            "Q_table[0,0]_old = 0.37790851826979227\n",
            "Q_table[(0, 0)]_new = 0.3785031537653708\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 1 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[0,2]_old = 0.36861413473665683\n",
            "Q_table[(0, 2)]_new = 0.3689483181157181\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 0 step\n",
            "Delta Q = 0.9383854873225578\n",
            "Q_table[0,0]_old = 0.3785031537653708\n",
            "Q_table[(0, 0)]_new = 0.3790383257113915\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 1 step\n",
            "Delta Q = 0.9383854873225578\n",
            "Q_table[0,3]_old = 0.37774124119520414\n",
            "Q_table[(0, 3)]_new = 0.3783526043982415\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 2 step\n",
            "Delta Q = 0.9391130303112041\n",
            "Q_table[0,1]_old = 0.3877321951773511\n",
            "Q_table[(0, 1)]_new = 0.38807200597082003\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 3 step\n",
            "Delta Q = 0.9391130303112041\n",
            "Q_table[4,0]_old = 0.38073651455823976\n",
            "Q_table[(4, 0)]_new = 0.38177589341361984\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 4 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[4,1]_old = 0.3950811142545861\n",
            "Q_table[(4, 1)]_new = 0.3961906165957343\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 5 step\n",
            "Delta Q = 0.9392228710429777\n",
            "Q_table[8,3]_old = 0.36724268991802467\n",
            "Q_table[(8, 3)]_new = 0.3697412919691999\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 6 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[4,1]_old = 0.3961906165957343\n",
            "Q_table[(4, 1)]_new = 0.3971891687027677\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 7 step\n",
            "Delta Q = 0.9393217277015741\n",
            "Q_table[8,3]_old = 0.3697412919691999\n",
            "Q_table[(8, 3)]_new = 0.3720888904738539\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 0 step\n",
            "Delta Q = 0.9384191285911112\n",
            "Q_table[0,3]_old = 0.3783526043982415\n",
            "Q_table[(0, 3)]_new = 0.3789364725495285\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 1 step\n",
            "Delta Q = 0.9371955968527269\n",
            "Q_table[0,2]_old = 0.3689483181157181\n",
            "Q_table[(0, 2)]_new = 0.3692490831568732\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 2 step\n",
            "Delta Q = 0.9394532808689225\n",
            "Q_table[1,2]_old = 0.3757130995224942\n",
            "Q_table[(1, 2)]_new = 0.37759507043916735\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 3 step\n",
            "Delta Q = 0.9373819119734776\n",
            "Q_table[2,0]_old = 0.3430022764643196\n",
            "Q_table[(2, 0)]_new = 0.3460839607913652\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 4 step\n",
            "Delta Q = 0.9394532808689225\n",
            "Q_table[1,2]_old = 0.37759507043916735\n",
            "Q_table[(1, 2)]_new = 0.37928884426417314\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 5 step\n",
            "Delta Q = 0.9394532808689225\n",
            "Q_table[2,3]_old = 0.3558467152046169\n",
            "Q_table[(2, 3)]_new = 0.35971532455307775\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 6 step\n",
            "Delta Q = 0.9433242550441603\n",
            "Q_table[2,1]_old = 0.3985179885749749\n",
            "Q_table[(2, 1)]_new = 0.4019904447616377\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 0 step\n",
            "Delta Q = 0.9393217277015741\n",
            "Q_table[0,1]_old = 0.38807200597082003\n",
            "Q_table[(0, 1)]_new = 0.38858653307531205\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 1 step\n",
            "Delta Q = 0.9384700667744559\n",
            "Q_table[4,3]_old = 0.37215674716371144\n",
            "Q_table[(4, 3)]_new = 0.3734111392217962\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 2 step\n",
            "Delta Q = 0.9393217277015741\n",
            "Q_table[0,1]_old = 0.38858653307531205\n",
            "Q_table[(0, 1)]_new = 0.38904960746935485\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 3 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[4,1]_old = 0.3971891687027677\n",
            "Q_table[(4, 1)]_new = 0.39808786559909776\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 4 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[8,0]_old = 0.38930725477058986\n",
            "Q_table[(8, 0)]_new = 0.3909941430601377\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 5 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[8,0]_old = 0.3909941430601377\n",
            "Q_table[(8, 0)]_new = 0.39251234252073075\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 6 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[8,0]_old = 0.39251234252073075\n",
            "Q_table[(8, 0)]_new = 0.39387872203526453\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 7 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[8,0]_old = 0.39387872203526453\n",
            "Q_table[(8, 0)]_new = 0.3951084635983449\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 8 step\n",
            "Delta Q = 0.9394106986943107\n",
            "Q_table[8,3]_old = 0.3720888904738539\n",
            "Q_table[(8, 3)]_new = 0.3742907001207792\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 9 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[4,1]_old = 0.39808786559909776\n",
            "Q_table[(4, 1)]_new = 0.3988966928057948\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 0 step\n",
            "Delta Q = 0.9394907725877737\n",
            "Q_table[0,1]_old = 0.38904960746935485\n",
            "Q_table[(0, 1)]_new = 0.389635419310193\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 1 step\n",
            "Delta Q = 0.9394907725877737\n",
            "Q_table[4,0]_old = 0.38177589341361984\n",
            "Q_table[(4, 0)]_new = 0.38308907666003156\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 2 step\n",
            "Delta Q = 0.9385739065117091\n",
            "Q_table[4,3]_old = 0.3734111392217962\n",
            "Q_table[(4, 3)]_new = 0.3746439318113257\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 3 step\n",
            "Delta Q = 0.9394907725877737\n",
            "Q_table[0,1]_old = 0.389635419310193\n",
            "Q_table[(0, 1)]_new = 0.3901626499669474\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 4 step\n",
            "Delta Q = 0.9394907725877737\n",
            "Q_table[4,0]_old = 0.38308907666003156\n",
            "Q_table[(4, 0)]_new = 0.3842709415818021\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 5 step\n",
            "Delta Q = 0.9394907725877737\n",
            "Q_table[4,0]_old = 0.3842709415818021\n",
            "Q_table[(4, 0)]_new = 0.38533462001139557\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 6 step\n",
            "Delta Q = 0.9394907725877737\n",
            "Q_table[4,0]_old = 0.38533462001139557\n",
            "Q_table[(4, 0)]_new = 0.3862919305980297\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 7 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[4,1]_old = 0.3988966928057948\n",
            "Q_table[(4, 1)]_new = 0.3996246372918222\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 8 step\n",
            "Delta Q = 0.9395628390918904\n",
            "Q_table[8,3]_old = 0.3742907001207792\n",
            "Q_table[(8, 3)]_new = 0.3764244692005917\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 9 step\n",
            "Delta Q = 0.9395628390918904\n",
            "Q_table[4,0]_old = 0.3862919305980297\n",
            "Q_table[(4, 0)]_new = 0.38722557663011714\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 0 step\n",
            "Delta Q = 0.9375495955821531\n",
            "Q_table[0,2]_old = 0.3692490831568732\n",
            "Q_table[(0, 2)]_new = 0.3698737704233391\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 1 step\n",
            "Delta Q = 0.9386261023467278\n",
            "Q_table[1,0]_old = 0.3728952128774611\n",
            "Q_table[(1, 0)]_new = 0.3742317939364428\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 2 step\n",
            "Delta Q = 0.9375495955821531\n",
            "Q_table[0,2]_old = 0.3698737704233391\n",
            "Q_table[(0, 2)]_new = 0.3704359889631583\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 3 step\n",
            "Delta Q = 0.9397970540314021\n",
            "Q_table[1,2]_old = 0.37928884426417314\n",
            "Q_table[(1, 2)]_new = 0.381157013869158\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 4 step\n",
            "Delta Q = 0.9377345443730467\n",
            "Q_table[2,0]_old = 0.3460839607913652\n",
            "Q_table[(2, 0)]_new = 0.34921010908527533\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 5 step\n",
            "Delta Q = 0.9377345443730467\n",
            "Q_table[1,3]_old = 0.36134568692432417\n",
            "Q_table[(1, 3)]_new = 0.3629456626049384\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 6 step\n",
            "Delta Q = 0.9397970540314021\n",
            "Q_table[1,2]_old = 0.381157013869158\n",
            "Q_table[(1, 2)]_new = 0.38283836651364433\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 7 step\n",
            "Delta Q = 0.9379009982848509\n",
            "Q_table[2,0]_old = 0.34921010908527533\n",
            "Q_table[(2, 0)]_new = 0.3521900964615986\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 8 step\n",
            "Delta Q = 0.9397970540314021\n",
            "Q_table[1,2]_old = 0.38283836651364433\n",
            "Q_table[(1, 2)]_new = 0.38435158389368207\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 9 step\n",
            "Delta Q = 0.9380508068054746\n",
            "Q_table[2,0]_old = 0.3521900964615986\n",
            "Q_table[(2, 0)]_new = 0.35502189362091324\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 0 step\n",
            "Delta Q = 0.9380508068054746\n",
            "Q_table[0,2]_old = 0.3704359889631583\n",
            "Q_table[(0, 2)]_new = 0.371443196872317\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 1 step\n",
            "Delta Q = 0.9380508068054746\n",
            "Q_table[1,3]_old = 0.3629456626049384\n",
            "Q_table[(1, 3)]_new = 0.36470190314991907\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 2 step\n",
            "Delta Q = 0.9397970540314021\n",
            "Q_table[1,2]_old = 0.38435158389368207\n",
            "Q_table[(1, 2)]_new = 0.385713479535716\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 3 step\n",
            "Delta Q = 0.9381856344740359\n",
            "Q_table[2,0]_old = 0.35502189362091324\n",
            "Q_table[(2, 0)]_new = 0.3577053387328578\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 4 step\n",
            "Delta Q = 0.9386261023467278\n",
            "Q_table[1,0]_old = 0.3742317939364428\n",
            "Q_table[(1, 0)]_new = 0.37543471688952634\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 5 step\n",
            "Delta Q = 0.9381856344740359\n",
            "Q_table[0,2]_old = 0.371443196872317\n",
            "Q_table[(0, 2)]_new = 0.3724845116591212\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 6 step\n",
            "Delta Q = 0.9397970540314021\n",
            "Q_table[1,2]_old = 0.385713479535716\n",
            "Q_table[(1, 2)]_new = 0.38693918561354657\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 7 step\n",
            "Delta Q = 0.9383069793757411\n",
            "Q_table[2,0]_old = 0.3577053387328578\n",
            "Q_table[(2, 0)]_new = 0.36024178423531317\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 8 step\n",
            "Delta Q = 0.9386261023467278\n",
            "Q_table[1,0]_old = 0.37543471688952634\n",
            "Q_table[(1, 0)]_new = 0.37651734754730154\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 9 step\n",
            "Delta Q = 0.9386261023467278\n",
            "Q_table[0,3]_old = 0.3789364725495285\n",
            "Q_table[(0, 3)]_new = 0.37966892764130344\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 10 step\n",
            "Delta Q = 0.9395628390918904\n",
            "Q_table[0,1]_old = 0.3901626499669474\n",
            "Q_table[(0, 1)]_new = 0.39070922406214303\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 11 step\n",
            "Delta Q = 0.9386802131821522\n",
            "Q_table[4,3]_old = 0.3746439318113257\n",
            "Q_table[(4, 3)]_new = 0.3758597518123453\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 12 step\n",
            "Delta Q = 0.9383069793757411\n",
            "Q_table[0,2]_old = 0.3724845116591212\n",
            "Q_table[(0, 2)]_new = 0.3735430398689502\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 13 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 0 step\n",
            "Delta Q = 0.9386802131821522\n",
            "Q_table[0,3]_old = 0.37966892764130344\n",
            "Q_table[(0, 3)]_new = 0.38038224805932525\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 1 step\n",
            "Delta Q = 0.9395628390918904\n",
            "Q_table[0,1]_old = 0.39070922406214303\n",
            "Q_table[(0, 1)]_new = 0.39120114074781914\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 0 step\n",
            "Delta Q = 0.9395628390918904\n",
            "Q_table[0,1]_old = 0.39120114074781914\n",
            "Q_table[(0, 1)]_new = 0.39164386576492766\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 0 step\n",
            "Delta Q = 0.9387727427107279\n",
            "Q_table[0,0]_old = 0.3790383257113915\n",
            "Q_table[(0, 0)]_new = 0.3799072358509802\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 1 step\n",
            "Delta Q = 0.9387727427107279\n",
            "Q_table[0,3]_old = 0.38038224805932525\n",
            "Q_table[(0, 3)]_new = 0.3811167659641206\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 2 step\n",
            "Delta Q = 0.9383069793757411\n",
            "Q_table[0,2]_old = 0.3735430398689502\n",
            "Q_table[(0, 2)]_new = 0.37449571525779635\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 0 step\n",
            "Delta Q = 0.9387727427107279\n",
            "Q_table[0,3]_old = 0.3811167659641206\n",
            "Q_table[(0, 3)]_new = 0.38177783207843635\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 1 step\n",
            "Delta Q = 0.9395628390918904\n",
            "Q_table[0,1]_old = 0.39164386576492766\n",
            "Q_table[(0, 1)]_new = 0.3920423182803253\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 2 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[4,3]_old = 0.3758597518123453\n",
            "Q_table[(4, 3)]_new = 0.377085966140863\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 3 step\n",
            "Delta Q = 0.9383069793757411\n",
            "Q_table[0,2]_old = 0.37449571525779635\n",
            "Q_table[(0, 2)]_new = 0.37535312310775787\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 4 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[1,0]_old = 0.37651734754730154\n",
            "Q_table[(1, 0)]_new = 0.3776778023023236\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 5 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[0,3]_old = 0.38177783207843635\n",
            "Q_table[(0, 3)]_new = 0.3824122383803449\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 6 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[0,0]_old = 0.3799072358509802\n",
            "Q_table[(0, 0)]_new = 0.38072870177563434\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 7 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[0,0]_old = 0.38072870177563434\n",
            "Q_table[(0, 0)]_new = 0.3814680211078231\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 8 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[0,3]_old = 0.3824122383803449\n",
            "Q_table[(0, 3)]_new = 0.38298320405206265\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 9 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[0,0]_old = 0.3814680211078231\n",
            "Q_table[(0, 0)]_new = 0.382133408506793\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 10 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[0,0]_old = 0.382133408506793\n",
            "Q_table[(0, 0)]_new = 0.3827322571658659\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 11 step\n",
            "Delta Q = 0.9383069793757411\n",
            "Q_table[0,2]_old = 0.37535312310775787\n",
            "Q_table[(0, 2)]_new = 0.3761247901727232\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 12 step\n",
            "Delta Q = 0.9383069793757411\n",
            "Q_table[1,3]_old = 0.36470190314991907\n",
            "Q_table[(1, 3)]_new = 0.3665386922106683\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 13 step\n",
            "Delta Q = 0.9383069793757411\n",
            "Q_table[1,3]_old = 0.3665386922106683\n",
            "Q_table[(1, 3)]_new = 0.3681918023653426\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 14 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 0 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[0,3]_old = 0.38298320405206265\n",
            "Q_table[(0, 3)]_new = 0.38349707315660864\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 1 step\n",
            "Delta Q = 0.9383069793757411\n",
            "Q_table[0,2]_old = 0.3761247901727232\n",
            "Q_table[(0, 2)]_new = 0.376819290531192\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 2 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[1,0]_old = 0.3776778023023236\n",
            "Q_table[(1, 0)]_new = 0.3787222115818435\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 3 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[0,0]_old = 0.3827322571658659\n",
            "Q_table[(0, 0)]_new = 0.38327122095903154\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 4 step\n",
            "Delta Q = 0.9383069793757411\n",
            "Q_table[0,2]_old = 0.376819290531192\n",
            "Q_table[(0, 2)]_new = 0.37744434085381395\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 0 step\n",
            "Delta Q = 0.9388121895097522\n",
            "Q_table[0,3]_old = 0.38349707315660864\n",
            "Q_table[(0, 3)]_new = 0.38395955535070003\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 1 step\n",
            "Delta Q = 0.9395628390918904\n",
            "Q_table[0,1]_old = 0.3920423182803253\n",
            "Q_table[(0, 1)]_new = 0.3924009255441832\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 2 step\n",
            "Delta Q = 0.9395628390918904\n",
            "Q_table[4,0]_old = 0.38722557663011714\n",
            "Q_table[(4, 0)]_new = 0.38806585805899585\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 3 step\n",
            "Delta Q = 0.9395628390918904\n",
            "Q_table[4,0]_old = 0.38806585805899585\n",
            "Q_table[(4, 0)]_new = 0.3888221113449867\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 4 step\n",
            "Delta Q = 0.9395628390918904\n",
            "Q_table[4,0]_old = 0.3888221113449867\n",
            "Q_table[(4, 0)]_new = 0.38950273930237844\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 5 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[4,1]_old = 0.3996246372918222\n",
            "Q_table[(4, 1)]_new = 0.4002797873292468\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 0 step\n",
            "Delta Q = 0.9388476916288742\n",
            "Q_table[0,3]_old = 0.38395955535070003\n",
            "Q_table[(0, 3)]_new = 0.3844112914445042\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 1 step\n",
            "Delta Q = 0.9388476916288742\n",
            "Q_table[0,3]_old = 0.3844112914445042\n",
            "Q_table[(0, 3)]_new = 0.3848178539289279\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 2 step\n",
            "Delta Q = 0.9383069793757411\n",
            "Q_table[0,2]_old = 0.37744434085381395\n",
            "Q_table[(0, 2)]_new = 0.3780068861441737\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 3 step\n",
            "Delta Q = 0.9397970540314021\n",
            "Q_table[1,2]_old = 0.38693918561354657\n",
            "Q_table[(1, 2)]_new = 0.38804232108359404\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 4 step\n",
            "Delta Q = 0.9384161897872758\n",
            "Q_table[2,0]_old = 0.36024178423531317\n",
            "Q_table[(2, 0)]_new = 0.36263379559905773\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 5 step\n",
            "Delta Q = 0.9388476916288742\n",
            "Q_table[1,0]_old = 0.3787222115818435\n",
            "Q_table[(1, 0)]_new = 0.3796976820525333\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 6 step\n",
            "Delta Q = 0.9396276989455955\n",
            "Q_table[0,1]_old = 0.3924009255441832\n",
            "Q_table[(0, 1)]_new = 0.39278853193536034\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 0 step\n",
            "Delta Q = 0.9388860646616007\n",
            "Q_table[0,0]_old = 0.38327122095903154\n",
            "Q_table[(0, 0)]_new = 0.38383016352472904\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 1 step\n",
            "Delta Q = 0.9384161897872758\n",
            "Q_table[0,2]_old = 0.3780068861441737\n",
            "Q_table[(0, 2)]_new = 0.3786223873170321\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 2 step\n",
            "Delta Q = 0.9384161897872758\n",
            "Q_table[1,3]_old = 0.3681918023653426\n",
            "Q_table[(1, 3)]_new = 0.36978881191608415\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 3 step\n",
            "Delta Q = 0.9397970540314021\n",
            "Q_table[1,2]_old = 0.38804232108359404\n",
            "Q_table[(1, 2)]_new = 0.3890351430066368\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 4 step\n",
            "Delta Q = 0.9397970540314021\n",
            "Q_table[2,3]_old = 0.35971532455307775\n",
            "Q_table[(2, 3)]_new = 0.36354084612917215\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 5 step\n",
            "Delta Q = 0.9385144791576571\n",
            "Q_table[2,0]_old = 0.36263379559905773\n",
            "Q_table[(2, 0)]_new = 0.364884895196809\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 6 step\n",
            "Delta Q = 0.9388860646616007\n",
            "Q_table[1,0]_old = 0.3796976820525333\n",
            "Q_table[(1, 0)]_new = 0.3806139785088806\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 7 step\n",
            "Delta Q = 0.9385144791576571\n",
            "Q_table[0,2]_old = 0.3786223873170321\n",
            "Q_table[(0, 2)]_new = 0.379274627742986\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 8 step\n",
            "Delta Q = 0.9397970540314021\n",
            "Q_table[1,2]_old = 0.3890351430066368\n",
            "Q_table[(1, 2)]_new = 0.38992868273737524\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 9 step\n",
            "Delta Q = 0.9433242550441603\n",
            "Q_table[2,1]_old = 0.4019904447616377\n",
            "Q_table[(2, 1)]_new = 0.4051156553296342\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 0 step\n",
            "Delta Q = 0.9388860646616007\n",
            "Q_table[0,0]_old = 0.38383016352472904\n",
            "Q_table[(0, 0)]_new = 0.3843332118338568\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 1 step\n",
            "Delta Q = 0.9388860646616007\n",
            "Q_table[0,3]_old = 0.3848178539289279\n",
            "Q_table[(0, 3)]_new = 0.3852221331976358\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 2 step\n",
            "Delta Q = 0.9388860646616007\n",
            "Q_table[0,0]_old = 0.3843332118338568\n",
            "Q_table[(0, 0)]_new = 0.3847859553120718\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 3 step\n",
            "Delta Q = 0.9396276989455955\n",
            "Q_table[0,1]_old = 0.39278853193536034\n",
            "Q_table[(0, 1)]_new = 0.39313737768741974\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 4 step\n",
            "Delta Q = 0.9389206003910546\n",
            "Q_table[4,3]_old = 0.377085966140863\n",
            "Q_table[(4, 3)]_new = 0.37829796991783127\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 5 step\n",
            "Delta Q = 0.9386029395910002\n",
            "Q_table[0,2]_old = 0.379274627742986\n",
            "Q_table[(0, 2)]_new = 0.37995010455968753\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 6 step\n",
            "Delta Q = 0.9401064498776338\n",
            "Q_table[1,2]_old = 0.38992868273737524\n",
            "Q_table[(1, 2)]_new = 0.39104226434127154\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 7 step\n",
            "Delta Q = 0.9325743020905483\n",
            "Q_table[2,2]_old = 0.2677099353359983\n",
            "Q_table[(2, 2)]_new = 0.27351324389294673\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 8 step\n",
            "Delta Q = 0.9325743020905483\n",
            "Q_table[3,3]_old = 0.2732006962082274\n",
            "Q_table[(3, 3)]_new = 0.27845492867795296\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 9 step\n",
            "Delta Q = 0.9325743020905483\n",
            "Q_table[3,2]_old = 0.1940112354972592\n",
            "Q_table[(3, 2)]_new = 0.20718441403808158\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 0 step\n",
            "Delta Q = 0.9396276989455955\n",
            "Q_table[0,1]_old = 0.39313737768741974\n",
            "Q_table[(0, 1)]_new = 0.3934513388642732\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 1 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[4,1]_old = 0.4002797873292468\n",
            "Q_table[(4, 1)]_new = 0.40086942236292894\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 2 step\n",
            "Delta Q = 0.93968607281393\n",
            "Q_table[8,3]_old = 0.3764244692005917\n",
            "Q_table[(8, 3)]_new = 0.37846809509446255\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 3 step\n",
            "Delta Q = 0.93968607281393\n",
            "Q_table[4,0]_old = 0.38950273930237844\n",
            "Q_table[(4, 0)]_new = 0.39023853818607057\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 4 step\n",
            "Delta Q = 0.93968607281393\n",
            "Q_table[4,0]_old = 0.39023853818607057\n",
            "Q_table[(4, 0)]_new = 0.3909007571813935\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 5 step\n",
            "Delta Q = 0.93968607281393\n",
            "Q_table[4,0]_old = 0.3909007571813935\n",
            "Q_table[(4, 0)]_new = 0.3914967542771841\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 6 step\n",
            "Delta Q = 0.9389516825475631\n",
            "Q_table[4,3]_old = 0.37829796991783127\n",
            "Q_table[(4, 3)]_new = 0.3794198554736112\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 7 step\n",
            "Delta Q = 0.93968607281393\n",
            "Q_table[0,1]_old = 0.3934513388642732\n",
            "Q_table[(0, 1)]_new = 0.39379227779177584\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 8 step\n",
            "Delta Q = 0.9389854355013858\n",
            "Q_table[4,3]_old = 0.3794198554736112\n",
            "Q_table[(4, 3)]_new = 0.38046330542763585\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 9 step\n",
            "Delta Q = 0.9389854355013858\n",
            "Q_table[0,3]_old = 0.3852221331976358\n",
            "Q_table[(0, 3)]_new = 0.3856853553792581\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 10 step\n",
            "Delta Q = 0.9389854355013858\n",
            "Q_table[0,3]_old = 0.3856853553792581\n",
            "Q_table[(0, 3)]_new = 0.38610225534271814\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 11 step\n",
            "Delta Q = 0.9387131841697859\n",
            "Q_table[0,2]_old = 0.37995010455968753\n",
            "Q_table[(0, 2)]_new = 0.38066827827350463\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 12 step\n",
            "Delta Q = 0.9401064498776338\n",
            "Q_table[1,2]_old = 0.39104226434127154\n",
            "Q_table[(1, 2)]_new = 0.3920444877847782\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 13 step\n",
            "Delta Q = 0.9433242550441603\n",
            "Q_table[2,1]_old = 0.4051156553296342\n",
            "Q_table[(2, 1)]_new = 0.40792834484083107\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 14 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 0 step\n",
            "Delta Q = 0.9389854355013858\n",
            "Q_table[0,3]_old = 0.38610225534271814\n",
            "Q_table[(0, 3)]_new = 0.3864774653098322\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 1 step\n",
            "Delta Q = 0.9389854355013858\n",
            "Q_table[0,0]_old = 0.3847859553120718\n",
            "Q_table[(0, 0)]_new = 0.38529279528225047\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 2 step\n",
            "Delta Q = 0.93968607281393\n",
            "Q_table[0,1]_old = 0.39379227779177584\n",
            "Q_table[(0, 1)]_new = 0.39409912282652826\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 3 step\n",
            "Delta Q = 0.9406176137666069\n",
            "Q_table[4,1]_old = 0.40086942236292894\n",
            "Q_table[(4, 1)]_new = 0.4014000938932429\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 4 step\n",
            "Delta Q = 0.9446962319178185\n",
            "Q_table[8,2]_old = 0.41027892693542245\n",
            "Q_table[(8, 2)]_new = 0.41394726615969873\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 5 step\n",
            "Delta Q = 0.945762173647925\n",
            "Q_table[9,1]_old = 0.35003214598914\n",
            "Q_table[(9, 1)]_new = 0.36079110503815104\n",
            "We are on 9 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 6 step\n",
            "Delta Q = 0.945762173647925\n",
            "Q_table[13,1]_old = 0.22906931352944349\n",
            "Q_table[(13, 1)]_new = 0.25192455582442413\n",
            "We are on 13 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 7 step\n",
            "Delta Q = 0.971039475888381\n",
            "Q_table[13,2]_old = 0.4622441782618685\n",
            "Q_table[(13, 2)]_new = 0.4870592363240626\n",
            "We are on 13 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 8 step\n",
            "Delta Q = 0.9544343368514222\n",
            "Q_table[14,3]_old = 0.249691865416509\n",
            "Q_table[(14, 3)]_new = 0.27915701572628027\n",
            "We are on 14 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 9 step\n",
            "Delta Q = 0.971039475888381\n",
            "Q_table[10,1]_old = 0.5498417863780016\n",
            "Q_table[(10, 1)]_new = 0.5658970836285825\n",
            "We are on 10 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 10 step\n",
            "Delta Q = 0.971039475888381\n",
            "Q_table[14,1]_old = 0.39739228686804823\n",
            "Q_table[(14, 1)]_new = 0.42869253406962443\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 11 step\n",
            "Delta Q = 0.9560238112792296\n",
            "Q_table[14,3]_old = 0.27915701572628027\n",
            "Q_table[(14, 3)]_new = 0.3072651254328819\n",
            "We are on 14 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 0 step\n",
            "Delta Q = 0.9390158131598263\n",
            "Q_table[0,3]_old = 0.3864774653098322\n",
            "Q_table[(0, 3)]_new = 0.3868455319386753\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 1 step\n",
            "Delta Q = 0.9397386092954311\n",
            "Q_table[0,1]_old = 0.39409912282652826\n",
            "Q_table[(0, 1)]_new = 0.39442781983930647\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 2 step\n",
            "Delta Q = 0.9397386092954311\n",
            "Q_table[4,0]_old = 0.3914967542771841\n",
            "Q_table[(4, 0)]_new = 0.39208568814489675\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 0 step\n",
            "Delta Q = 0.9397386092954311\n",
            "Q_table[0,1]_old = 0.39442781983930647\n",
            "Q_table[(0, 1)]_new = 0.3947236471508069\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 1 step\n",
            "Delta Q = 0.9397386092954311\n",
            "Q_table[4,0]_old = 0.39208568814489675\n",
            "Q_table[(4, 0)]_new = 0.39261572862583816\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 2 step\n",
            "Delta Q = 0.9390776410679299\n",
            "Q_table[4,3]_old = 0.38046330542763585\n",
            "Q_table[(4, 3)]_new = 0.38149461595280215\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 3 step\n",
            "Delta Q = 0.9397386092954311\n",
            "Q_table[0,1]_old = 0.3947236471508069\n",
            "Q_table[(0, 1)]_new = 0.3949898917311572\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 4 step\n",
            "Delta Q = 0.9391039992813845\n",
            "Q_table[4,3]_old = 0.38149461595280215\n",
            "Q_table[(4, 3)]_new = 0.3824491536389065\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 5 step\n",
            "Delta Q = 0.9391039992813845\n",
            "Q_table[0,0]_old = 0.38529279528225047\n",
            "Q_table[(0, 0)]_new = 0.38586751503541\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 6 step\n",
            "Delta Q = 0.9388124042906931\n",
            "Q_table[0,2]_old = 0.38066827827350463\n",
            "Q_table[(0, 2)]_new = 0.38141385473684725\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 7 step\n",
            "Delta Q = 0.9391039992813845\n",
            "Q_table[1,0]_old = 0.3806139785088806\n",
            "Q_table[(1, 0)]_new = 0.3816565799393771\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 8 step\n",
            "Delta Q = 0.9391039992813845\n",
            "Q_table[0,3]_old = 0.3868455319386753\n",
            "Q_table[(0, 3)]_new = 0.38726497802619236\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 9 step\n",
            "Delta Q = 0.9391039992813845\n",
            "Q_table[0,3]_old = 0.38726497802619236\n",
            "Q_table[(0, 3)]_new = 0.3876424795049577\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 10 step\n",
            "Delta Q = 0.9391039992813845\n",
            "Q_table[0,0]_old = 0.38586751503541\n",
            "Q_table[(0, 0)]_new = 0.38638476281325357\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 11 step\n",
            "Delta Q = 0.9391039992813845\n",
            "Q_table[0,3]_old = 0.3876424795049577\n",
            "Q_table[(0, 3)]_new = 0.38798223083584654\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 12 step\n",
            "Delta Q = 0.9391039992813845\n",
            "Q_table[0,0]_old = 0.38638476281325357\n",
            "Q_table[(0, 0)]_new = 0.3868502858133128\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 13 step\n",
            "Delta Q = 0.9388124042906931\n",
            "Q_table[0,2]_old = 0.38141385473684725\n",
            "Q_table[(0, 2)]_new = 0.38208487355385556\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 14 step\n",
            "Delta Q = 0.9391039992813845\n",
            "Q_table[1,0]_old = 0.3816565799393771\n",
            "Q_table[(1, 0)]_new = 0.382594921226824\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 15 step\n",
            "Delta Q = 0.9397386092954311\n",
            "Q_table[0,1]_old = 0.3949898917311572\n",
            "Q_table[(0, 1)]_new = 0.39522951185347255\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 16 step\n",
            "Delta Q = 0.9397386092954311\n",
            "Q_table[4,0]_old = 0.39261572862583816\n",
            "Q_table[(4, 0)]_new = 0.3930927650586854\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 17 step\n",
            "Delta Q = 0.9391277216734938\n",
            "Q_table[4,3]_old = 0.3824491536389065\n",
            "Q_table[(4, 3)]_new = 0.38333195994850966\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 18 step\n",
            "Delta Q = 0.9388124042906931\n",
            "Q_table[0,2]_old = 0.38208487355385556\n",
            "Q_table[(0, 2)]_new = 0.38268879048916304\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 19 step\n",
            "Delta Q = 0.9403849061392423\n",
            "Q_table[1,2]_old = 0.3920444877847782\n",
            "Q_table[(1, 2)]_new = 0.3932249451455427\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 20 step\n",
            "Delta Q = 0.9389292695694087\n",
            "Q_table[2,0]_old = 0.364884895196809\n",
            "Q_table[(2, 0)]_new = 0.36732567524653686\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 21 step\n",
            "Delta Q = 0.9391277216734938\n",
            "Q_table[1,0]_old = 0.382594921226824\n",
            "Q_table[(1, 0)]_new = 0.3834631507776354\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 22 step\n",
            "Delta Q = 0.9389292695694087\n",
            "Q_table[0,2]_old = 0.38268879048916304\n",
            "Q_table[(0, 2)]_new = 0.3833491810096555\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 23 step\n",
            "Delta Q = 0.9389292695694087\n",
            "Q_table[1,3]_old = 0.36978881191608415\n",
            "Q_table[(1, 3)]_new = 0.37173920029388446\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 24 step\n",
            "Delta Q = 0.9389292695694087\n",
            "Q_table[1,3]_old = 0.37173920029388446\n",
            "Q_table[(1, 3)]_new = 0.37349454983390473\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 25 step\n",
            "Delta Q = 0.9403849061392423\n",
            "Q_table[1,2]_old = 0.3932249451455427\n",
            "Q_table[(1, 2)]_new = 0.3942873567702307\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 26 step\n",
            "Delta Q = 0.9403849061392423\n",
            "Q_table[2,3]_old = 0.36354084612917215\n",
            "Q_table[(2, 3)]_new = 0.3675716676554972\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 27 step\n",
            "Delta Q = 0.9433242550441603\n",
            "Q_table[2,1]_old = 0.40792834484083107\n",
            "Q_table[(2, 1)]_new = 0.4104597654009082\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 28 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 0 step\n",
            "Delta Q = 0.9391277216734938\n",
            "Q_table[0,0]_old = 0.3868502858133128\n",
            "Q_table[(0, 0)]_new = 0.3872929789054753\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 1 step\n",
            "Delta Q = 0.9391277216734938\n",
            "Q_table[0,0]_old = 0.3872929789054753\n",
            "Q_table[(0, 0)]_new = 0.38769140268842156\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 2 step\n",
            "Delta Q = 0.9391277216734938\n",
            "Q_table[0,0]_old = 0.38769140268842156\n",
            "Q_table[(0, 0)]_new = 0.3880499840930732\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 3 step\n",
            "Delta Q = 0.9390344483202528\n",
            "Q_table[0,2]_old = 0.3833491810096555\n",
            "Q_table[(0, 2)]_new = 0.38404871122894274\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 4 step\n",
            "Delta Q = 0.9406355167746899\n",
            "Q_table[1,2]_old = 0.3942873567702307\n",
            "Q_table[(1, 2)]_new = 0.39549413786789755\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 5 step\n",
            "Delta Q = 0.9406355167746899\n",
            "Q_table[2,3]_old = 0.3675716676554972\n",
            "Q_table[(2, 3)]_new = 0.3714500176646374\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 6 step\n",
            "Delta Q = 0.9433242550441603\n",
            "Q_table[2,1]_old = 0.4104597654009082\n",
            "Q_table[(2, 1)]_new = 0.4127380439049777\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 0 step\n",
            "Delta Q = 0.9391277216734938\n",
            "Q_table[0,0]_old = 0.3880499840930732\n",
            "Q_table[(0, 0)]_new = 0.38837270735725965\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 1 step\n",
            "Delta Q = 0.9391277216734938\n",
            "Q_table[0,3]_old = 0.38798223083584654\n",
            "Q_table[(0, 3)]_new = 0.38831172942575565\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 2 step\n",
            "Delta Q = 0.9391277216734938\n",
            "Q_table[0,0]_old = 0.38837270735725965\n",
            "Q_table[(0, 0)]_new = 0.38866315829502746\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 3 step\n",
            "Delta Q = 0.9391539196489219\n",
            "Q_table[0,2]_old = 0.38404871122894274\n",
            "Q_table[(0, 2)]_new = 0.3847977597549703\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 0 step\n",
            "Delta Q = 0.9391277216734938\n",
            "Q_table[0,0]_old = 0.38866315829502746\n",
            "Q_table[(0, 0)]_new = 0.3889245641390185\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 1 step\n",
            "Delta Q = 0.9391539196489219\n",
            "Q_table[0,2]_old = 0.3847977597549703\n",
            "Q_table[(0, 2)]_new = 0.38547190342839516\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 0 step\n",
            "Delta Q = 0.9391539196489219\n",
            "Q_table[0,2]_old = 0.38547190342839516\n",
            "Q_table[(0, 2)]_new = 0.3860786327344775\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 1 step\n",
            "Delta Q = 0.9408610663465928\n",
            "Q_table[1,2]_old = 0.39549413786789755\n",
            "Q_table[(1, 2)]_new = 0.39680579042770064\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 2 step\n",
            "Delta Q = 0.9433242550441603\n",
            "Q_table[2,1]_old = 0.4127380439049777\n",
            "Q_table[(2, 1)]_new = 0.4147884945586402\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 3 step\n",
            "Delta Q = 0.9560238112792296\n",
            "Q_table[6,1]_old = 0.4376187378198009\n",
            "Q_table[(6, 1)]_new = 0.44988067531705045\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 0 step\n",
            "Delta Q = 0.9391277216734938\n",
            "Q_table[0,3]_old = 0.38831172942575565\n",
            "Q_table[(0, 3)]_new = 0.38860827815667387\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 1 step\n",
            "Delta Q = 0.9391277216734938\n",
            "Q_table[0,3]_old = 0.38860827815667387\n",
            "Q_table[(0, 3)]_new = 0.3888751720145003\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 2 step\n",
            "Delta Q = 0.9397386092954311\n",
            "Q_table[0,1]_old = 0.39522951185347255\n",
            "Q_table[(0, 1)]_new = 0.39544516996355633\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 3 step\n",
            "Delta Q = 0.9397386092954311\n",
            "Q_table[4,0]_old = 0.3930927650586854\n",
            "Q_table[(4, 0)]_new = 0.39352209784824793\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 4 step\n",
            "Delta Q = 0.9409807793498102\n",
            "Q_table[4,1]_old = 0.4014000938932429\n",
            "Q_table[(4, 1)]_new = 0.4022408638537288\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 0 step\n",
            "Delta Q = 0.9398218455215192\n",
            "Q_table[0,1]_old = 0.39544516996355633\n",
            "Q_table[(0, 1)]_new = 0.3957224984887199\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 1 step\n",
            "Delta Q = 0.9409807793498102\n",
            "Q_table[4,1]_old = 0.4022408638537288\n",
            "Q_table[(4, 1)]_new = 0.40299755681816607\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 2 step\n",
            "Delta Q = 0.9446962319178185\n",
            "Q_table[8,2]_old = 0.41394726615969873\n",
            "Q_table[(8, 2)]_new = 0.4172487714615474\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[9,3]_old = 0.0\n",
            "Q_table[(9, 3)]_new = 0.0\n",
            "We are on 9 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 0 step\n",
            "Delta Q = 0.9392837732523424\n",
            "Q_table[0,2]_old = 0.3860786327344775\n",
            "Q_table[(0, 2)]_new = 0.3867545427133722\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 1 step\n",
            "Delta Q = 0.9392837732523424\n",
            "Q_table[1,3]_old = 0.37349454983390473\n",
            "Q_table[(1, 3)]_new = 0.3754288681028566\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 2 step\n",
            "Delta Q = 0.9410640609613055\n",
            "Q_table[1,2]_old = 0.39680579042770064\n",
            "Q_table[(1, 2)]_new = 0.39818927234623597\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 3 step\n",
            "Delta Q = 0.9410640609613055\n",
            "Q_table[2,3]_old = 0.3714500176646374\n",
            "Q_table[(2, 3)]_new = 0.37536907685947907\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 4 step\n",
            "Delta Q = 0.9410640609613055\n",
            "Q_table[2,3]_old = 0.37536907685947907\n",
            "Q_table[(2, 3)]_new = 0.37889623013483653\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 5 step\n",
            "Delta Q = 0.9325743020905483\n",
            "Q_table[2,2]_old = 0.27351324389294673\n",
            "Q_table[(2, 2)]_new = 0.27873622159420036\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 6 step\n",
            "Delta Q = 0.9325743020905483\n",
            "Q_table[3,2]_old = 0.20718441403808158\n",
            "Q_table[(3, 2)]_new = 0.2190402747248217\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 7 step\n",
            "Delta Q = 0.9410640609613055\n",
            "Q_table[3,0]_old = 0.32903335444998266\n",
            "Q_table[(3, 0)]_new = 0.3371940799662898\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 8 step\n",
            "Delta Q = 0.9410640609613055\n",
            "Q_table[2,3]_old = 0.37889623013483653\n",
            "Q_table[(2, 3)]_new = 0.38207066808265827\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 9 step\n",
            "Delta Q = 0.9394207379622774\n",
            "Q_table[2,0]_old = 0.36732567524653686\n",
            "Q_table[(2, 0)]_new = 0.3700138456841605\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 10 step\n",
            "Delta Q = 0.9391765273503833\n",
            "Q_table[1,0]_old = 0.3834631507776354\n",
            "Q_table[(1, 0)]_new = 0.3842933630502551\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 11 step\n",
            "Delta Q = 0.9398967581249985\n",
            "Q_table[0,1]_old = 0.3957224984887199\n",
            "Q_table[(0, 1)]_new = 0.39604700676484633\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 12 step\n",
            "Delta Q = 0.9392086536697198\n",
            "Q_table[4,3]_old = 0.38333195994850966\n",
            "Q_table[(4, 3)]_new = 0.3842074176233785\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 13 step\n",
            "Delta Q = 0.9392086536697198\n",
            "Q_table[0,3]_old = 0.3888751720145003\n",
            "Q_table[(0, 3)]_new = 0.3891963084827701\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 14 step\n",
            "Delta Q = 0.9392086536697198\n",
            "Q_table[0,3]_old = 0.3891963084827701\n",
            "Q_table[(0, 3)]_new = 0.3894853313042129\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 15 step\n",
            "Delta Q = 0.9398967581249985\n",
            "Q_table[0,1]_old = 0.39604700676484633\n",
            "Q_table[(0, 1)]_new = 0.3963390642133601\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 16 step\n",
            "Delta Q = 0.9398967581249985\n",
            "Q_table[4,0]_old = 0.39352209784824793\n",
            "Q_table[(4, 0)]_new = 0.3940666461884216\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 17 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 0 step\n",
            "Delta Q = 0.9394207379622774\n",
            "Q_table[0,2]_old = 0.3867545427133722\n",
            "Q_table[(0, 2)]_new = 0.3874998264043123\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 1 step\n",
            "Delta Q = 0.9394207379622774\n",
            "Q_table[1,3]_old = 0.3754288681028566\n",
            "Q_table[(1, 3)]_new = 0.37730671925484827\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 2 step\n",
            "Delta Q = 0.9392375673571227\n",
            "Q_table[1,0]_old = 0.3842933630502551\n",
            "Q_table[(1, 0)]_new = 0.38510159410235223\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 3 step\n",
            "Delta Q = 0.9392375673571227\n",
            "Q_table[0,0]_old = 0.3889245641390185\n",
            "Q_table[(0, 0)]_new = 0.3892696750822393\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 4 step\n",
            "Delta Q = 0.9394207379622774\n",
            "Q_table[0,2]_old = 0.3874998264043123\n",
            "Q_table[(0, 2)]_new = 0.3881705817261584\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 5 step\n",
            "Delta Q = 0.9394207379622774\n",
            "Q_table[1,3]_old = 0.37730671925484827\n",
            "Q_table[(1, 3)]_new = 0.3789967852916408\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 6 step\n",
            "Delta Q = 0.9392375673571227\n",
            "Q_table[1,0]_old = 0.38510159410235223\n",
            "Q_table[(1, 0)]_new = 0.38582900204923964\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 7 step\n",
            "Delta Q = 0.9392375673571227\n",
            "Q_table[0,0]_old = 0.3892696750822393\n",
            "Q_table[(0, 0)]_new = 0.389580274931138\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 8 step\n",
            "Delta Q = 0.9394207379622774\n",
            "Q_table[0,2]_old = 0.3881705817261584\n",
            "Q_table[(0, 2)]_new = 0.38877426151581995\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 9 step\n",
            "Delta Q = 0.9392375673571227\n",
            "Q_table[1,0]_old = 0.38582900204923964\n",
            "Q_table[(1, 0)]_new = 0.38648366920143834\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 10 step\n",
            "Delta Q = 0.9398967581249985\n",
            "Q_table[0,1]_old = 0.3963390642133601\n",
            "Q_table[(0, 1)]_new = 0.39660191591702254\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 11 step\n",
            "Delta Q = 0.9398967581249985\n",
            "Q_table[4,0]_old = 0.3940666461884216\n",
            "Q_table[(4, 0)]_new = 0.3945567396945779\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 0 step\n",
            "Delta Q = 0.9392635896757853\n",
            "Q_table[0,0]_old = 0.389580274931138\n",
            "Q_table[(0, 0)]_new = 0.3898858371138095\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 1 step\n",
            "Delta Q = 0.9392635896757853\n",
            "Q_table[0,0]_old = 0.3898858371138095\n",
            "Q_table[(0, 0)]_new = 0.3901608430782138\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 2 step\n",
            "Delta Q = 0.9392635896757853\n",
            "Q_table[0,0]_old = 0.3901608430782138\n",
            "Q_table[(0, 0)]_new = 0.39040834844617767\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 3 step\n",
            "Delta Q = 0.9392635896757853\n",
            "Q_table[0,3]_old = 0.3894853313042129\n",
            "Q_table[(0, 3)]_new = 0.3898003878495769\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 4 step\n",
            "Delta Q = 0.9392635896757853\n",
            "Q_table[0,0]_old = 0.39040834844617767\n",
            "Q_table[(0, 0)]_new = 0.3906311032773452\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 5 step\n",
            "Delta Q = 0.9392635896757853\n",
            "Q_table[0,3]_old = 0.3898003878495769\n",
            "Q_table[(0, 3)]_new = 0.3900839387404044\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 6 step\n",
            "Delta Q = 0.9392635896757853\n",
            "Q_table[0,0]_old = 0.3906311032773452\n",
            "Q_table[(0, 0)]_new = 0.3908315826253959\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 7 step\n",
            "Delta Q = 0.9392635896757853\n",
            "Q_table[0,0]_old = 0.3908315826253959\n",
            "Q_table[(0, 0)]_new = 0.39101201403864155\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 8 step\n",
            "Delta Q = 0.9398967581249985\n",
            "Q_table[0,1]_old = 0.39660191591702254\n",
            "Q_table[(0, 1)]_new = 0.3968384824503187\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 0 step\n",
            "Delta Q = 0.9392870097625816\n",
            "Q_table[0,0]_old = 0.39101201403864155\n",
            "Q_table[(0, 0)]_new = 0.39119782239735895\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 1 step\n",
            "Delta Q = 0.9392870097625816\n",
            "Q_table[0,3]_old = 0.3900839387404044\n",
            "Q_table[(0, 3)]_new = 0.39036255462894554\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 2 step\n",
            "Delta Q = 0.9394207379622774\n",
            "Q_table[0,2]_old = 0.38877426151581995\n",
            "Q_table[(0, 2)]_new = 0.38931757332651534\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 3 step\n",
            "Delta Q = 0.9392870097625816\n",
            "Q_table[1,0]_old = 0.38648366920143834\n",
            "Q_table[(1, 0)]_new = 0.38712231204387604\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 4 step\n",
            "Delta Q = 0.9392870097625816\n",
            "Q_table[0,3]_old = 0.39036255462894554\n",
            "Q_table[(0, 3)]_new = 0.39061330892863255\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 5 step\n",
            "Delta Q = 0.9392870097625816\n",
            "Q_table[0,0]_old = 0.39119782239735895\n",
            "Q_table[(0, 0)]_new = 0.3913650499202046\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 6 step\n",
            "Delta Q = 0.9392870097625816\n",
            "Q_table[0,3]_old = 0.39061330892863255\n",
            "Q_table[(0, 3)]_new = 0.39083898779835086\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 7 step\n",
            "Delta Q = 0.9392870097625816\n",
            "Q_table[0,3]_old = 0.39083898779835086\n",
            "Q_table[(0, 3)]_new = 0.3910420987810973\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 8 step\n",
            "Delta Q = 0.9392870097625816\n",
            "Q_table[0,3]_old = 0.3910420987810973\n",
            "Q_table[(0, 3)]_new = 0.39122489866556914\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 9 step\n",
            "Delta Q = 0.9392870097625816\n",
            "Q_table[0,0]_old = 0.3913650499202046\n",
            "Q_table[(0, 0)]_new = 0.3915155546907657\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 10 step\n",
            "Delta Q = 0.9398967581249985\n",
            "Q_table[0,1]_old = 0.3968384824503187\n",
            "Q_table[(0, 1)]_new = 0.3970513923302853\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 11 step\n",
            "Delta Q = 0.9393080878406983\n",
            "Q_table[4,3]_old = 0.3842074176233785\n",
            "Q_table[(4, 3)]_new = 0.3850947637017389\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 12 step\n",
            "Delta Q = 0.9398967581249985\n",
            "Q_table[0,1]_old = 0.3970513923302853\n",
            "Q_table[(0, 1)]_new = 0.3972430112222552\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 13 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 0 step\n",
            "Delta Q = 0.9394207379622774\n",
            "Q_table[0,2]_old = 0.38931757332651534\n",
            "Q_table[(0, 2)]_new = 0.38980655395614117\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 1 step\n",
            "Delta Q = 0.9410640609613055\n",
            "Q_table[1,2]_old = 0.39818927234623597\n",
            "Q_table[(1, 2)]_new = 0.39943440607291775\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 2 step\n",
            "Delta Q = 0.9410640609613055\n",
            "Q_table[2,3]_old = 0.38207066808265827\n",
            "Q_table[(2, 3)]_new = 0.38492766223569785\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 3 step\n",
            "Delta Q = 0.944538186856388\n",
            "Q_table[2,1]_old = 0.4147884945586402\n",
            "Q_table[(2, 1)]_new = 0.4178478319591642\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 4 step\n",
            "Delta Q = 0.9413669353639573\n",
            "Q_table[6,3]_old = 0.29046873035861265\n",
            "Q_table[(6, 3)]_new = 0.30278879268670866\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 5 step\n",
            "Delta Q = 0.944538186856388\n",
            "Q_table[2,1]_old = 0.4178478319591642\n",
            "Q_table[(2, 1)]_new = 0.4206012356196358\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 6 step\n",
            "Delta Q = 0.941639522326344\n",
            "Q_table[6,3]_old = 0.30278879268670866\n",
            "Q_table[(6, 3)]_new = 0.31414943574438176\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 7 step\n",
            "Delta Q = 0.941639522326344\n",
            "Q_table[2,3]_old = 0.38492766223569785\n",
            "Q_table[(2, 3)]_new = 0.388074418338472\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 8 step\n",
            "Delta Q = 0.9395440062012189\n",
            "Q_table[2,0]_old = 0.3700138456841605\n",
            "Q_table[(2, 0)]_new = 0.3725564673169633\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 9 step\n",
            "Delta Q = 0.9393270581110033\n",
            "Q_table[1,0]_old = 0.38712231204387604\n",
            "Q_table[(1, 0)]_new = 0.3877371389504917\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 10 step\n",
            "Delta Q = 0.9393270581110033\n",
            "Q_table[0,3]_old = 0.39122489866556914\n",
            "Q_table[(0, 3)]_new = 0.3914294669100155\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 11 step\n",
            "Delta Q = 0.9393270581110033\n",
            "Q_table[0,3]_old = 0.3914294669100155\n",
            "Q_table[(0, 3)]_new = 0.39161357833001725\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 12 step\n",
            "Delta Q = 0.9393270581110033\n",
            "Q_table[0,0]_old = 0.3915155546907657\n",
            "Q_table[(0, 0)]_new = 0.39169105733269244\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 13 step\n",
            "Delta Q = 0.9393270581110033\n",
            "Q_table[0,3]_old = 0.39161357833001725\n",
            "Q_table[(0, 3)]_new = 0.3917792786080188\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 14 step\n",
            "Delta Q = 0.9395440062012189\n",
            "Q_table[0,2]_old = 0.38980655395614117\n",
            "Q_table[(0, 2)]_new = 0.3903699047617459\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 15 step\n",
            "Delta Q = 0.9393270581110033\n",
            "Q_table[1,0]_old = 0.3877371389504917\n",
            "Q_table[(1, 0)]_new = 0.3882904831664458\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 16 step\n",
            "Delta Q = 0.9398967581249985\n",
            "Q_table[0,1]_old = 0.3972430112222552\n",
            "Q_table[(0, 1)]_new = 0.3974154682250281\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 17 step\n",
            "Delta Q = 0.9413076283746932\n",
            "Q_table[4,1]_old = 0.40299755681816607\n",
            "Q_table[(4, 1)]_new = 0.4040054295110427\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 18 step\n",
            "Delta Q = 0.9399965375215933\n",
            "Q_table[8,3]_old = 0.37846809509446255\n",
            "Q_table[(8, 3)]_new = 0.3806178231066095\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 19 step\n",
            "Delta Q = 0.9413076283746932\n",
            "Q_table[4,1]_old = 0.4040054295110427\n",
            "Q_table[(4, 1)]_new = 0.40491251493463165\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 20 step\n",
            "Delta Q = 0.9446962319178185\n",
            "Q_table[8,2]_old = 0.4172487714615474\n",
            "Q_table[(8, 2)]_new = 0.42022012623321114\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 21 step\n",
            "Delta Q = 0.9482188643960823\n",
            "Q_table[9,1]_old = 0.36079110503815104\n",
            "Q_table[(9, 1)]_new = 0.37293085893041816\n",
            "We are on 9 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 22 step\n",
            "Delta Q = 0.9\n",
            "Q_table[13,0]_old = 0.0\n",
            "Q_table[(13, 0)]_new = 0.0\n",
            "We are on 13 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 0 step\n",
            "Delta Q = 0.9400863389785286\n",
            "Q_table[0,1]_old = 0.3974154682250281\n",
            "Q_table[(0, 1)]_new = 0.39776026038105383\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 1 step\n",
            "Delta Q = 0.941601792497088\n",
            "Q_table[4,1]_old = 0.40491251493463165\n",
            "Q_table[(4, 1)]_new = 0.4060230559382564\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 2 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[8,3]_old = 0.3806178231066095\n",
            "Q_table[(8, 3)]_new = 0.38275232333383596\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 3 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[4,0]_old = 0.3945567396945779\n",
            "Q_table[(4, 0)]_new = 0.3952973482630075\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 4 step\n",
            "Delta Q = 0.9393782657777243\n",
            "Q_table[4,3]_old = 0.3850947637017389\n",
            "Q_table[(4, 3)]_new = 0.38596355310928937\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 5 step\n",
            "Delta Q = 0.9393782657777243\n",
            "Q_table[0,3]_old = 0.3917792786080188\n",
            "Q_table[(0, 3)]_new = 0.3919796165249413\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 6 step\n",
            "Delta Q = 0.9393782657777243\n",
            "Q_table[0,0]_old = 0.39169105733269244\n",
            "Q_table[(0, 0)]_new = 0.39190021737714753\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 7 step\n",
            "Delta Q = 0.9395440062012189\n",
            "Q_table[0,2]_old = 0.3903699047617459\n",
            "Q_table[(0, 2)]_new = 0.3908769204867901\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 8 step\n",
            "Delta Q = 0.941639522326344\n",
            "Q_table[1,2]_old = 0.39943440607291775\n",
            "Q_table[(1, 2)]_new = 0.4011304877919699\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 9 step\n",
            "Delta Q = 0.9333822139166628\n",
            "Q_table[2,2]_old = 0.27873622159420036\n",
            "Q_table[(2, 2)]_new = 0.284244813351443\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 10 step\n",
            "Delta Q = 0.9333822139166628\n",
            "Q_table[3,3]_old = 0.27845492867795296\n",
            "Q_table[(3, 3)]_new = 0.28399164972682034\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 11 step\n",
            "Delta Q = 0.9333822139166628\n",
            "Q_table[3,3]_old = 0.28399164972682034\n",
            "Q_table[(3, 3)]_new = 0.288974698670801\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 0 step\n",
            "Delta Q = 0.9397119182914051\n",
            "Q_table[0,2]_old = 0.3908769204867901\n",
            "Q_table[(0, 2)]_new = 0.39150114672951614\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 1 step\n",
            "Delta Q = 0.9397119182914051\n",
            "Q_table[1,3]_old = 0.3789967852916408\n",
            "Q_table[(1, 3)]_new = 0.38080902505388176\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 2 step\n",
            "Delta Q = 0.9397119182914051\n",
            "Q_table[1,3]_old = 0.38080902505388176\n",
            "Q_table[(1, 3)]_new = 0.38244004083989863\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 3 step\n",
            "Delta Q = 0.941639522326344\n",
            "Q_table[1,2]_old = 0.4011304877919699\n",
            "Q_table[(1, 2)]_new = 0.4026569613391169\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 4 step\n",
            "Delta Q = 0.941639522326344\n",
            "Q_table[2,3]_old = 0.388074418338472\n",
            "Q_table[(2, 3)]_new = 0.39090649883096873\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 5 step\n",
            "Delta Q = 0.941639522326344\n",
            "Q_table[2,3]_old = 0.39090649883096873\n",
            "Q_table[(2, 3)]_new = 0.3934553712742158\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 6 step\n",
            "Delta Q = 0.9398630391725726\n",
            "Q_table[2,0]_old = 0.3725564673169633\n",
            "Q_table[(2, 0)]_new = 0.3751638597578395\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 7 step\n",
            "Delta Q = 0.941639522326344\n",
            "Q_table[1,2]_old = 0.4026569613391169\n",
            "Q_table[(1, 2)]_new = 0.40403078753154914\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 8 step\n",
            "Delta Q = 0.9333822139166628\n",
            "Q_table[2,2]_old = 0.284244813351443\n",
            "Q_table[(2, 2)]_new = 0.2892025459329614\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 0 step\n",
            "Delta Q = 0.9393782657777243\n",
            "Q_table[0,0]_old = 0.39190021737714753\n",
            "Q_table[(0, 0)]_new = 0.39208846141715714\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 1 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[0,1]_old = 0.39776026038105383\n",
            "Q_table[(0, 1)]_new = 0.39818051688083583\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 0 step\n",
            "Delta Q = 0.9394198711712027\n",
            "Q_table[0,3]_old = 0.3919796165249413\n",
            "Q_table[(0, 3)]_new = 0.39220152604364994\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 1 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[0,1]_old = 0.39818051688083583\n",
            "Q_table[(0, 1)]_new = 0.39855874773063965\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 2 step\n",
            "Delta Q = 0.9394573160253333\n",
            "Q_table[4,3]_old = 0.38596355310928937\n",
            "Q_table[(4, 3)]_new = 0.38682451382369376\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 3 step\n",
            "Delta Q = 0.9394573160253333\n",
            "Q_table[0,0]_old = 0.39208846141715714\n",
            "Q_table[(0, 0)]_new = 0.39233693130077474\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 4 step\n",
            "Delta Q = 0.9394573160253333\n",
            "Q_table[0,0]_old = 0.39233693130077474\n",
            "Q_table[(0, 0)]_new = 0.3925605541960306\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 5 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[0,1]_old = 0.39855874773063965\n",
            "Q_table[(0, 1)]_new = 0.39889915549546306\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 6 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[4,0]_old = 0.3952973482630075\n",
            "Q_table[(4, 0)]_new = 0.39596389597459414\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 7 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[4,0]_old = 0.39596389597459414\n",
            "Q_table[(4, 0)]_new = 0.3965637889150221\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,2]_old = 0.0\n",
            "Q_table[(4, 2)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 0 step\n",
            "Delta Q = 0.9394910163940509\n",
            "Q_table[0,3]_old = 0.39220152604364994\n",
            "Q_table[(0, 3)]_new = 0.39247238983333577\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 1 step\n",
            "Delta Q = 0.9394910163940509\n",
            "Q_table[0,3]_old = 0.39247238983333577\n",
            "Q_table[(0, 3)]_new = 0.39271616724405306\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 2 step\n",
            "Delta Q = 0.9394910163940509\n",
            "Q_table[0,0]_old = 0.3925605541960306\n",
            "Q_table[(0, 0)]_new = 0.3927955151704784\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 3 step\n",
            "Delta Q = 0.9399990479656234\n",
            "Q_table[0,2]_old = 0.39150114672951614\n",
            "Q_table[(0, 2)]_new = 0.3923500800221879\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 4 step\n",
            "Delta Q = 0.9399990479656234\n",
            "Q_table[1,3]_old = 0.38244004083989863\n",
            "Q_table[(1, 3)]_new = 0.38419508472153213\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 5 step\n",
            "Delta Q = 0.9399990479656234\n",
            "Q_table[1,3]_old = 0.38419508472153213\n",
            "Q_table[(1, 3)]_new = 0.3857746242150023\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 6 step\n",
            "Delta Q = 0.9399990479656234\n",
            "Q_table[1,3]_old = 0.3857746242150023\n",
            "Q_table[(1, 3)]_new = 0.38719620975912544\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 7 step\n",
            "Delta Q = 0.941639522326344\n",
            "Q_table[1,2]_old = 0.40403078753154914\n",
            "Q_table[(1, 2)]_new = 0.40526723110473817\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 8 step\n",
            "Delta Q = 0.9333822139166628\n",
            "Q_table[2,2]_old = 0.2892025459329614\n",
            "Q_table[(2, 2)]_new = 0.293664505256328\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 9 step\n",
            "Delta Q = 0.941639522326344\n",
            "Q_table[3,0]_old = 0.3371940799662898\n",
            "Q_table[(3, 0)]_new = 0.34511419429600476\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 10 step\n",
            "Delta Q = 0.9401214558793691\n",
            "Q_table[2,0]_old = 0.3751638597578395\n",
            "Q_table[(2, 0)]_new = 0.3777689296614246\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 11 step\n",
            "Delta Q = 0.941639522326344\n",
            "Q_table[1,2]_old = 0.40526723110473817\n",
            "Q_table[(1, 2)]_new = 0.4063800303206083\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 12 step\n",
            "Delta Q = 0.941639522326344\n",
            "Q_table[2,3]_old = 0.3934553712742158\n",
            "Q_table[(2, 3)]_new = 0.3957493564731382\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 13 step\n",
            "Delta Q = 0.944538186856388\n",
            "Q_table[2,1]_old = 0.4206012356196358\n",
            "Q_table[(2, 1)]_new = 0.4230792989140602\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 14 step\n",
            "Delta Q = 0.9418848505924919\n",
            "Q_table[6,3]_old = 0.31414943574438176\n",
            "Q_table[(6, 3)]_new = 0.32461934276243554\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 15 step\n",
            "Delta Q = 0.944538186856388\n",
            "Q_table[2,1]_old = 0.4230792989140602\n",
            "Q_table[(2, 1)]_new = 0.4253095558790422\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 16 step\n",
            "Delta Q = 0.9560238112792296\n",
            "Q_table[6,1]_old = 0.44988067531705045\n",
            "Q_table[(6, 1)]_new = 0.4609164190645751\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 17 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 0 step\n",
            "Delta Q = 0.9394910163940509\n",
            "Q_table[0,0]_old = 0.3927955151704784\n",
            "Q_table[(0, 0)]_new = 0.3930069800474814\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 1 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[0,1]_old = 0.39889915549546306\n",
            "Q_table[(0, 1)]_new = 0.39920552248380414\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 2 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[4,0]_old = 0.3965637889150221\n",
            "Q_table[(4, 0)]_new = 0.39710369256140726\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 3 step\n",
            "Delta Q = 0.9395213467258966\n",
            "Q_table[4,3]_old = 0.38682451382369376\n",
            "Q_table[(4, 3)]_new = 0.38766340916722103\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 4 step\n",
            "Delta Q = 0.9395213467258966\n",
            "Q_table[0,3]_old = 0.39271616724405306\n",
            "Q_table[(0, 3)]_new = 0.39296589724554437\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 5 step\n",
            "Delta Q = 0.9395213467258966\n",
            "Q_table[0,0]_old = 0.3930069800474814\n",
            "Q_table[(0, 0)]_new = 0.39322762876862993\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 6 step\n",
            "Delta Q = 0.9402316230017402\n",
            "Q_table[0,2]_old = 0.3923500800221879\n",
            "Q_table[(0, 2)]_new = 0.3933466950217093\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 7 step\n",
            "Delta Q = 0.9421056460320252\n",
            "Q_table[1,2]_old = 0.4063800303206083\n",
            "Q_table[(1, 2)]_new = 0.40784767332057265\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 8 step\n",
            "Delta Q = 0.9421056460320252\n",
            "Q_table[2,3]_old = 0.3957493564731382\n",
            "Q_table[(2, 3)]_new = 0.39828006685784956\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 9 step\n",
            "Delta Q = 0.9421056460320252\n",
            "Q_table[2,3]_old = 0.39828006685784956\n",
            "Q_table[(2, 3)]_new = 0.40055770620408976\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 10 step\n",
            "Delta Q = 0.9403769196587367\n",
            "Q_table[2,0]_old = 0.3777689296614246\n",
            "Q_table[(2, 0)]_new = 0.38036895635401885\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 11 step\n",
            "Delta Q = 0.9421056460320252\n",
            "Q_table[1,2]_old = 0.40784767332057265\n",
            "Q_table[(1, 2)]_new = 0.40916855202054053\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 12 step\n",
            "Delta Q = 0.9421056460320252\n",
            "Q_table[2,3]_old = 0.40055770620408976\n",
            "Q_table[(2, 3)]_new = 0.4026075816157059\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 13 step\n",
            "Delta Q = 0.9405076866500335\n",
            "Q_table[2,0]_old = 0.38036895635401885\n",
            "Q_table[(2, 0)]_new = 0.3828397473686505\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 14 step\n",
            "Delta Q = 0.9395213467258966\n",
            "Q_table[1,0]_old = 0.3882904831664458\n",
            "Q_table[(1, 0)]_new = 0.3889827815756979\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 15 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[0,1]_old = 0.39920552248380414\n",
            "Q_table[(0, 1)]_new = 0.3994812527733111\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 16 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[4,0]_old = 0.39710369256140726\n",
            "Q_table[(4, 0)]_new = 0.3975896058431539\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 17 step\n",
            "Delta Q = 0.9395486440245578\n",
            "Q_table[4,3]_old = 0.38766340916722103\n",
            "Q_table[(4, 3)]_new = 0.38844571227505675\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 18 step\n",
            "Delta Q = 0.9395486440245578\n",
            "Q_table[0,0]_old = 0.39322762876862993\n",
            "Q_table[(0, 0)]_new = 0.3934535099163248\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 19 step\n",
            "Delta Q = 0.9405076866500335\n",
            "Q_table[0,2]_old = 0.3933466950217093\n",
            "Q_table[(0, 2)]_new = 0.39451971216957193\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 20 step\n",
            "Delta Q = 0.9395486440245578\n",
            "Q_table[1,0]_old = 0.3889827815756979\n",
            "Q_table[(1, 0)]_new = 0.3896331474426859\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 21 step\n",
            "Delta Q = 0.9405076866500335\n",
            "Q_table[0,2]_old = 0.39451971216957193\n",
            "Q_table[(0, 2)]_new = 0.39557542760264824\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 22 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 0 step\n",
            "Delta Q = 0.9395486440245578\n",
            "Q_table[0,3]_old = 0.39296589724554437\n",
            "Q_table[(0, 3)]_new = 0.3932179515455478\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 1 step\n",
            "Delta Q = 0.9395486440245578\n",
            "Q_table[0,3]_old = 0.3932179515455478\n",
            "Q_table[(0, 3)]_new = 0.39344480041555085\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 2 step\n",
            "Delta Q = 0.9401962825378875\n",
            "Q_table[0,1]_old = 0.3994812527733111\n",
            "Q_table[(0, 1)]_new = 0.39972941003386736\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 3 step\n",
            "Delta Q = 0.941601792497088\n",
            "Q_table[4,1]_old = 0.4060230559382564\n",
            "Q_table[(4, 1)]_new = 0.4070225428415187\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 4 step\n",
            "Delta Q = 0.941601792497088\n",
            "Q_table[8,0]_old = 0.3951084635983449\n",
            "Q_table[(8, 0)]_new = 0.3971994097355983\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 5 step\n",
            "Delta Q = 0.941601792497088\n",
            "Q_table[8,0]_old = 0.3971994097355983\n",
            "Q_table[(8, 0)]_new = 0.3990812612591264\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 6 step\n",
            "Delta Q = 0.9402952317413104\n",
            "Q_table[8,3]_old = 0.38275232333383596\n",
            "Q_table[(8, 3)]_new = 0.3847723227417627\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 7 step\n",
            "Delta Q = 0.9395732115933529\n",
            "Q_table[4,3]_old = 0.38844571227505675\n",
            "Q_table[(4, 3)]_new = 0.38917435264090394\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 8 step\n",
            "Delta Q = 0.9405076866500335\n",
            "Q_table[0,2]_old = 0.39557542760264824\n",
            "Q_table[(0, 2)]_new = 0.39652557149241696\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 9 step\n",
            "Delta Q = 0.9395732115933529\n",
            "Q_table[1,0]_old = 0.3896331474426859\n",
            "Q_table[(1, 0)]_new = 0.3902430442917702\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 10 step\n",
            "Delta Q = 0.9395732115933529\n",
            "Q_table[0,0]_old = 0.3934535099163248\n",
            "Q_table[(0, 0)]_new = 0.3936813705180452\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 11 step\n",
            "Delta Q = 0.9405076866500335\n",
            "Q_table[0,2]_old = 0.39652557149241696\n",
            "Q_table[(0, 2)]_new = 0.39738070099320877\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 12 step\n",
            "Delta Q = 0.9421056460320252\n",
            "Q_table[1,2]_old = 0.40916855202054053\n",
            "Q_table[(1, 2)]_new = 0.4103573428505116\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 13 step\n",
            "Delta Q = 0.9341663052353045\n",
            "Q_table[2,2]_old = 0.293664505256328\n",
            "Q_table[(2, 2)]_new = 0.2984643599659996\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 14 step\n",
            "Delta Q = 0.9341663052353045\n",
            "Q_table[3,3]_old = 0.288974698670801\n",
            "Q_table[(3, 3)]_new = 0.29424353403902537\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 15 step\n",
            "Delta Q = 0.9341663052353045\n",
            "Q_table[3,3]_old = 0.29424353403902537\n",
            "Q_table[(3, 3)]_new = 0.2989854858704273\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 16 step\n",
            "Delta Q = 0.9341663052353045\n",
            "Q_table[3,2]_old = 0.2190402747248217\n",
            "Q_table[(3, 2)]_new = 0.23130255248764403\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 17 step\n",
            "Delta Q = 0.9341663052353045\n",
            "Q_table[3,2]_old = 0.23130255248764403\n",
            "Q_table[(3, 2)]_new = 0.24233860247418412\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 18 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 0 step\n",
            "Delta Q = 0.9395732115933529\n",
            "Q_table[0,0]_old = 0.3936813705180452\n",
            "Q_table[(0, 0)]_new = 0.3938864450595935\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 1 step\n",
            "Delta Q = 0.9395732115933529\n",
            "Q_table[0,3]_old = 0.39344480041555085\n",
            "Q_table[(0, 3)]_new = 0.39367353196734867\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 2 step\n",
            "Delta Q = 0.9402952317413104\n",
            "Q_table[0,1]_old = 0.39972941003386736\n",
            "Q_table[(0, 1)]_new = 0.400051700771791\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 3 step\n",
            "Delta Q = 0.9396051183764074\n",
            "Q_table[4,3]_old = 0.38917435264090394\n",
            "Q_table[(4, 3)]_new = 0.38986203575322087\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 4 step\n",
            "Delta Q = 0.9396051183764074\n",
            "Q_table[0,3]_old = 0.39367353196734867\n",
            "Q_table[(0, 3)]_new = 0.3939112971470211\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 5 step\n",
            "Delta Q = 0.9402952317413104\n",
            "Q_table[0,1]_old = 0.400051700771791\n",
            "Q_table[(0, 1)]_new = 0.40034176243592223\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 6 step\n",
            "Delta Q = 0.9396338344811563\n",
            "Q_table[4,3]_old = 0.38986203575322087\n",
            "Q_table[(4, 3)]_new = 0.3905096666590551\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 7 step\n",
            "Delta Q = 0.9396338344811563\n",
            "Q_table[0,0]_old = 0.3938864450595935\n",
            "Q_table[(0, 0)]_new = 0.3941316350347905\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 8 step\n",
            "Delta Q = 0.9396338344811563\n",
            "Q_table[0,3]_old = 0.3939112971470211\n",
            "Q_table[(0, 3)]_new = 0.3941540019134753\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 9 step\n",
            "Delta Q = 0.9396338344811563\n",
            "Q_table[0,0]_old = 0.3941316350347905\n",
            "Q_table[(0, 0)]_new = 0.39435230601246773\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 10 step\n",
            "Delta Q = 0.9396338344811563\n",
            "Q_table[0,3]_old = 0.3941540019134753\n",
            "Q_table[(0, 3)]_new = 0.3943724362032841\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 11 step\n",
            "Delta Q = 0.9402952317413104\n",
            "Q_table[0,1]_old = 0.40034176243592223\n",
            "Q_table[(0, 1)]_new = 0.40060281793364033\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 12 step\n",
            "Delta Q = 0.941601792497088\n",
            "Q_table[4,1]_old = 0.4070225428415187\n",
            "Q_table[(4, 1)]_new = 0.4079220810544547\n",
            "We are on 4 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 13 step\n",
            "Delta Q = 0.941601792497088\n",
            "Q_table[8,0]_old = 0.3990812612591264\n",
            "Q_table[(8, 0)]_new = 0.40077492763030165\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 14 step\n",
            "Delta Q = 0.9446962319178185\n",
            "Q_table[8,2]_old = 0.42022012623321114\n",
            "Q_table[(8, 2)]_new = 0.42289434552770855\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 15 step\n",
            "Delta Q = 0.9418665402072431\n",
            "Q_table[9,0]_old = 0.3280275402042163\n",
            "Q_table[(9, 0)]_new = 0.3370913263910379\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 16 step\n",
            "Delta Q = 0.9446962319178185\n",
            "Q_table[8,2]_old = 0.42289434552770855\n",
            "Q_table[(8, 2)]_new = 0.4253011428927562\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 17 step\n",
            "Delta Q = 0.9560238112792296\n",
            "Q_table[9,2]_old = 0.45147709007897474\n",
            "Q_table[(9, 2)]_new = 0.462353192350307\n",
            "We are on 9 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 18 step\n",
            "Delta Q = 0.9457729660426805\n",
            "Q_table[10,0]_old = 0.2328052931620214\n",
            "Q_table[(10, 0)]_new = 0.25529772988849964\n",
            "We are on 10 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 19 step\n",
            "Delta Q = 0.942104813146383\n",
            "Q_table[9,0]_old = 0.3370913263910379\n",
            "Q_table[(9, 0)]_new = 0.34548700689831696\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 20 step\n",
            "Delta Q = 0.9403842860243911\n",
            "Q_table[8,3]_old = 0.3847723227417627\n",
            "Q_table[(8, 3)]_new = 0.3866793764919775\n",
            "We are on 8 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 21 step\n",
            "Delta Q = 0.9403842860243911\n",
            "Q_table[4,0]_old = 0.3975896058431539\n",
            "Q_table[(4, 0)]_new = 0.39821493128322955\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 22 step\n",
            "Delta Q = 0.9396596789754305\n",
            "Q_table[4,3]_old = 0.3905096666590551\n",
            "Q_table[(4, 3)]_new = 0.39111837896858\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 23 step\n",
            "Delta Q = 0.9396596789754305\n",
            "Q_table[0,0]_old = 0.39435230601246773\n",
            "Q_table[(0, 0)]_new = 0.39457675438665135\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 24 step\n",
            "Delta Q = 0.9396596789754305\n",
            "Q_table[0,0]_old = 0.39457675438665135\n",
            "Q_table[(0, 0)]_new = 0.3947787579234166\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 25 step\n",
            "Delta Q = 0.9403842860243911\n",
            "Q_table[0,1]_old = 0.40060281793364033\n",
            "Q_table[(0, 1)]_new = 0.40092682216466735\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 26 step\n",
            "Delta Q = 0.939691755394302\n",
            "Q_table[4,3]_old = 0.39111837896858\n",
            "Q_table[(4, 3)]_new = 0.39169829646602405\n",
            "We are on 4 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 27 step\n",
            "Delta Q = 0.939691755394302\n",
            "Q_table[0,3]_old = 0.3943724362032841\n",
            "Q_table[(0, 3)]_new = 0.3946269479772578\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 28 step\n",
            "Delta Q = 0.939691755394302\n",
            "Q_table[0,3]_old = 0.3946269479772578\n",
            "Q_table[(0, 3)]_new = 0.39485600857383407\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 29 step\n",
            "Delta Q = 0.9406253769422007\n",
            "Q_table[0,2]_old = 0.39738070099320877\n",
            "Q_table[(0, 2)]_new = 0.39826800783608857\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 30 step\n",
            "Delta Q = 0.939691755394302\n",
            "Q_table[1,0]_old = 0.3902430442917702\n",
            "Q_table[(1, 0)]_new = 0.39091049525689525\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 31 step\n",
            "Delta Q = 0.9406253769422007\n",
            "Q_table[0,2]_old = 0.39826800783608857\n",
            "Q_table[(0, 2)]_new = 0.39906658399468037\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 32 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j45ghrMbmYMW",
        "outputId": "f9c36d5e-5927-4d99-bf6c-575f4c1c2eca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg) (67.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio"
      ],
      "metadata": {
        "id": "NKpgHiejml6h"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_video(env, q_table, out_directory, fps=1):\n",
        "  images = []\n",
        "  done = False\n",
        "  state = env.reset(seed=random.randint(0,500))\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action = np.argmax(q_table[state][:])\n",
        "    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ],
      "metadata": {
        "id": "Vi8Mq4tEl4Yb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path=\"/content/replay.gif\"\n",
        "video_fps=1\n",
        "record_video(env, q_table, video_path, video_fps)\n",
        "\n",
        "from IPython.display import Image\n",
        "Image('./replay.gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "turRjFNxmFal",
        "outputId": "73b937ca-b2dc-407a-e26d-2fbed1b0fcf7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/gif": "R0lGODlhAAEAAYUAAP///+v1+Zz3/9/w/8zm/1bj97TI5mjW/z3K8v/CofC1QaHA3auwtJ6qsGOrP0+kuDu+/zK5/zK4/yy1/yip+Syl9SWo/9Ccjs91K4yhtDt9TzGh7yKb9R53v6tRMOZFOa0vRY9NV5dEBok7DFIzP0xohTo/XisrRQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACH5BABkAAAALAAAAAAAAQABAAj/AA0IHEiwoMGDCBMqXMiwocOHECNKnEixokWCBDJq3EgggMcAAEKKHEmypMmPHzmqzChw5UaUJmPKHInSo0uOLW92/Diz58maOjXmvAnTp9GQNQMEZWlA6dKdPotGBepSoNOlHqdmNZr0ptWnUHtKFUt15denW2eOVVtW5VmsIMmmlZuyalOwc2OuldnV7tWgeX8G1tsW5120cdkOFlzX7GG8PEUuTko5MYDKAd4injsZ81jMmuFytkzTc2SklUMDPn2ZtGTToymr1vnZNWrYpWU/3my5M+7Xuv+K7m279e/bSWcTZe3bdO7kTVFC7psU9fPqwD1alc6bO/bYlK9v/2+8mnpN69mxI88cnTxtyhm/E68svr3N7nXlXz+ffvz94d7xB556xmlnn3DLmVfUgPyt5x+CLlUWn4DzhdefAem5txJ9rR1F4EcCZfhfghR62KBxIa6noUocLlbShwaKCCFHLRb34okgYqjiiBFa6CJJMLInI4CR/bhfbikWyN17+nGFY4w7zviSjzYC+aSQ+9W4IGZHIYdUklHKtyWHJm6FpYxiFslllwuCqeSaaRKoVVxnhknhmBaWSaebsJl5Z55Omslnnyra2WWBX+qI5p9+khnonooq1ieecvrkJmGTUnqiUZcylimda3bZ6Y2fNgoop5HylSkJrJJg6KGjWv9ZKqiOovrop6+KmiqmpeZ61HiHztSqq4saeRmwwbKV5aYnIZssYcvu9aKzz94YLWt6UVttSMNeayx72G6Lnp3faituh8VWmWi44jJY6bQY3ofnuK+x6sC9DrA6GovshhSivGr6ae1PpfHr4r9OzYtuadC+ZrCNCE9oKr0Uv1Ywjf0CEPFOEy9cLwn45kvCvhgfHG/CAYM68MqtPSzTxgoH1tnFU5rcMse0qmxlw6i5HFOntZJkb8j4skoqgoMBfeq5S2qU9K5vGnto0xOapPS721IdFklXMzvS0ESLfDS/VkMddLsaPu1pxs9qrfbR0madtm0IN4wdqxpoEPa9eev/m3OPNdVN8JvJmgo4SoIPjLWyBR6eo8cMEx6s4RtCB7nFkuOt9959j/x35YGfbLfXZCHneIwzSz715w8/nvriqpoOOuIGaCTpfZrnrfvuvBv95lND3Y5ytX0FFbyqARJfmF22I5+fus7zyHxGwmeUO+/Yd64i8LVTH/3wbS/vWPO8Aqy81uN7Xz74hYvvVvdOF8cdqyCA8MH9+Od/f/2+b6/TUFVjjErOt6KNAHBrskIQAaVnGIzxaoDhQ58B4RfAsRGAfvbTnwb5Ryz/eYWCCHwOBNsnQaGAsDkjnJz7TOhAAXJkgVJiyk2OhsH6aXCD9QNB/7LzwRkm8D2ME+H0/1ZiwR4FkYdDTKHsjBi7HybxhQmsYQZviL8c6rCDSEwfEZ3IRJ5l8X0+FGIXBydGMLqkiJU74hLfV8C0DIsE9VOAAjCAgQTY8Y52pKMcOei3I6GoPWMs4eyCFLDxBLKAp6vNmAyZxi8SSZGFBGQjAfDGOM6xjni8ox4VwEfP+TFHbawQWCQGKDExkmyOLE8p73TKFq7xkcxh5YFM06oLXCCPGAiBLkOAx12GgI52tCWrKhg1A81qhfHjFzFBM8tSwUWZCGTmMQU5IWi6y5irYpUtcenLXu4SmAkQJgmWmZpmfuqZGCNncKbJwHS685rgYmcMq/nOCoVOfpgZ1jYTwP8qPPYznBcYltRGYpX1TQqapAxWQdd2UHcmFFZNMWifEIozhUaUoR/R5y35SQJ/dhSgAoUe1y4Kt0xRNG4vI2kCz+nQikIUn7M6KdvKJlKh1XKj/7TjP8W5Q13V1FuEStZCVyfPZw2VTfL8KUFVWqabZvKOPPWkUJl6q2MalapzmuZVlUquoFr0L8Fy6lNB2qplpRSsEQzVSjOmGRhi7Wz+2o1bSQdXjcn1UK3ypV532S0ZnXUjc41bXduaVrgO9q4kVKtZf3Yg9fkkr3vVa1/XN1KqnEtua3mQYy9LVGxplgCcLSxpPnsUsDlgfzm8X8h6utbKcie0ic0LaWHbWdn/Nha0tEVqZiUJ2MGZFrU2/MBqsdjVrLRys5gzkfDoc1zcsmwqyw1Pc70I3e8xl7fk2xklP5q3vTkgbzolbjGrM10yOim65MUuciumxrVeV0PULZ11pXuyM8rkn93lnAbCW7wEbUyJnO0v4P4LRdoKGHQE7q2BkSmxBGe3JKzy5f3kKMf7+dJv1OSYg9fLNAZruL5bXHCGXTej3P6uPAhrZ2UivMsJU9jCfMWihDaU4hkV9XIzZlGNE5mpiuWYRjseZK9wDB8an0zF+YRjDodlRdb++CVBbt2QZVZkHR/Zxuz0cZWBfGUeT0rLB45PktqpEykyecni3Y+VHTbKmqFs/6AHPhOZVfnQrCJtzPMkUZ3pIj0553kjGQh0BoYV6AY0YFgMSDQD1rfmnrU5fgCD8/L8/GhIv7mmccZzpUm55+px2UpgKfShW2XoRCNa0XoyIahHmbwO/2dQbW412l6dqjk/jJgEVDXNnmJoQ4ta0cBetG6vAmtWP++ySyr2dNiHWWLX+s+WxnVadc3Fm4i61w1INLYNDTsHmQ2RJUtZXS/kQiJ1NatdW7apxu3tcqty3UuDW7rxc24+z9vc452pku797pyxe99Q81K+qTwctcRKU5WytUuzFXBEDdw1CkfpsRqOcGZFnG11SmC9d304g1Nc3Eu7+I8y/pyNs5lJVf8ieXZM7miUezzlVBo5uKUtkqOWtGMPXM1ZoyvwnAORsTBPk6TgsvP59tzdY6wszx3u8+UUXaJHR2PSlxr0Pw1d50BnrwpL6nKqa311XCeR0i/XvrB33Otk3/pau17ziw60vWG29Njf3kQ1ix3tdI9v3Du90Lyb14Ozcy1xnjvtd1OLysieOc7iOXjtzjrP9xwN4RMLoMNDnKtIH6TlJ69CkWOz8ZF7fOXbE/rkNnv08WZMZ2P9IEnTPcNQbqaeVs/q1mNa32XEiu1nP2zWy/5RtMfL7oHf+9r/fk7BR4vtZ1X6phvPnEP+eio/mFTJ02WUy49+2nP/v4t4//vgD7//+MdP/vKb//zoT7/618/+76tSxIonwAF9Ftq9T/D9sLU/C9keYA/Lfzc/Jyl6QmbKgUrWJ3F25xjQ9i24d2IKCBn0gnN8JiUF6ErOM4AUCIBO5zES6GkPiBjIV1XUB4EcmDMYOILGZn03t0rBQVH0tGmWBkn3FGuxJFGENIMt9YIwuHix1IIpCHruxYLQgTREuIMx2INDSIMqGIQ3SDtFmIOb5ijSBHs8GGlqci314X9GKGRZSIUz1iS+Ennxt4VS1oVj+IUlsihmqHBkWIYXooVouCVY+IZU2IZHWB9D0m8CU1VIoij6RwAdEIiCOIiEKIjqRjt5iHJyyIfAgWcZ/1aIkEiIh/g4UQJL0udHt+GIiheJnNgBkwglxWSJ29dajeiHHtaJkfiJGfdlkuMZnZUoP+EShUgBtFiLtlgBFcABHNCJijgovxEnpMMrsHgjskiItniMFICLusiLJLKKQQWMCKhxExeLKzGLyFiLyriLnNiLz/aLjBKMqjeNxFiNxniNtJiNzOg4sQJUWpJ6KWUSKmGN5kiLEVCP9oiL+FgBG7ABy2iIabSO6dKO3VYSnRKP5TiPFGCP95iP+siP2hiIRgSQxRVz7shY8MgR8jiPClmPDNmQ/QiR/9hw7EiRAzlSF7kRGWmOGxkBHbmPH+mJIdmAypUuUYEsBhmICP+Zkwm5kgv5kjVjLmgDVDVJegBwkx2gkwjJkz35kDDZYERZf/ZUkeuyFUaJlBqplCyZi0z5k0/Zf0IpFjaJkYJolSqJlejoj055MzFzeV7UZ2wFYig5lvNYAAWAAHZ5l3iJl0mZlYNYNTCTMlrWlkRoM9IziAhJl3mZmHe5l7jYl1Dxlx2DeOblloSJIIY5l3WpmInJmBXgmMYFYmvJeSTjZu9YmHJpjoipmXnJmZ4JEl0TjclHc0kSlzh5jKqJAHQpAAKQmrdJl8jYmP5oVxgFf6hkkiFBm0dpm6qZm7uZmb1ZAL/ZmcH5mjL5KMW5VCKBnMj4nLrJm8sJnccInCD/KZwrSJwW2HbZqRGXaYvc2Zy3aZe+GZ7SOZ6Jo10laZ+hFDpFqZ6nWYt4SZcAGqAAmpgC6px3GZ+2CJJC8jrgODpIpp/aqZzwWaACSqAVmpcIWosKWp+Rc58dmp+IGKHseaAUGqAWaqIYCp4JCpMLik+FonYSpBv7mRHr6Z8kWqLeOaEo+p8qqqEsejyMFkLDxoYhEpe26J26maTumZdK2p0FoJsW6qQrun/OtTY0J4JLUaT8eaQG2qRLipdeypxR2pxTKkMc5j9+B3gfNKOAmJy0iKRNmqMIEKZPKgBjmqEg+X8PtnZCeoJZiiFGWotwqqRySqdQmqJS6qNUeqVa/wNDz7eflzmhdumlhzqhlPqld6mkm0kBeXpAKFRgnTdzWhqpuJmZl8qjl1qoSbqpnXpCMKVAovWoNCqXkjqnlIqqlKqqlbqYnNqUnvqqAOanazqrtVmrp0qiqWqgk7qqq9mriwqqr3Sejjd9TAGpyYmXB3AAXsqjzEmoylqqcuqdrRpG1HqlYJaB1kqL2KqtTcqtdeqtJ/qt4uqrIKRg5dqnphetqjar6nqX2bqtN/quSRquA5qieDmu9sV9UwJ3iDSq1+qv7KqpAUun8WqhB0uvoaSwzXglkeQUxZqp7YqstwqudcqjOmqg9bih6hU/GutlUZmJh/GxyyqxljqyAf+6q6m5owiQsj+6suoEbaTUhDDrsQ87s8xaswB7s3ZKoieLlzwrZj4bTWMYtBzbKGchs7ZKs6V6rEprsiTrtBGgskmFTlPyszgYiImJswAKsCerq5hKlxMwAboJtWO7GtYUlaA0q2m7tCfLtiTrtt4Jt3IrAHQrT2SbTFLrg2jLpHxLsn5boHvrpDwat3PbEdnXUO9xt9FytR2wt+76uBcKpgNroIJbueBig6YhU3nHue0JupILsn6rmwo5AAPwma/KUmUrdy+lt995rDU7qCG7rLNbu66JVQ/3ZDtBmrvbpq0bvFuLqb5rq8Nru6jrGarLVazbuyP7u126vdJrj7T/S72hqlVTRbTMWaCgK6aIerSKGbe02zM2V1XMV76zer4Cmr4lu767mpjuOwDwa7zo1WP026b2q7Ra27X627j8OwHv2zLxa2fz+1X1W6fo67wIjKv7m5f9+79oFVupd1hOUY+BW7AGzL5Ia8J5qZADRFge/FbueBYiTLokvLbOe8IZDLb1uMKINb4f/MKHEcPu2rc1/Lxam5gq/EIszMMuvDgwHAEjnLM0XMREjMI4HAE6bFkmxohtF8IRIAESsKwl6rdGC6/fmcPkM1tZPIGVlRH16MVgTKFinLVx+q08asbqg8Zp/D1rTABt/MW2GsZDnKzPacfOhcd5vDZ73Mdv/1zBUizIZWzFZ7yy8dVeI2lXdVGP7lqin9uckMu0JHrEtis9k1x3GJVelxwBmUyhm6zJnjyhoFy88PV38lW9PMFImBywrCzEuVyqdWyPfinJskzJAQnL93HLbavKE8vJocvLn+zLjwmX0Np/I4Y6XAzFTqqz3NvJuiygZkxiCZt/HubNfOzEmVnABYuru6y0BdrN1PzNUDnNLcrG5JzN5yyy6UzD6wzJ4hysrqZ44gzEz6vN9ozM2xyg7NyiD2pVRBZ38UwAEAAB6CyvAivQYzy6Bg3JUNs4QoYrC+0+Df3QET2m11zPFT3SdEnICI1l5EtlDL0xID3QIq3MbuutF/8dexotZRzN0h7t0hAN0wlM0XJM0wCK0poWhc/jemkzmxoB0JqJoxJNpyNM1KYIgwGC1H2m1PIsp6mMzVM80r1s0y33aFV9e26D1eOs1bi8zDaszF/tNEVdaWMtrG6tKBvB1Irp1DHt1c0M1ifHG+ZafP8XFxvx0Macovcs1N3auCeN0dXKcXSGr8G3UIMNAYW91fWc2Iys2AVAyP+3asv216nGFIKtEYSNyneNoxgs0wLb1tQW1sMB2tYp2sdJ2pRt2vEq0Jh9v+y72IaReafDcp7iJpNd2Yqptoi92iSL0qDYsuEGbwOpnyMx3LatmsZt0VG8tDUNafymiP4mlQD/RxLS/Z62mtqZfbLKrXJe+I3PjYjRTdvE7bkia9LInd1pKYwPN478By+sEd4g29QTrdbJHQEWYAGOpXICdxx9fXYMt9/uPd03PMVAfdEDXuAHB3IJB3kYRy38vaz+fdzxWo8TXqUG7nAI7tqBxxca3uCi2+HWTbCLHeI08cB+xXS+La1bvBcZ8dClfdv4TMcB/tAFDstLJ3HTfFY47tA6TtyAjNYXDeQiLuRGR+NSN0kEeSAlkeNJPt3HbL/+vdhOzjAyHiVRV21Td+PhguU7bti6zeRDHQFfbjF9h3mEZ3+7VWRU2eDvLd53uZJUK75pOq1qGm6C12rSned6vrMb/9nnUP7nzeeAJ27mhI7nWn7oe57oVbjocg7ojk5/cWXno43lCknpisnnl27JS3iJsc2NR52G8qyQXvzqEoCVztxbBrN5mk55hidJNTLbKwnrXizrnI1btd6Vkil6ub7qi9jq9ujrsQ7sEDTsNXjroYp6Vpjs4+zqvg7sjO090H6fsHmvVibAJQfYynd8dBGbgHG5FleddWi55i6A5K570Hfhrze17u7dY351wjfv617vbDjX1QeEztd9Ad/oU0591WfwZE7wCZ+vNe4Y7RfxEj/xFF/xFn/xGJ/xGi9++PfO8Td/gg7OsAfyyuvxRFqvIW/yf1aBC3vuWPqBROfydv+GgjEP7zPvFyR4gA24dyzPsjI/gTSPdTYP9DgPgj/vgWyU84337TyvgfzXHK6IJj1f8mnHimEy9bqrdVY/XqrhlmQoheUEtAtX9V7F9U5/d1pf9tKkhAI/zJurgV6/hWC/Tmfo6YsYhk6Y3gpyhWpIh3W/93uI96DU7nZ4g58FS1QbgWolhv8eh3wv+J/X+Hb/+Pm2hmJf+FWrifCchnbWh4m4sYGvxqX4+TyG6i8KsxmyFKgIiaqo+f5MJRjo+ZWohzrT+aM/+9wd+sIj+5tOjqvvmLDkjN5Ycf4OKUz4jb4SgsLvHK2oWC6P3jOSkvL5koXIjcevKcn//L7I/ND/yO5Fsv1R3/3FP4yeLZY1Gp3UL4nNKJHHS5INWuXy+4zO3xPsv9LzPxMFaf79WZYK2ZIOCfwAQUCgwAABABgwAEDhQoYLCz6EGFGiQokQG168iBDjxYodI1L0uFGkRpEOPZ4E2bEkRpINBw7sEFMmBZo1bdKMkFNnBZ49N2zgwEFmh5cvCx408HDl0oZHTaJcGQChUqZVnaYMGXXq1apRDT7NWlJqUqdFCQy9mVatTZ1td1YIOtRowa1fu3pleJLrxrFU74q1C0BvYL51/+IFq1Ir2a9m0a6FzNZtW55xZc4dKzgAQaoWNXMkbDLv5qKeWSYsyNmp572fMXJNXdpv/0bUpFl3Dt0a5GizpmlrdjwTcoECCIwfR448ck6ecgkc1Rj79urcoXeb7D27YXTbuKmD5hs4NmbrCrmr/nob/GvxpMmPrB08ZmTiye0fXx6h+eXnBluOnugwkSDK7jT2AhTwQPcG0u2/xLRLEKwCf1Popcdsuu844gQQoL4MNSwgrf1iEggpBX2LUELZDAQNwRRVnIvFpip6ccbxGLSuJQuFw/DDDTss7kPjiBOxAudM1M01F61K7yGz0HuIu/CwShIwrJ7sLyIp2aOyPCs1u5G8KBPacb6bkCMuTTXTtG/NINEM8SYSn9tyvSWZoi5MHLWsbUowIVwqzwXFpKtPLv//rHLAJvWEslAAyuwgLTjdVLPNNS1Na86xBgKMwP4SlAjLohDiVFFPE+3USVEHIrVEU1VF9VVGzdJoR5s8NI5DXYG0b1cOf7T01zhpmpOAVglIVTovvfJ0VWMNKDW8U5dNdlAsj62WM1AjclagWmGKtCZcEfCV1+TKBTa5H4msqdhjtVXQrG2bvRbaGOMtal5VRX33U3xf0ndWVsk8S7ghgyyXQzgTNhe5Xe0jlihv7cVRWmsDtnZUiuFt8WIBQ1213yTpdfUwkPkl+LGDc0144YTHZVnh5CIeWNSOV020NZJf6hdgGzOuWNGb67X5Z5yX1XlfWlMOF7kDDih30gL/0H0TRJgRGNfdjfM1WtScqxO452hhfPLroZ8Uu2SyJ/QTQKCffbRgmpyG2lepqbb06qwlflbpe6/sdk8aH0ypLixh89tZqLosnLHD2xO47LAQXXQqgcx02G4QGT443ZWxZvO4nDQ1XHK3AxfcxQDHTJzjP1Fv1LfVC23dX8BRX5zyxknD/LioN28ZdM9B77zq0SXua7CTutVTWbf5VH55xa11/kHWo++Ieeq7ex4iywvuVYC7NS/+6l3HJW6CCTgkqC7suZ0+O9c9cv/92ueS33bKr7d/5/zx1x/9knK5DoRvfA+zWugyJyw4qY99dEqKxd73vyxRizbl6V/zFoSi/6VMRYLYoyAHV/K9mAjpR787GAN9FzyWtWUAA4BOBE8EQtm85y4enGH0QgiokuCwYxOsoeD+QsIC+mhqLASdCmNGPnIJwIUw9I8M75LBjxzGh12hogg7KEUsZjFWp+FdB9a1JhQK74jB0pWQ1PdCkPTNZF60IBjf6EUBXZFJdLTiAAs2RjWVsY/iU9cRZZahNQ6gjd9T2xT18sEqIRJZH1tkDr3kSIzdqUuN1GNO0Be6PyLQZZ68T1vkRUlI5q57mFxQJav4Qx4iJZWlnNwpJ5nJCGzSQ51MYyDLaB9R5qt+iaxRF1H0y0cG8y9LIqYx56id7+VEAhJgGaUEmcsF+v/qanDKic9c6SllHnOV5mFMbLqpyGGGkzTjFCYzafnMaFJql03EmxGzGa3SaXNGiqyWSuo5ttHgU1Yh2Scwr8OkfNKodDmRmjTHp1AQYVMn2gpoMe/ZxYJOJKJtwxPSlLdNj62HoP/Up+MIgNAEMrR4wnITnBw6zxgC50noPJnXHDUrmMLvaJmh6Thj+jickkaTQeKjAoFnUjOiNE0snSnQauo/2fQUS0u9357O81Kd2lSmTh1pLYF6xJTqEkhdPelXjxoB1XBnVnhM2k4ZZFagoRVsVjUKW3mawYFar61ThQAEXKa3aYJ1hVRT0zzbV5uzZrGul7wrYdtqWNfI8nD/cpUcFQ+7v8S6NK97rVoKdeXXJZ5vTYKFIHZgRx703DFxmWnjaAVX2ozuDLUuVW0FWRsouIa2QgP5qQmlmdkkWlOoxAHtayN30+58kXK9aclwr1rcOB63NMl92/SUZVy1vvYluTUiUTXr2U0G10HKJa3+9DWwGY12WjVq1nejm53qpSi9MnxJXkmaN0p9UqwnBOTBQAs33sDuvC96b3n9C6vmpoq8/cUdgdG7LxzGFwLzDSRR8esmUAKXrDxLyNmk651YnshBt9uwoBSTrA+/LnCzM6WHM7wQB0M4Q4PsrVHxW7zgOkrDxBXx4Ei84tOduIqDoe2Y/hXiRXX4hw5q/3EEhMQy+1I4l4G9cFl5/DPEclC5WqRIibFSZQhduZWC0fKfuJw07eXMMCweiHyVvMIMTfhSES5ATixgAbW9tmNjrk6ZkRbm6XTYy2aestvwDBo9i+XMtxWImjPX5r6+WWpyprNE+1LQLb9Ke/DRKIozvV7xMsSOP+uzgaeHaQ4mOq8PXnNC06REOOckr3WO4qZDbelRb+TTsqy0xS5tay6yUlCiPhqpIWRqRcP5j9c0o6shAGtXTvaNrCTudmRo3C91L9qennaBhQbq6JazIvBKsouXzEu3xC7WzvYmtJcr7SYtWN1zZTe6/WntdWP72/4Kd6rHHcpyV9Aih26saP8AHFUoATxpC/4z7RDn0QgxVUylU0xZstqWZ1ZcApOZjLzihhmDVwfhnIbewifqXoL7u+MMH2+IIT44iU/G4s/EeL99xt76UffLN1ZczZuL5SEzT+emJSen42rOFPMc5zj7eWu17fCyJT3ISy/50HXMLKiDd61E9/PNu4Y7nfevn1SHXdft93Vgd0vs7yM7rQN3duylXdeoQ0jc5T53utfd7nfHe971vne+993vfwd84AU/eMIX3vCHR3ziFb94xjc+8BvuplrRtjX2avvp4E2bEJUp+aVBfvO1nbzQ/SVyoz8IZaKPVem7dPoEP920YdPjrlP1+rc5MtgB/7XSYY//eguq3rmhbz3Vac96H7te97WPPY4oGFtzy7Iv5p3NyDZq1+cPWOS+nroART/bgDv/m9pffn+Y39Tvd8T2nkd39Jx//munf/pVZn+93Q9k6hNz/ONXnffMmWCQzc77z7M/Ipsu3Pi/xAhAHCMw9aA+yFG4qLu/uUIc/rG67PG3dltAANw/H+u/H2PA/JNA3ttABeQyDDQ9ZxmKE0RB/tAzPrGrFSTA4wMQ6OI8QvkOGHwKGQQ98hNBqotAHFSuFARCFRRAG6MsF6zBy4McHyy5iNu58hOue0PAI+TBJAw02CoKFIyMyhCKIMQx9aI/TbOkV8myKVM/3aEsahMzMCPD/+kDw28yPjsTLfngEbXQwiDkm8giQjzLsRFMpzHkNibsszC0GD/0vkAsMkFUEEJ0iSs8wcjACbfoCZ8Aii0slhUJs0LMihQboSrEvi80sh7ixD9kw0+ED4yQQzPJD8qIxAr4CcuoxBi5xAWECk0ExeMrQ1osRSS8RVLkNaqQQ0d0xJhjDrigxDvkn8jrwKkrDMZARkwMFIBbCg+QxmlkOIiYRg8oveRpDEZERWBUC2HUD2J0DinTunk7Q63TxmaUxd6DxpW4Rmmsxoe4xmycKkihD97KkPwYEeSJIpeatYM7lNSyIQMZwEoDyHisvFIsyD8xAROQRgWAyIiUxoakyP+KdMhpjEgFmEgTwLJ6BJduTAtkgxjIGEbnaKmF3EH3QzDNI0jmMkiPC0gr5D5p80cOa8iHzEiN9ACLtMhrzMiN7MgVs8czMSJWY7QiOZISG7Fgcq0cqcKl/Di2wbYZukkPyMmclMYH0MqtxMmrhMiNdJ2F0JGPDJceYTSjvA92sYl9LBGlVMaB0yAZwbXPi0sK4baq9EqJ9ICt5EqrzEudbMiwBKeNKxiQpABV4ywz4qtMQZ46mShE9BOmqgjH/DrIPBTJlAjKNAm8VAAMwACfjEjPvEbP/MlpFM2dNAEa/BYCMkzEdLSS4i21bJfGNBQ7ccOMAjHVrM3HvE3ays3/1Emq8ODM0+zKzvxM08SA0pTG0wxM4MwMWxGXqomnahIWGNMs2dQafuI2wRw+s6OYbOm07nQWbBGJqiRN4xzN4yzN0/TM9sQAERCB5kQZwuzGcZnOv9qsM/Iq7OQb8vwg7jy+tfvOfwJQJBRQ7WQI80xO9ETO4lzO43RPz4RP+ayXuFEZ4oEnJsIvzwof60QAmpmYFek5iQq64RIZDEocjBnPrWkNBY3Q9kxP4kTO09RKCp08CzUYDOUc4LnPJRrJ7PybrUPQAA0ZFkVRPVHRIhXRBL3IF3XPGD1OKM3KB7DRpcHRuTmOp/GjVfMt+rIU5ABSquqxx6m2tcGwohlT/9PZtjTVGDQFgIbUSmkcgTml0zqd02u0Uzqd0hrlSOS70sPM0rqpMC7lUDj70uMIU41j0yWNyd+smacSUqlEORObPDeF0weQ0zy1UzzV1D2l0j4lvt7prPyKMc35I5UyI+Q4nsGqnQjcvgqUHQ7URjI10yiMPlmNKM64VL4sgRJ4Rw940fTsVb7kUxQjIiwdVftCoFNtqFQVnQggHZGSSqarPA/0jlwNIAc0N1fNE2wtiF3dyl791WBFzmEl1oY0Vj0qoXMhVVyCscQs1INxIAFgVS/SnvzhVv2Do3sNonz9wI4AV63MyNO8yge9Sr5sSPhT1yJatATa0kphV1ZLn//1oVcI2tf46ddk/Ff74VcA8tcGPImAfYCBVU+sBNYFzUiENQGFDSPd2tHrlE4k4pAniqEj5dggmsktslkgAqCc3USbBdeC9YBevUpxPdmD/dSfJSCXRaIxok5qaiKaPTdJGowdQsNmo1q9sFrLuzWGNAG+FFqizUmjPc+UTVpQDKOg2tB25VI08lDkKKRD6jVbHLs8srxzLMMhmtuLaMheJddeFduMBFzAdVIMSFi0JSC1naZ3bVuvetvjiFvg6NqKaju7XSbJstyV6NsS+FvALdrB5VwnPVxMEwjsKp6wAqXtglpy2y9kIaXLfUvEIt0h1cXepKzZFag3NQHQDd3/zfXbCOXd3x1cdJ0ln9IqqUHd1S3VxzWOXgKY1/UmWoRKe7OnEo3d2+3F6l0I3yVcw93d7nXP4A3d4e3T2XUmaGoiaXonhhFJ0AEtscxAdKI9duMm+UVC+lWVjTiBE+DJitzfPN3f/qXI/WUc6s0qdkpfd2KiUUVLh9KmZLLfKcRfcYrgapngc8KIABZgE/hfO9VgASZgM4RfVYGw3fotLpWwqrEwpOIoRR053AQpg5LWIUXDrwGyi2qI/RXfwX3RHQbc/b1hkSphE1ZhFK6vZtWvh/oUHJ7UMu3Ej2DiF/bNGLaoGQYmHfbh0A3fLAbiRZoq7FJcNEphxUUqrHJh/2OaQamKDzGlyyVMKkhVCCz24R7m4hO4qS8+3t5KTMW1Ja76rAsTspxCRmrNEo/U3o/7M0MeGzneYTr24f294zW+rKGKzUaD2KeVsTiLstDCTMxNqxzsqcLy5LeSTMjKjv0tXPaM0Act3C4+K7zSK0p22/viLfb946GjVB2s208uZcWCwF0m5VY1ZdlA5VRmZRg92VY+gV5Gs9LNY0bTruUVKwe+ujhUrWmxOdeCLvxLwCbU5hWblQVYgGIu3GNWZWWurrF05vY14Vk2KmoeLGuGvoU00OcC51cNL99L53vGEnEmZyc1ZwhNZVc+rQZLM1SD5iNWXSdj3P1Sr3nmHv+4dI+Htr6IJrnxoOiX8OcTyGItbs+O3l9xHlODNjVxK5/XdDNcgueJETD+s+iGY7A1hOgCTacDk2cC2OiOduQdDukFGOkpS7JxY1zuIlRAgjKOe0oHbEPLZMGjw8McY2r9w5eczuKdFt+ePjKgPmiTZtcmI6MnGyukHtFfHjQedMsJlFVepJKzJg2qnmPgrWORBjWAC2o2S0tLFioai4A5qzM+47DpTThDC0VDvJPAHhC/Lghx3uj9ZezGduzHhuwTUGyfPmxmbGYCKDYmu2ui5isL42tJQ+xDfEvDXkYxxNs8Q7/XCO3JjuzWdm3GnmzBvk1iQ2hjM+KEVjZmm1z/7OU5QkYlSkvDt7s9OXqVyTbu40bu5J7sAq2fi6BtcVPfhmm1CHg1SZtaRiqysqNV4sbuXBtrRo234lbu8SZvxWZurAO3rdaJffuQjIPVqb3aRv09PAzv+J7UNPY2eaOo7ZQ/cLo3iSvp9WZvfuulkLJAkns3+rY3/f4oeoO3Be8+SErwhLS3AVRAZ6a4lwPH1kU0Nb7VJo5ekNPX6xO4ixbxYyzxFE+5LhQpJrwtl9PwDdc4mrPsybLvSH3qk5NiWFpBHXc7Hlc5rAPscqxVr3E64atp/zry2UtyrsM6oGvyE2M7KyNyRzXyJ1e6oDOvJTdt09pyLDc+L1dyIa9bJgbP5RWFIxIXbu9M8/Z4urAjc7RT8e+ePMez8zvH8zzX8z3Hu4AAACH5BABkAAAALBEADQAdAGYAhf///+v1+Zz3/9/w/8zm/1bj97TI5mjW/z3K8v/CofC1QaHA3auwtNCcjp6qsGOrPzu+/4yhtE+kuDt9TzK5/zK4/yy1/yip+Syl9SWo/zGh7yKb9c91K71qYqtRMOZFOa0vRUxohY9NV5dEBok7DFIzPx53vzo/XisrRQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAj/AAMIHEiwoEAAAAwSRMiwocOEARoqjPiwIkSJCi86PFiRI0KBBAhoxGjRI8SQFlOqNKmy5UeDLh9yzBiTJMSBIVnWvAmSwMESQIMKHYoRZ8iQQ5MKldmTAFARUDtInToVqgigRY8+jUqVqlWgM5tuFdHVK1SwFHk6LVG2rVS0BwmuddsWrkKgdMsCzXmXbV6qe332/Qu4xESBeAm/NTyQ4cDEitFuRFzCKt2vjC2OvXy2hEqloJemDE36M2nQkxmOBcqgdevVnm0CgO36deXOKm0Hrc1gaOuFDnWzru2bweGBDpIrX+6gdXKmBplLd+7g4dHrBCIsj6BdeW3r2I/K/xWss2F48gH41jw/vnzF83yBH28aHibP+ROZwo+ff/J+8i+5F2B62DXG00pGXReTTgah5BKDBeW0U0oFTViSgY5huKCGB+6EX1ojURiAASSWaOKJKKao4ooslmghgiBeKKBjD3L4HnAvyagQerJNNpF4O6IXFkZANigkRSbRV2SFIYJXIE0zGmjfcdANGFZ/RX2IpJYTiUalS6JZaWNFYd7XGIRAPaDmA5JliBKaJazJZmZuiqRZnHKuiVVqd+apZ2xZGgjUBBP4qSahbdI0aKGGIkpnhGsRKumklDpqJVIlVKqppHtCChQIIHwg6qikigrqngFiCmqprH5wKqA3ffIKaqitkjorCJ1Sdmutts6651CgKqAABxwkYOyxxhIr7KtKBTtsscgeq6wCzArVQAPJcmCVCMhuS6yx1w51bbbbdmvVtwmEy1gA1mKbAFDIwptuA0IV1K6x8uJbArj0BuXRve/ue6y86qI6IFDjRsuvXaOVkLDC6sY01rYUG9wwxRhfBSuZeKpp6qyiymkxR2mu+fGqH4i8MckCE2roA4Tq27CxLjc6gb44IjSxqMIKK+q2dtl7G1Q89/wzZoHq6mtQt1oMwHmyVtv0xk9fxx13QnGXnFDfMYSd1g4IlZxwXSN03nbd8eaak1Z3txx1yxkUEAAh+QQAZAAAACwRAE0AHQBmAIX////r9fmc9//f8P/M5v9W4/e0yOZo1v89yvL/wqHwtUGhwN2rsLTQnI6eqrBjqz87vv+MobRPpLg7fU8yuf8yuP8stf8oqfkspfUlqP8xoe8im/XPdSu9amKrUTDmRTmtL0VMaIWPTVeXRAaJOwxSMz8ed786P14rK0UAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI/wADCBxIsKBAAAAMEkTIsKHDhAEaKoz4sCJEiQovOjxYkSNCgQQIaMRo0SPEkBZTqjSpsuVHgy4fcswYkyTEgSFZ1rwJkoDOmgVDChW5E2OAoSiLMsSJdOjPpRSZNs1JsWRVglOz+syIVWvTiQq9Uv06UexWsmC7Oj0qNG1YpD2penRLt+rLumBb0lW6V6nfvy6fWk0puKNdwIQHIjaKF+ZIqI1nHgagtevClJWZXrY41fJkzmjZFm6Y+TLd0op5Rk6N0atbmWyzpt5sOG5byYXVCo2p02BSvZN9+1x8dzRv1sWL0uapvO/LwAEMSJ9Ovbr169iza59O3Ch04583Iv/nTPtp2q0mzYO9Ldxx+thl0c+2a5t9weeYQ5sOf7c4bpreqRZVXuI15t9qAZSgYAkHLmfRggxCdp9LEDK2UG8JlvDAhg8o+B5KGCrIYYclfEhURSKOyKGCsKWUoookwjahghNMAOOGNXo44Iwl1HjjAzmWuGNPNNZo5JFITsCiaiEVmeSTSkYYFAEKggDCB1hmqSWWVi55V5MlWLnlmB90GeFdVVp5JZlaqgnCkgOlKSabWbq5JIRhgqCAAhxwkMCfgP7Z555m4pnmnn0GGuigChQKYQMNCMqBCJSKEGilIiSaAKR4QiopppdWqimnQmaooKcJKBioqps2AGFBj0ajmmoJq9La6qtVxfonq7vaSqqXxZ0qq6K3lsqfsMT+SWpMCmLqbKXAuljCs89G+9CLD3CpJpYjRssRttrO2e2Z+LHq44019irtn+fCmO6syzVbKZZ77oklpjoqJC+l9NZ7L7Tk6puno3aSi9BUcr65YMEPIRXBwxFA+LADDkDIwMUMkDbUxBUvSPHFFmOsMVIUU8wxxihn7NBUHJfswMUuU2xQQAAh+QQAZAAAACwRAI0AWgAmAIX////r9fmc9//f8P/M5v9W4/e0yOZo1v89yvL/wqHwtUGhwN2rsLTQnI6eqrBjqz87vv+MobRPpLg7fU8yuf8yuP8stf8oqfkspfUlqP8xoe8im/XPdSu9amKrUTDmRTmtL0VMaIWPTVeXRAaJOwxSMz8ed786P14rK0UAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI/wADCBxIsKBAAAAMEkTIsKFDhgYMPJxosITFixgvBkCocKLHgwwVFvTYMEDEgSQnZlxpcWPIhSlLuuQoEmVMkwZsxmTIcuXMhAtByvz4UyCBo0hhTowI9CjMpwEuTphKdeqDBxiLAn0o1GFXo0id6nzIFCxUkAKlVqV6NWvJnXBpgg3bFaJErh0fWqx6tW9fi3EDyw0QVuzSu17zOtzL1u/fEjLHxkU7sHBSg2V/DgW6kLFVx35bcq4Ll/LcwgozEx180PME0KFLbKxMgPTkgpZzR0Sa0qBT159hY5VtVnNg37kL7z7aG3dt4K+FD6cdVnBk6smXXyY61/WH7+DDf/9veZq5ddaEkx/Vbpgide/i45NPn9z2S7zlw7IvjJ++RRAAghCffMTRl5t9NPWn3n7VJdZdCQEKOGB4gBGk3oE1XWfaSfm1NxgB/0UIggIKcMBBAigm0EADFWJ3oVgiaejSQBwaSFdRlYUYIYkmpqgiiwVa+GJ+xclIY041JZlWCT6uaKIIUIrg43xCXkhkel+JVKOSIlnUZANPRjllkDVZdppScZ3EHZcWrbjimGNyaWNtBqIJl5ruydmmm3CmCBh6co50Hp6CFbTnm34ymehLgcY4aE7nKWSRiYjGaRyjGeYp6GEGnsfRpBxUumhzSa5pZ0MnNRipRVG2KsKfnkbiuilCW6bnKauuQglrrIXOCkCt5gXGmF9TATgeZAkedymmpdZo2WoNDdtXsRLCiqB7pCr5K5JzQstTCXw9gOJnu/KK3ot04tRUbnC5dtW40VVoLrNzmilQZsm1W0KuUH5HYouN2kSaSPVl1mG6Xe7Lr78K/BmwwMYRfKDB9SJck44iioaQekKeauqc6tKEbn0YR7grx7R5rCmRTIk8MlIRxOzAzD0xYPPNGBY5b5Utv/QyARHMPHMENd9sc85YLtvrXD27/HIAQsvsgNFUb1yfoFzuVFDTmI4ctNAz2wy20AIFBAAh+QQAZAAAACxUAI0AVwAmAIX////r9fmc9//f8P/M5v9W4/e0yOZo1v89yvL/wqHwtUGhwN2rsLTQnI6eqrBjqz87vv+MobRPpLg7fU8yuf8yuP8stf8oqfkspfUlqP8xoe8im/XPdSu9amKrUTDmRTmtL0VMaIWPTVeXRAaJOwxSMz8ed786P14rK0UAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI/wADCBxIkCAAAAULHlzIsOFCAwYcSkxYoqLFixYDHEyoUSJDgR85GvS4MADEgSQlYlxZsePGkSlBlhSJMiXCkzJtLmS50iVCmDM95vxJoKhRoA0hEiUwsmkAixOiSo364MFFnz5fCsUawOjRmhKVCizqVKZAqFOlVr36UadOgl7JZj2o1KFIlSWmVt27t6Lbvz/Hxh36MKJdjnj18u1bIiTgoIG7xpVbUOxcrZFBVlS8mLFGwm7NDpxMmaDlrS8Nblbb2TMAuY9DwiUdF6LRmAXJrubcuiLs2KlH0/Zquyju2U/zpm3NeDLw4IKHF/+6NfruCR+ya9+e3Xfc55klS/83MPhyZKPXuav/4J02aMcNZ5Oe7jy+cAIVQegHsZ57e9LvQSabeJPR95191pWwH3/9adcSgcN9dddMZeEEIXUUdpXfgiAooAAHHCQgYgINNPBghJPRxFWFBtxX3oD4KcihhyCOSKKJJcg3XHRf/QadaS2qKGRFNpYIoghIimDjgzy6d6FgQ9FkoZAiETmikRwkqeSITHKUIoFI6XRSdVRWVGKJS5aQpopfehWmTWNOROVZJZzZQJprzqnic3E+VpCZZ+LJZY560sRni8BxVBGIaNqYwIOH7SlnQiSd5BV4yTF6p6N+TWqop2/S1eKlzyWnpZadgvcXpQxNKdlzFZ3cmmSqqr6lUKtBChfbanxFpV93jcUW4I93WVjfYQ3xupevDNK6qnnEImbsgcgydF1VIlJlVbC1JoQiUwJZRptb1z6Q7QRrNQZtaLmhOJC4pJFbgqxIZuehX4WKFmm7KVrWpIRVzkuvvQp0mi9mA+ropr8XlkbThhyC0NJCX0IJlk3eDlbXUt+mCDGHtFYsWaj7/muSYRx3TEAELDvgMk8MxCyzm8INC5h8G7+k8souuxwBzDLHTLPFtQZnVM4pfxtAzy07EPTTB4ksmqTHhYsyjN9G0HPPMW/ds0ABAQAh+QQAZAAAACyRAI0AHQBmAIX////r9fmc9//f8P/M5v9W4/e0yOZo1v89yvL/wqHwtUGhwN2rsLTQnI6eqrBjqz87vv+MobRPpLg7fU8yuf8yuP8stf8oqfkspfUlqP8xoe8im/XPdSu9amKrUTDmRTmtL0VMaIWPTVeXRAaJOwxSMz8ed786P14rK0UAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI/wADCBxIsKBAAAAMEkTIsKHDhAEaKoz4sCJEiQovOjxYkSNCgQQIaMRo0SPEkBZTqjSpsuVHgy4fcswYkyTEgSFZ1rwJkoDOmgVDChW5E2OAoSiLMsSJdOjPpRSZNs1JsWRVglOz+syIVWvTiQq9Uv06UexWsmC7Oj0qNG1YpD2penRLt+rLumBb0lW6V6nfvy6fWk0puKNdwIQHIjaKF+ZIqI1nHgagtevClJWZXrY41fJkzmjZFm6Y+TLd0op5Rk6N0atbmWyzpt5sOG5byYXVCo2p02BSvZN9+1x8dzRv1sWL0uapvO/LwAEMSJ9Ovbr169iza59O3Ch04583Iv/nTPtp2q0mzYO9Ldxx+thl0c+2a5t9weeYQ5sOf7c4bpreqRZVXuI15t9qAZSgYAkHLmfRggxCdp9LEDK2UG8JlvDAhg8o+B5KGCrIYYclfEhURSKOyKGCsKWUoookwjahghNMAOOGNXo44Iwl1HjjAzmWuGNPNNZo5JFITsCiaiEVmeSTSkYYFAEKggDCB1hmqSWWVi55V5MlWLnlmB90GeFdVVp5JZlaqgnCkgOlKSabWbq5JIRhgqCAAhxwkMCfgP7Z555m4pnmnn0GGuigChQKYQMNCMqBCJSKEGilIiSaAKR4QiopppdWqimnQmaooKcJKBioqps2AGFBj0ajmmoJq9La6qtVxfonq7vaSqqXxZ0qq6K3lsqfsMT+SWpMCmLqbKXAuljCs89G+9CLD3CpJpYjRssRttrO2e2Z+LHq44019irtn+fCmO6syzVbKZZ77oklpjoqJC+l9NZ7L7Tk6puno3aSi9BUcr65YMEPIRXBwxFA+LADDkDIwMUMkDbUxBUvSPHFFmOsMVIUU8wxxihn7NBUHJfswMUuU2xQQAAh+QQAZAAAACyRAM0AWgAmAIX////r9fmc9//f8P/M5v9W4/e0yOZo1v89yvL/wqHwtUGrsLShwN2eqrA7vv9PpLhjqz8yuf8yuP8stf8oqfkspfUlqP/QnI7PdSu9amKMobQ7fU8xoe8im/Ued7/mRTmrUTCtL0WNXDOPTVeXRAaJOwx3RjZSMz9MaIU+VGo6P14rK0UAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI/wADCBxIsKBAAAAMEkTIsKFDhgYMPJxo8ITFixgvBkCocKLHgwwVFvTYMEDEgSQnZlxpcWPIgSBSOgTJUSRKmSYN3JTJkOVKlzUFxqT58iPQhAEIKF260GNEpEqbElShAgSIixuyas0KAQLGqlZBKED6kGjJowKXMt358GlaAlIHUrWKdavWrl/DiuXJN2hStXCPQpRYtuBcsQoSK7C4tatjxxYVj+3LkyDgwBOfFp4KVvLiE40fQz4heSTlmn4vRzXoVvDLw4kxYLgK+q7ox5FBmD4N0rJqha2NwlYgm3bo23hJ635rlrJB1ZcjLk15WHZsxnaRjx64+vRZ39CXSv9XSh2sdeLYjyNv+Vat95fgoY9f+7C6bNnpN3zYz7//fvZ/ufceUvGpNl93Dtl3X37+NfgBgOFhRlJzBap1IGANUfXAA1aV4KFFIYQYgoP+QRhec2dtFmB0BoSXoQobdvjhCSKOSCJ/FhG4YoSrifTdTQOd1B5gAmm44ZEogFhjCLFhkMCTCVxwQY4VRmgTWqYFqdOQahUJ45EbJknjkk1CGeWUJyjEY2CXMYclcFteGYCRYH5mppSyjaDnCGYCWCWRO7IpoV8FCSknnUfaCSWeGOzJJ5R+2tTmik1RdpJRXtYpmUVSStnnCZ/KyaWgPbom06UUyfXlhp5x2umnn8L/J6pNA6JaHgoo3HcfbZ1eACukJ8g6a0fv2UoSVbjqWhwIYsrmqZkJWJTrhHJiultbOglYnwq4dpsrBsha5Kyv0EqLArVXWlsptit6hKy334Z7gqOOmovrgLxdC4Chb3m0wgpUBSywRfTuaZHA+DqnL79/+QuwwFRh91hWIf53AlVkKZzSsPvGedlD/8KLq8SOUWyjuRn3haKwtBr6sUMhi5xfV09y5dUJ9ybM8ppaQqVaQzHDOzMENW+QXM466zjqpDn5/DJCQXtLcMEj7JeYucNm6ZpI0DX9p0D/KovfvFRb/ZlsWcel4tetLR1Y2GKPvaSI4t53IneBrbx2oE3XZgQdAwzAHbeSc9ct291u6j1TQW1q5jRggAsumwiUU26CTyZUTvlveCuuMt4EOO435IGvAG8KqKfuU+qpc+5m0jqKR9hLl0Vuusisp6A55bnjijiQ1eJEkOiyKmW7yCjkvrsIvaMQEAA7\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}