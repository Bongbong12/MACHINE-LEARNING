{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bongbong12/MACHINE-LEARNING/blob/main/FrozenLake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2Bw_wXXQKaf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyglet==1.5.1\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gym==0.24\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "\n",
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "id": "oYbPDSFYQhwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twtBNh1WQ3EF",
        "outputId": "75312e4f-8dc1-4ccf-8fed-59d0b5fb3b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_map = [\n",
        "    \"HFFFS\",\n",
        "    \"HFHFF\",\n",
        "    \"FHFFF\",\n",
        "    \"GFFFH\"\n",
        "]\n",
        "\n",
        "env = gym.make('FrozenLake-v1', desc=my_map, is_slippery=False)\n",
        "env.render()\n",
        "env.reset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-hUKLnhQ_pf",
        "outputId": "d3a41976-29ec-42e5-db7a-b732251adeb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "print(f'action_space_size = {action_space_size}')\n",
        "print(f'state_space_size = {state_space_size}')\n",
        "print(f'q_table = \\n{q_table}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoAGkxOCUCej",
        "outputId": "dfac2d28-9c98-4398-db98-9b2f4c2560a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_space_size = 4\n",
            "state_space_size = 20\n",
            "q_table = \n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "num_episodes = 1000\n",
        "max_steps_per_episode = 100\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "\n",
        "exploration_rate =1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.05"
      ],
      "metadata": {
        "id": "ravyEYVNVXsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_all_episodes = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "  state = env.reset()\n",
        "  state = 0\n",
        "  done = False\n",
        "  reward_current_episode = 0\n",
        "\n",
        "  for step in range(max_steps_per_episode):\n",
        "    exploration_rate_threshold = random.uniform(0, 1)\n",
        "    if exploration_rate_threshold > exploration_rate:\n",
        "      action = np.argmax(q_table[state, :])\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    delta_q = ( 1 - learning_rate)+  learning_rate*(reward + discount_rate*np.max(q_table[new_state, :]))\n",
        "\n",
        "    print(f\"We are on {episode} episode and {step} step\")\n",
        "    print(f\"Delta Q = {delta_q}\")\n",
        "    print(f\"Q_table[{state},{action}]_old = {q_table[state, action]}\")\n",
        "\n",
        "    q_table[state, action] = q_table[state, action]*(1 - learning_rate)+\\\n",
        "                            learning_rate*(reward+discount_rate*np.max(q_table[new_state, :]))\n",
        "    print(f\"Q_table[{state, action}]_new = {q_table[state, action]}\")\n",
        "    print(f\"We are on {state} state\")\n",
        "    state = new_state\n",
        "    print(f\"And now we are on {state} state\")\n",
        "    reward_current_episode+= reward\n",
        "    print(f\"We get {reward} reward \")\n",
        "    print(f\"exploration_rate = {exploration_rate}\\n\")\n",
        "\n",
        "    if done == True:\n",
        "        break\n",
        "\n",
        "exploration_rate = min_exploration_rate +\\\n",
        "                 (max_exploration_rate - min_exploration_rate)*np.exp(-exploration_decay_rate*episode)\n",
        "rewards_all_episodes.append(reward_current_episode)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nr48_17XqBk",
        "outputId": "b9364ca8-d327-4586-d381-1ed70b9125cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 15 step\n",
            "Delta Q = 0.9511999897036648\n",
            "Q_table[4,2]_old = 0.5084135977851084\n",
            "Q_table[(4, 2)]_new = 0.5087722277102624\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 16 step\n",
            "Delta Q = 0.9511999897036648\n",
            "Q_table[4,2]_old = 0.5087722277102624\n",
            "Q_table[(4, 2)]_new = 0.509094994642901\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 17 step\n",
            "Delta Q = 0.9511999897036648\n",
            "Q_table[4,2]_old = 0.509094994642901\n",
            "Q_table[(4, 2)]_new = 0.5093854848822758\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 18 step\n",
            "Delta Q = 0.9511999897036648\n",
            "Q_table[4,3]_old = 0.5085120860281068\n",
            "Q_table[(4, 3)]_new = 0.508860867128961\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 19 step\n",
            "Delta Q = 0.9518911726798056\n",
            "Q_table[4,1]_old = 0.5121728627043132\n",
            "Q_table[(4, 1)]_new = 0.5128467491136874\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 20 step\n",
            "Delta Q = 0.9518911726798056\n",
            "Q_table[9,2]_old = 0.5070509134859772\n",
            "Q_table[(9, 2)]_new = 0.5082369948171851\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 21 step\n",
            "Delta Q = 0.9536889777605217\n",
            "Q_table[9,0]_old = 0.5241532593919755\n",
            "Q_table[(9, 0)]_new = 0.5254269112132998\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 22 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 0 step\n",
            "Delta Q = 0.95221083046809\n",
            "Q_table[0,0]_old = 0.49711070789549017\n",
            "Q_table[(0, 0)]_new = 0.49961046757403116\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 1 step\n",
            "Delta Q = 0.9511999897036648\n",
            "Q_table[3,2]_old = 0.5037306132886674\n",
            "Q_table[(3, 2)]_new = 0.5045575416634656\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 2 step\n",
            "Delta Q = 0.9520172642101167\n",
            "Q_table[4,1]_old = 0.5128467491136874\n",
            "Q_table[(4, 1)]_new = 0.5135793384124354\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 3 step\n",
            "Delta Q = 0.9524328057707678\n",
            "Q_table[9,1]_old = 0.5181258533846465\n",
            "Q_table[(9, 1)]_new = 0.5187460738169497\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 4 step\n",
            "Delta Q = 0.9560429046549523\n",
            "Q_table[14,0]_old = 0.5296243007148268\n",
            "Q_table[(14, 0)]_new = 0.5327047752982965\n",
            "We are on 14 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 5 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[13,2]_old = 0.478453440092672\n",
            "Q_table[(13, 2)]_new = 0.4833458688379361\n",
            "We are on 13 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 6 step\n",
            "Delta Q = 0.9520172642101167\n",
            "Q_table[14,3]_old = 0.49689281596181895\n",
            "Q_table[(14, 3)]_new = 0.49922079857575374\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 7 step\n",
            "Delta Q = 0.9520172642101167\n",
            "Q_table[9,2]_old = 0.5082369948171851\n",
            "Q_table[(9, 2)]_new = 0.5094305595455833\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 8 step\n",
            "Delta Q = 0.9536889777605217\n",
            "Q_table[9,0]_old = 0.5254269112132998\n",
            "Q_table[(9, 0)]_new = 0.5265731978524916\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 9 step\n",
            "Delta Q = 0.9560429046549523\n",
            "Q_table[8,1]_old = 0.542312906671937\n",
            "Q_table[(8, 1)]_new = 0.5441245206596956\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 10 step\n",
            "Delta Q = 0.9594481743956333\n",
            "Q_table[13,1]_old = 0.5660899460096196\n",
            "Q_table[(13, 1)]_new = 0.568929125804291\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 11 step\n",
            "Delta Q = 0.9563239834546249\n",
            "Q_table[18,3]_old = 0.41407297265518345\n",
            "Q_table[(18, 3)]_new = 0.4289896588442899\n",
            "We are on 18 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 12 step\n",
            "Delta Q = 0.9594481743956333\n",
            "Q_table[13,1]_old = 0.568929125804291\n",
            "Q_table[(13, 1)]_new = 0.5714843876194953\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 13 step\n",
            "Delta Q = 0.9565769543743301\n",
            "Q_table[18,3]_old = 0.4289896588442899\n",
            "Q_table[(18, 3)]_new = 0.44266764733419095\n",
            "We are on 18 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 14 step\n",
            "Delta Q = 0.9594481743956333\n",
            "Q_table[13,1]_old = 0.5714843876194953\n",
            "Q_table[(13, 1)]_new = 0.5737841232531791\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 15 step\n",
            "Delta Q = 0.9594481743956333\n",
            "Q_table[18,1]_old = 0.5093156368428233\n",
            "Q_table[(18, 1)]_new = 0.5178322475541743\n",
            "We are on 18 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 16 step\n",
            "Delta Q = 0.9594481743956333\n",
            "Q_table[18,1]_old = 0.5178322475541743\n",
            "Q_table[(18, 1)]_new = 0.5254971971943903\n",
            "We are on 18 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 17 step\n",
            "Delta Q = 0.9594481743956333\n",
            "Q_table[18,1]_old = 0.5254971971943903\n",
            "Q_table[(18, 1)]_new = 0.5323956518705846\n",
            "We are on 18 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 18 step\n",
            "Delta Q = 0.965271552710033\n",
            "Q_table[18,0]_old = 0.600486610056902\n",
            "Q_table[(18, 0)]_new = 0.6057095017612447\n",
            "We are on 18 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 19 step\n",
            "Delta Q = 0.954648048604115\n",
            "Q_table[17,3]_old = 0.443601696629718\n",
            "Q_table[(17, 3)]_new = 0.4538895755708612\n",
            "We are on 17 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 20 step\n",
            "Delta Q = 0.9\n",
            "Q_table[12,3]_old = 0.0\n",
            "Q_table[(12, 3)]_new = 0.0\n",
            "We are on 12 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 0 step\n",
            "Delta Q = 0.9511999897036648\n",
            "Q_table[0,2]_old = 0.4871204207179272\n",
            "Q_table[(0, 2)]_new = 0.48960836834979937\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 1 step\n",
            "Delta Q = 0.9511999897036648\n",
            "Q_table[4,3]_old = 0.508860867128961\n",
            "Q_table[(4, 3)]_new = 0.5091747701197297\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 2 step\n",
            "Delta Q = 0.9521307465873967\n",
            "Q_table[4,1]_old = 0.5135793384124354\n",
            "Q_table[(4, 1)]_new = 0.5143521511585886\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 3 step\n",
            "Delta Q = 0.9511999897036648\n",
            "Q_table[9,3]_old = 0.5013187995366671\n",
            "Q_table[(9, 3)]_new = 0.5023869092866653\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 4 step\n",
            "Delta Q = 0.9521307465873967\n",
            "Q_table[4,1]_old = 0.5143521511585886\n",
            "Q_table[(4, 1)]_new = 0.5150476826301263\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 5 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[9,1]_old = 0.5187460738169497\n",
            "Q_table[(9, 1)]_new = 0.5196092391897861\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 6 step\n",
            "Delta Q = 0.9521307465873967\n",
            "Q_table[14,3]_old = 0.49922079857575374\n",
            "Q_table[(14, 3)]_new = 0.5014294653055751\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 7 step\n",
            "Delta Q = 0.9511999897036648\n",
            "Q_table[9,3]_old = 0.5023869092866653\n",
            "Q_table[(9, 3)]_new = 0.5033482080616636\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 8 step\n",
            "Delta Q = 0.95221083046809\n",
            "Q_table[4,0]_old = 0.5171716131683316\n",
            "Q_table[(4, 0)]_new = 0.5176652823195884\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 9 step\n",
            "Delta Q = 0.9538683275453099\n",
            "Q_table[3,1]_old = 0.5273821259403029\n",
            "Q_table[(3, 1)]_new = 0.5285122408915824\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 10 step\n",
            "Delta Q = 0.9521307465873967\n",
            "Q_table[8,2]_old = 0.5052706988837428\n",
            "Q_table[(8, 2)]_new = 0.5068743755827652\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 11 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[9,1]_old = 0.5196092391897861\n",
            "Q_table[(9, 1)]_new = 0.5203860880253388\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 12 step\n",
            "Delta Q = 0.9521307465873967\n",
            "Q_table[14,3]_old = 0.5014294653055751\n",
            "Q_table[(14, 3)]_new = 0.5034172653624143\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 13 step\n",
            "Delta Q = 0.9521307465873967\n",
            "Q_table[9,2]_old = 0.5094305595455833\n",
            "Q_table[(9, 2)]_new = 0.5106182501784216\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 14 step\n",
            "Delta Q = 0.9512488629496393\n",
            "Q_table[9,3]_old = 0.5033482080616636\n",
            "Q_table[(9, 3)]_new = 0.5042622502051365\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 15 step\n",
            "Delta Q = 0.9512488629496393\n",
            "Q_table[4,2]_old = 0.5093854848822758\n",
            "Q_table[(4, 2)]_new = 0.5096957993436875\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 16 step\n",
            "Delta Q = 0.9512488629496393\n",
            "Q_table[4,3]_old = 0.5091747701197297\n",
            "Q_table[(4, 3)]_new = 0.5095061560573959\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 17 step\n",
            "Delta Q = 0.9512488629496393\n",
            "Q_table[4,3]_old = 0.5095061560573959\n",
            "Q_table[(4, 3)]_new = 0.5098044034012955\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 18 step\n",
            "Delta Q = 0.9512488629496393\n",
            "Q_table[4,2]_old = 0.5096957993436875\n",
            "Q_table[(4, 2)]_new = 0.5099750823589579\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 19 step\n",
            "Delta Q = 0.9512488629496393\n",
            "Q_table[4,2]_old = 0.5099750823589579\n",
            "Q_table[(4, 2)]_new = 0.5102264370727014\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 20 step\n",
            "Delta Q = 0.9521307465873967\n",
            "Q_table[4,1]_old = 0.5150476826301263\n",
            "Q_table[(4, 1)]_new = 0.5156736609545104\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 21 step\n",
            "Delta Q = 0.9538683275453099\n",
            "Q_table[9,0]_old = 0.5265731978524916\n",
            "Q_table[(9, 0)]_new = 0.5277842056125523\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 22 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 0 step\n",
            "Delta Q = 0.9522506363556427\n",
            "Q_table[0,1]_old = 0.5017623658758652\n",
            "Q_table[(0, 1)]_new = 0.5038367656439213\n",
            "We are on 0 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 1 step\n",
            "Delta Q = 0.9522506363556427\n",
            "Q_table[9,2]_old = 0.5106182501784216\n",
            "Q_table[(9, 2)]_new = 0.5118070615162221\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 2 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[9,1]_old = 0.5203860880253388\n",
            "Q_table[(9, 1)]_new = 0.5210852519773364\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[14,1]_old = 0.0\n",
            "Q_table[(14, 1)]_new = 0.0\n",
            "We are on 14 state\n",
            "And now we are on 19 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 0 step\n",
            "Delta Q = 0.9512488629496393\n",
            "Q_table[0,3]_old = 0.4941593354025273\n",
            "Q_table[(0, 3)]_new = 0.4959922648119139\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 1 step\n",
            "Delta Q = 0.9512488629496393\n",
            "Q_table[4,3]_old = 0.5098044034012955\n",
            "Q_table[(4, 3)]_new = 0.5100728260108052\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 2 step\n",
            "Delta Q = 0.9512488629496393\n",
            "Q_table[4,3]_old = 0.5100728260108052\n",
            "Q_table[(4, 3)]_new = 0.5103144063593639\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 3 step\n",
            "Delta Q = 0.9512488629496393\n",
            "Q_table[4,3]_old = 0.5103144063593639\n",
            "Q_table[(4, 3)]_new = 0.5105318286730667\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 4 step\n",
            "Delta Q = 0.9512488629496393\n",
            "Q_table[4,2]_old = 0.5102264370727014\n",
            "Q_table[(4, 2)]_new = 0.5104526563150705\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 5 step\n",
            "Delta Q = 0.9523227118482667\n",
            "Q_table[4,0]_old = 0.5176652823195884\n",
            "Q_table[(4, 0)]_new = 0.5182214659358962\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 6 step\n",
            "Delta Q = 0.9538683275453099\n",
            "Q_table[3,1]_old = 0.5285122408915824\n",
            "Q_table[(3, 1)]_new = 0.5295293443477341\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 7 step\n",
            "Delta Q = 0.9568046282020648\n",
            "Q_table[8,1]_old = 0.5441245206596956\n",
            "Q_table[(8, 1)]_new = 0.5465166967957908\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 8 step\n",
            "Delta Q = 0.9541051529827833\n",
            "Q_table[13,3]_old = 0.5037546985233393\n",
            "Q_table[(13, 3)]_new = 0.5074843816537886\n",
            "We are on 13 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 9 step\n",
            "Delta Q = 0.9568046282020648\n",
            "Q_table[8,1]_old = 0.5465166967957908\n",
            "Q_table[(8, 1)]_new = 0.5486696553182765\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 10 step\n",
            "Delta Q = 0.9599652406743633\n",
            "Q_table[13,1]_old = 0.5737841232531791\n",
            "Q_table[(13, 1)]_new = 0.5763709516022244\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 11 step\n",
            "Delta Q = 0.9599652406743633\n",
            "Q_table[18,1]_old = 0.5323956518705846\n",
            "Q_table[(18, 1)]_new = 0.5391213273578893\n",
            "We are on 18 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 12 step\n",
            "Delta Q = 0.9599652406743633\n",
            "Q_table[18,1]_old = 0.5391213273578893\n",
            "Q_table[(18, 1)]_new = 0.5451744352964636\n",
            "We are on 18 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 13 step\n",
            "Delta Q = 0.9570607242086202\n",
            "Q_table[18,3]_old = 0.44266764733419095\n",
            "Q_table[(18, 3)]_new = 0.4554616068093921\n",
            "We are on 18 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 14 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[13,2]_old = 0.4833458688379361\n",
            "Q_table[(13, 2)]_new = 0.48774905470867386\n",
            "We are on 13 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 15 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[14,2]_old = 0.5088582421223427\n",
            "Q_table[(14, 2)]_new = 0.5107101906646397\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 16 step\n",
            "Delta Q = 0.9\n",
            "Q_table[14,1]_old = 0.0\n",
            "Q_table[(14, 1)]_new = 0.0\n",
            "We are on 14 state\n",
            "And now we are on 19 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 0 step\n",
            "Delta Q = 0.9513039251276537\n",
            "Q_table[0,2]_old = 0.48960836834979937\n",
            "Q_table[(0, 2)]_new = 0.4919514566424732\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 1 step\n",
            "Delta Q = 0.9513039251276537\n",
            "Q_table[4,3]_old = 0.5105318286730667\n",
            "Q_table[(4, 3)]_new = 0.5107825709334137\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 2 step\n",
            "Delta Q = 0.9513039251276537\n",
            "Q_table[4,3]_old = 0.5107825709334137\n",
            "Q_table[(4, 3)]_new = 0.5110082389677261\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 3 step\n",
            "Delta Q = 0.9522506363556427\n",
            "Q_table[4,1]_old = 0.5156736609545104\n",
            "Q_table[(4, 1)]_new = 0.516356931214702\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 4 step\n",
            "Delta Q = 0.9543182958765094\n",
            "Q_table[9,0]_old = 0.5277842056125523\n",
            "Q_table[(9, 0)]_new = 0.5293240809278065\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 5 step\n",
            "Delta Q = 0.9570607242086202\n",
            "Q_table[8,1]_old = 0.5486696553182765\n",
            "Q_table[(8, 1)]_new = 0.5508634139950691\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 6 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[13,3]_old = 0.5074843816537886\n",
            "Q_table[(13, 3)]_new = 0.5112714214739216\n",
            "We are on 13 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 0 step\n",
            "Delta Q = 0.9513039251276537\n",
            "Q_table[0,2]_old = 0.4919514566424732\n",
            "Q_table[(0, 2)]_new = 0.4940602361058796\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 1 step\n",
            "Delta Q = 0.9524030840118529\n",
            "Q_table[4,1]_old = 0.516356931214702\n",
            "Q_table[(4, 1)]_new = 0.5171243221050847\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 2 step\n",
            "Delta Q = 0.9524030840118529\n",
            "Q_table[9,2]_old = 0.5118070615162221\n",
            "Q_table[(9, 2)]_new = 0.5130294393764527\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 3 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[9,0]_old = 0.5293240809278065\n",
            "Q_table[(9, 0)]_new = 0.5309271508205377\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 0 step\n",
            "Delta Q = 0.9525617879312333\n",
            "Q_table[0,1]_old = 0.5038367656439213\n",
            "Q_table[(0, 1)]_new = 0.5060148770107624\n",
            "We are on 0 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 1 step\n",
            "Delta Q = 0.9525617879312333\n",
            "Q_table[9,2]_old = 0.5130294393764527\n",
            "Q_table[(9, 2)]_new = 0.5142882833700406\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 2 step\n",
            "Delta Q = 0.9525617879312333\n",
            "Q_table[9,2]_old = 0.5142882833700406\n",
            "Q_table[(9, 2)]_new = 0.5154212429642697\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 3 step\n",
            "Delta Q = 0.9525617879312333\n",
            "Q_table[9,2]_old = 0.5154212429642697\n",
            "Q_table[(9, 2)]_new = 0.516440906599076\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 4 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[9,1]_old = 0.5210852519773364\n",
            "Q_table[(9, 1)]_new = 0.5217144995341341\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[14,1]_old = 0.0\n",
            "Q_table[(14, 1)]_new = 0.0\n",
            "We are on 14 state\n",
            "And now we are on 19 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 0 step\n",
            "Delta Q = 0.9513039251276537\n",
            "Q_table[0,2]_old = 0.4940602361058796\n",
            "Q_table[(0, 2)]_new = 0.49595813762294544\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 1 step\n",
            "Delta Q = 0.9524234050904257\n",
            "Q_table[4,0]_old = 0.5182214659358962\n",
            "Q_table[(4, 0)]_new = 0.5188227244327323\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 2 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[3,1]_old = 0.5295293443477341\n",
            "Q_table[(3, 1)]_new = 0.5311118878984726\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 3 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[8,3]_old = 0.4959362723742593\n",
            "Q_table[(8, 3)]_new = 0.4989227220387822\n",
            "We are on 8 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 4 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[3,3]_old = 0.5091625610390733\n",
            "Q_table[(3, 3)]_new = 0.5108263818371148\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 5 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[3,3]_old = 0.5108263818371148\n",
            "Q_table[(3, 3)]_new = 0.5123238205553522\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 6 step\n",
            "Delta Q = 0.9513634497188406\n",
            "Q_table[3,2]_old = 0.5045575416634656\n",
            "Q_table[(3, 2)]_new = 0.5054652372159595\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 7 step\n",
            "Delta Q = 0.9525617879312333\n",
            "Q_table[4,1]_old = 0.5171243221050847\n",
            "Q_table[(4, 1)]_new = 0.5179736778258095\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 8 step\n",
            "Delta Q = 0.9513634497188406\n",
            "Q_table[9,3]_old = 0.5042622502051365\n",
            "Q_table[(9, 3)]_new = 0.5051994749034634\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 9 step\n",
            "Delta Q = 0.9513634497188406\n",
            "Q_table[4,3]_old = 0.5110082389677261\n",
            "Q_table[(4, 3)]_new = 0.5112708647897939\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 10 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[4,0]_old = 0.5188227244327323\n",
            "Q_table[(4, 0)]_new = 0.5195205288914079\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 11 step\n",
            "Delta Q = 0.9473203062665412\n",
            "Q_table[3,0]_old = 0.45702910573507416\n",
            "Q_table[(3, 0)]_new = 0.4586465014281079\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 12 step\n",
            "Delta Q = 0.9396359156544567\n",
            "Q_table[2,0]_old = 0.36600965198002305\n",
            "Q_table[(2, 0)]_new = 0.36904460243647746\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 13 step\n",
            "Delta Q = 0.9082167118253205\n",
            "Q_table[1,1]_old = 0.040219205579767735\n",
            "Q_table[(1, 1)]_new = 0.044413996847111406\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 14 step\n",
            "Delta Q = 0.9396359156544567\n",
            "Q_table[6,3]_old = 0.08299708914465098\n",
            "Q_table[(6, 3)]_new = 0.11433329588464261\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 15 step\n",
            "Delta Q = 0.9473203062665412\n",
            "Q_table[1,2]_old = 0.39485448565488196\n",
            "Q_table[(1, 2)]_new = 0.4026893433559349\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 16 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[2,2]_old = 0.4779828915812237\n",
            "Q_table[(2, 2)]_new = 0.4827646793250502\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 17 step\n",
            "Delta Q = 0.94779370325318\n",
            "Q_table[3,0]_old = 0.4586465014281079\n",
            "Q_table[(3, 0)]_new = 0.4605755545384771\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 18 step\n",
            "Delta Q = 0.9398662449922376\n",
            "Q_table[2,0]_old = 0.36904460243647746\n",
            "Q_table[(2, 0)]_new = 0.3720063871850673\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 19 step\n",
            "Delta Q = 0.94779370325318\n",
            "Q_table[1,2]_old = 0.4026893433559349\n",
            "Q_table[(1, 2)]_new = 0.41021411227352145\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 20 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[2,2]_old = 0.4827646793250502\n",
            "Q_table[(2, 2)]_new = 0.487068288294494\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 21 step\n",
            "Delta Q = 0.948219760541155\n",
            "Q_table[3,0]_old = 0.4605755545384771\n",
            "Q_table[(3, 0)]_new = 0.4627377596257843\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 22 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[2,2]_old = 0.487068288294494\n",
            "Q_table[(2, 2)]_new = 0.49094153636699345\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 23 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[3,3]_old = 0.5123238205553522\n",
            "Q_table[(3, 3)]_new = 0.5136715154017658\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 24 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[3,3]_old = 0.5136715154017658\n",
            "Q_table[(3, 3)]_new = 0.514884440763538\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 25 step\n",
            "Delta Q = 0.9514325323602494\n",
            "Q_table[3,2]_old = 0.5054652372159595\n",
            "Q_table[(3, 2)]_new = 0.5063512458546129\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 26 step\n",
            "Delta Q = 0.9525617879312333\n",
            "Q_table[4,1]_old = 0.5179736778258095\n",
            "Q_table[(4, 1)]_new = 0.5187380979744618\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 27 step\n",
            "Delta Q = 0.9514325323602494\n",
            "Q_table[9,3]_old = 0.5051994749034634\n",
            "Q_table[(9, 3)]_new = 0.5061120597733665\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 28 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[4,0]_old = 0.5195205288914079\n",
            "Q_table[(4, 0)]_new = 0.5201485529042159\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 29 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[3,3]_old = 0.514884440763538\n",
            "Q_table[(3, 3)]_new = 0.515976073589133\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 30 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[3,3]_old = 0.515976073589133\n",
            "Q_table[(3, 3)]_new = 0.5169585431321685\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 31 step\n",
            "Delta Q = 0.9525800769019488\n",
            "Q_table[3,3]_old = 0.5169585431321685\n",
            "Q_table[(3, 3)]_new = 0.5178427657209005\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 32 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[3,1]_old = 0.5311118878984726\n",
            "Q_table[(3, 1)]_new = 0.5325361770941373\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 33 step\n",
            "Delta Q = 0.9527210815323196\n",
            "Q_table[8,3]_old = 0.4989227220387822\n",
            "Q_table[(8, 3)]_new = 0.5017515313672236\n",
            "We are on 8 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 34 step\n",
            "Delta Q = 0.9486032121003324\n",
            "Q_table[3,0]_old = 0.4627377596257843\n",
            "Q_table[(3, 0)]_new = 0.4650671957635382\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 35 step\n",
            "Delta Q = 0.9527210815323196\n",
            "Q_table[2,2]_old = 0.49094153636699345\n",
            "Q_table[(2, 2)]_new = 0.4945684642626137\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 36 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[3,0]_old = 0.4650671957635382\n",
            "Q_table[(3, 0)]_new = 0.46752275414918315\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 37 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[2,3]_old = 0.4327231269880854\n",
            "Q_table[(2, 3)]_new = 0.4384130922512756\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 38 step\n",
            "Delta Q = 0.9406111971150787\n",
            "Q_table[2,0]_old = 0.3720063871850673\n",
            "Q_table[(2, 0)]_new = 0.3754169455816392\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 39 step\n",
            "Delta Q = 0.9113189962925796\n",
            "Q_table[1,1]_old = 0.044413996847111406\n",
            "Q_table[(1, 1)]_new = 0.051291593454979884\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 40 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 0 step\n",
            "Delta Q = 0.9525617879312333\n",
            "Q_table[0,1]_old = 0.5060148770107624\n",
            "Q_table[(0, 1)]_new = 0.5079751772409193\n",
            "We are on 0 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 1 step\n",
            "Delta Q = 0.9525617879312333\n",
            "Q_table[9,2]_old = 0.516440906599076\n",
            "Q_table[(9, 2)]_new = 0.5173586038704017\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 2 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[9,0]_old = 0.5309271508205377\n",
            "Q_table[(9, 0)]_new = 0.5323699137239957\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 3 step\n",
            "Delta Q = 0.9527046214586756\n",
            "Q_table[8,2]_old = 0.5068743755827652\n",
            "Q_table[(8, 2)]_new = 0.5088915594831642\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 4 step\n",
            "Delta Q = 0.9514947067375173\n",
            "Q_table[9,3]_old = 0.5061120597733665\n",
            "Q_table[(9, 3)]_new = 0.5069955605335472\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 5 step\n",
            "Delta Q = 0.9514947067375173\n",
            "Q_table[4,2]_old = 0.5104526563150705\n",
            "Q_table[(4, 2)]_new = 0.5109020974210808\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 6 step\n",
            "Delta Q = 0.9527046214586756\n",
            "Q_table[4,1]_old = 0.5187380979744618\n",
            "Q_table[(4, 1)]_new = 0.5195689096356912\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 7 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[9,0]_old = 0.5323699137239957\n",
            "Q_table[(9, 0)]_new = 0.5336684003371079\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 8 step\n",
            "Delta Q = 0.9528331716333737\n",
            "Q_table[8,2]_old = 0.5088915594831642\n",
            "Q_table[(8, 2)]_new = 0.5108355751682215\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 9 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[9,0]_old = 0.5336684003371079\n",
            "Q_table[(9, 0)]_new = 0.5348370382889089\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 0 step\n",
            "Delta Q = 0.9514947067375173\n",
            "Q_table[0,2]_old = 0.49595813762294544\n",
            "Q_table[(0, 2)]_new = 0.49785703059816827\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 1 step\n",
            "Delta Q = 0.9514947067375173\n",
            "Q_table[4,3]_old = 0.5112708647897939\n",
            "Q_table[(4, 3)]_new = 0.5116384850483319\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 2 step\n",
            "Delta Q = 0.9514947067375173\n",
            "Q_table[4,2]_old = 0.5109020974210808\n",
            "Q_table[(4, 2)]_new = 0.5113065944164901\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 3 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[4,1]_old = 0.5195689096356912\n",
            "Q_table[(4, 1)]_new = 0.5205608854627242\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 4 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[9,2]_old = 0.5173586038704017\n",
            "Q_table[(9, 2)]_new = 0.5185716102739635\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 5 step\n",
            "Delta Q = 0.9515355276608097\n",
            "Q_table[9,3]_old = 0.5069955605335472\n",
            "Q_table[(9, 3)]_new = 0.5078315321410022\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 6 step\n",
            "Delta Q = 0.9515355276608097\n",
            "Q_table[4,3]_old = 0.5116384850483319\n",
            "Q_table[(4, 3)]_new = 0.5120101642043083\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 7 step\n",
            "Delta Q = 0.9527210815323196\n",
            "Q_table[4,0]_old = 0.5201485529042159\n",
            "Q_table[(4, 0)]_new = 0.5208547791461139\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 8 step\n",
            "Delta Q = 0.9527210815323196\n",
            "Q_table[3,3]_old = 0.5178427657209005\n",
            "Q_table[(3, 3)]_new = 0.51877957068113\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 9 step\n",
            "Delta Q = 0.9515646231354653\n",
            "Q_table[3,2]_old = 0.5063512458546129\n",
            "Q_table[(3, 2)]_new = 0.5072807444046169\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 10 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[4,1]_old = 0.5205608854627242\n",
            "Q_table[(4, 1)]_new = 0.5214536637070537\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 11 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[9,2]_old = 0.5185716102739635\n",
            "Q_table[(9, 2)]_new = 0.5196633160371691\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 12 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[9,1]_old = 0.5217144995341341\n",
            "Q_table[(9, 1)]_new = 0.5222808223352521\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 13 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[14,3]_old = 0.5034172653624143\n",
            "Q_table[(14, 3)]_new = 0.5060244056167749\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 14 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[9,1]_old = 0.5222808223352521\n",
            "Q_table[(9, 1)]_new = 0.5227905128562582\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 15 step\n",
            "Delta Q = 0.9\n",
            "Q_table[14,1]_old = 0.0\n",
            "Q_table[(14, 1)]_new = 0.0\n",
            "We are on 14 state\n",
            "And now we are on 19 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 0 step\n",
            "Delta Q = 0.9527210815323196\n",
            "Q_table[0,0]_old = 0.49961046757403116\n",
            "Q_table[(0, 0)]_new = 0.5023705023489476\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 1 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[3,1]_old = 0.5325361770941373\n",
            "Q_table[(3, 1)]_new = 0.5338180373702354\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 2 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[8,2]_old = 0.5108355751682215\n",
            "Q_table[(8, 2)]_new = 0.5127008844420013\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 3 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[9,2]_old = 0.5196633160371691\n",
            "Q_table[(9, 2)]_new = 0.5206458512240542\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 4 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[9,1]_old = 0.5227905128562582\n",
            "Q_table[(9, 1)]_new = 0.5232492343251638\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 5 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[14,2]_old = 0.5107101906646397\n",
            "Q_table[(14, 2)]_new = 0.5123769443527072\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 6 step\n",
            "Delta Q = 0.9527377727545314\n",
            "Q_table[14,2]_old = 0.5123769443527072\n",
            "Q_table[(14, 2)]_new = 0.5138770226719679\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 7 step\n",
            "Delta Q = 0.9570607242086202\n",
            "Q_table[14,0]_old = 0.5327047752982965\n",
            "Q_table[(14, 0)]_new = 0.5364950219770871\n",
            "We are on 14 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 8 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[13,3]_old = 0.5112714214739216\n",
            "Q_table[(13, 3)]_new = 0.5146797573120412\n",
            "We are on 13 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 9 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[8,2]_old = 0.5127008844420013\n",
            "Q_table[(8, 2)]_new = 0.5143796627884032\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 10 step\n",
            "Delta Q = 0.9531130071757317\n",
            "Q_table[9,1]_old = 0.5232492343251638\n",
            "Q_table[(9, 1)]_new = 0.524037318068379\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 11 step\n",
            "Delta Q = 0.9570607242086202\n",
            "Q_table[14,0]_old = 0.5364950219770871\n",
            "Q_table[(14, 0)]_new = 0.5399062439879986\n",
            "We are on 14 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 12 step\n",
            "Delta Q = 0.954648048604115\n",
            "Q_table[13,0]_old = 0.5145210778294813\n",
            "Q_table[(13, 0)]_new = 0.5177170186506482\n",
            "We are on 13 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 13 step\n",
            "Delta Q = 0.9570607242086202\n",
            "Q_table[12,2]_old = 0.4307713422243659\n",
            "Q_table[(12, 2)]_new = 0.44475493221054957\n",
            "We are on 12 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 14 step\n",
            "Delta Q = 0.954648048604115\n",
            "Q_table[13,0]_old = 0.5177170186506482\n",
            "Q_table[(13, 0)]_new = 0.5205933653896985\n",
            "We are on 13 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 15 step\n",
            "Delta Q = 0.9570607242086202\n",
            "Q_table[12,2]_old = 0.44475493221054957\n",
            "Q_table[(12, 2)]_new = 0.4573401631981149\n",
            "We are on 12 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 16 step\n",
            "Delta Q = 0.954648048604115\n",
            "Q_table[13,0]_old = 0.5205933653896985\n",
            "Q_table[(13, 0)]_new = 0.5231820774548437\n",
            "We are on 13 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 17 step\n",
            "Delta Q = 0.965271552710033\n",
            "Q_table[12,1]_old = 0.5520004909506565\n",
            "Q_table[(12, 1)]_new = 0.5620719945656237\n",
            "We are on 12 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 18 step\n",
            "Delta Q = 0.9556451274619968\n",
            "Q_table[17,3]_old = 0.4538895755708612\n",
            "Q_table[(17, 3)]_new = 0.4641457454757718\n",
            "We are on 17 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 19 step\n",
            "Delta Q = 0.9\n",
            "Q_table[12,0]_old = 0.0\n",
            "Q_table[(12, 0)]_new = 0.0\n",
            "We are on 12 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 0 step\n",
            "Delta Q = 0.9516239127069983\n",
            "Q_table[0,2]_old = 0.49785703059816827\n",
            "Q_table[(0, 2)]_new = 0.4996952402453498\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 1 step\n",
            "Delta Q = 0.9528479856996533\n",
            "Q_table[4,0]_old = 0.5208547791461139\n",
            "Q_table[(4, 0)]_new = 0.5216172869311558\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 2 step\n",
            "Delta Q = 0.9528479856996533\n",
            "Q_table[3,3]_old = 0.51877957068113\n",
            "Q_table[(3, 3)]_new = 0.5197495993126703\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 3 step\n",
            "Delta Q = 0.9516401114061844\n",
            "Q_table[3,2]_old = 0.5072807444046169\n",
            "Q_table[(3, 2)]_new = 0.5081927813703396\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 4 step\n",
            "Delta Q = 0.9528479856996533\n",
            "Q_table[4,0]_old = 0.5216172869311558\n",
            "Q_table[(4, 0)]_new = 0.5223035439376935\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 5 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[3,0]_old = 0.46752275414918315\n",
            "Q_table[(3, 0)]_new = 0.4697327566962636\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 6 step\n",
            "Delta Q = 0.9406111971150787\n",
            "Q_table[2,0]_old = 0.3754169455816392\n",
            "Q_table[(2, 0)]_new = 0.3784864481385539\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 7 step\n",
            "Delta Q = 0.9406111971150787\n",
            "Q_table[1,3]_old = 0.3336356152245985\n",
            "Q_table[(1, 3)]_new = 0.34088325081721726\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 8 step\n",
            "Delta Q = 0.9406111971150787\n",
            "Q_table[1,3]_old = 0.34088325081721726\n",
            "Q_table[(1, 3)]_new = 0.34740612285057415\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 9 step\n",
            "Delta Q = 0.950289542546851\n",
            "Q_table[1,0]_old = 0.40036278438845163\n",
            "Q_table[(1, 0)]_new = 0.4106160484964575\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 0 step\n",
            "Delta Q = 0.9528479856996533\n",
            "Q_table[0,0]_old = 0.5023705023489476\n",
            "Q_table[(0, 0)]_new = 0.5049814378137062\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 1 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[3,1]_old = 0.5338180373702354\n",
            "Q_table[(3, 1)]_new = 0.5349717116187237\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 2 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[8,2]_old = 0.5143796627884032\n",
            "Q_table[(8, 2)]_new = 0.5158905633001649\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 3 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[9,2]_old = 0.5206458512240542\n",
            "Q_table[(9, 2)]_new = 0.5215301328922507\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 4 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[9,2]_old = 0.5215301328922507\n",
            "Q_table[(9, 2)]_new = 0.5223259863936276\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 5 step\n",
            "Delta Q = 0.9517080508498317\n",
            "Q_table[9,3]_old = 0.5078315321410022\n",
            "Q_table[(9, 3)]_new = 0.5087564297767336\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 6 step\n",
            "Delta Q = 0.9529621994502536\n",
            "Q_table[4,0]_old = 0.5223035439376935\n",
            "Q_table[(4, 0)]_new = 0.5230353889941778\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 7 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[3,0]_old = 0.4697327566962636\n",
            "Q_table[(3, 0)]_new = 0.471721758988636\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 8 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[2,3]_old = 0.4384130922512756\n",
            "Q_table[(2, 3)]_new = 0.4435340609881468\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 9 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[2,3]_old = 0.4435340609881468\n",
            "Q_table[(2, 3)]_new = 0.4481429328513309\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 10 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[2,3]_old = 0.4481429328513309\n",
            "Q_table[(2, 3)]_new = 0.45229091752819656\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 0 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[0,1]_old = 0.5079751772409193\n",
            "Q_table[(0, 1)]_new = 0.5101265263074294\n",
            "We are on 0 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 1 step\n",
            "Delta Q = 0.9517805035104236\n",
            "Q_table[9,3]_old = 0.5087564297767336\n",
            "Q_table[(9, 3)]_new = 0.5096612903094839\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 2 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[4,1]_old = 0.5214536637070537\n",
            "Q_table[(4, 1)]_new = 0.5222571641269503\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 3 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[9,2]_old = 0.5223259863936276\n",
            "Q_table[(9, 2)]_new = 0.5230422545448669\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 4 step\n",
            "Delta Q = 0.9517805035104236\n",
            "Q_table[9,3]_old = 0.5096612903094839\n",
            "Q_table[(9, 3)]_new = 0.5104756647889591\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 5 step\n",
            "Delta Q = 0.9529621994502536\n",
            "Q_table[4,0]_old = 0.5230353889941778\n",
            "Q_table[(4, 0)]_new = 0.5236940495450136\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 6 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[3,0]_old = 0.471721758988636\n",
            "Q_table[(3, 0)]_new = 0.4735118610517712\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 7 step\n",
            "Delta Q = 0.9406509888011493\n",
            "Q_table[2,0]_old = 0.3784864481385539\n",
            "Q_table[(2, 0)]_new = 0.3812887921258479\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 8 step\n",
            "Delta Q = 0.9406509888011493\n",
            "Q_table[1,3]_old = 0.34740612285057415\n",
            "Q_table[(1, 3)]_new = 0.35331649936666604\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 9 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[1,2]_old = 0.41021411227352145\n",
            "Q_table[(1, 2)]_new = 0.41815497900816806\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 0 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[0,1]_old = 0.5101265263074294\n",
            "Q_table[(0, 1)]_new = 0.5120627404672884\n",
            "We are on 0 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 1 step\n",
            "Delta Q = 0.9534507181548119\n",
            "Q_table[9,1]_old = 0.524037318068379\n",
            "Q_table[(9, 1)]_new = 0.525084304416353\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 2 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[14,3]_old = 0.5060244056167749\n",
            "Q_table[(14, 3)]_new = 0.5083708318456994\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 3 step\n",
            "Delta Q = 0.9518457109049564\n",
            "Q_table[9,3]_old = 0.5104756647889591\n",
            "Q_table[(9, 3)]_new = 0.5112738092150195\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 4 step\n",
            "Delta Q = 0.9518457109049564\n",
            "Q_table[4,3]_old = 0.5120101642043083\n",
            "Q_table[(4, 3)]_new = 0.5126548586888339\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 5 step\n",
            "Delta Q = 0.9518457109049564\n",
            "Q_table[4,2]_old = 0.5113065944164901\n",
            "Q_table[(4, 2)]_new = 0.5120216458797974\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 6 step\n",
            "Delta Q = 0.9518457109049564\n",
            "Q_table[4,2]_old = 0.5120216458797974\n",
            "Q_table[(4, 2)]_new = 0.512665192196774\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 7 step\n",
            "Delta Q = 0.9518457109049564\n",
            "Q_table[4,2]_old = 0.512665192196774\n",
            "Q_table[(4, 2)]_new = 0.513244383882053\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 8 step\n",
            "Delta Q = 0.9518457109049564\n",
            "Q_table[4,2]_old = 0.513244383882053\n",
            "Q_table[(4, 2)]_new = 0.513765656398804\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 9 step\n",
            "Delta Q = 0.9518457109049564\n",
            "Q_table[4,2]_old = 0.513765656398804\n",
            "Q_table[(4, 2)]_new = 0.5142348016638799\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 10 step\n",
            "Delta Q = 0.9529621994502536\n",
            "Q_table[4,0]_old = 0.5236940495450136\n",
            "Q_table[(4, 0)]_new = 0.5242868440407659\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 11 step\n",
            "Delta Q = 0.9529621994502536\n",
            "Q_table[3,3]_old = 0.5197495993126703\n",
            "Q_table[(3, 3)]_new = 0.5207368388316569\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 12 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[3,1]_old = 0.5349717116187237\n",
            "Q_table[(3, 1)]_new = 0.5360100184423632\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 13 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[8,2]_old = 0.5158905633001649\n",
            "Q_table[(8, 2)]_new = 0.5172503737607504\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 14 step\n",
            "Delta Q = 0.9534507181548119\n",
            "Q_table[9,1]_old = 0.525084304416353\n",
            "Q_table[(9, 1)]_new = 0.5260265921295296\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 15 step\n",
            "Delta Q = 0.9\n",
            "Q_table[14,1]_old = 0.0\n",
            "Q_table[(14, 1)]_new = 0.0\n",
            "We are on 14 state\n",
            "And now we are on 19 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 0 step\n",
            "Delta Q = 0.9519043975600359\n",
            "Q_table[0,2]_old = 0.4996952402453498\n",
            "Q_table[(0, 2)]_new = 0.5016301137808507\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 1 step\n",
            "Delta Q = 0.9519043975600359\n",
            "Q_table[4,2]_old = 0.5142348016638799\n",
            "Q_table[(4, 2)]_new = 0.5147157190575278\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 2 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[4,1]_old = 0.5222571641269503\n",
            "Q_table[(4, 1)]_new = 0.5229803145048573\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 3 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[9,2]_old = 0.5230422545448669\n",
            "Q_table[(9, 2)]_new = 0.5236868958809822\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 4 step\n",
            "Delta Q = 0.9519043975600359\n",
            "Q_table[9,3]_old = 0.5112738092150195\n",
            "Q_table[(9, 3)]_new = 0.5120508258535534\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 5 step\n",
            "Delta Q = 0.953064991825794\n",
            "Q_table[4,0]_old = 0.5242868440407659\n",
            "Q_table[(4, 0)]_new = 0.5249231514624833\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 6 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[3,0]_old = 0.4735118610517712\n",
            "Q_table[(3, 0)]_new = 0.4751229529085928\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 7 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[2,3]_old = 0.45229091752819656\n",
            "Q_table[(2, 3)]_new = 0.4560241037373757\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 8 step\n",
            "Delta Q = 0.9413973429218087\n",
            "Q_table[2,0]_old = 0.3812887921258479\n",
            "Q_table[(2, 0)]_new = 0.3845572558350717\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 9 step\n",
            "Delta Q = 0.9506942113062615\n",
            "Q_table[1,0]_old = 0.4106160484964575\n",
            "Q_table[(1, 0)]_new = 0.42024865495307334\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 0 step\n",
            "Delta Q = 0.9519673919947859\n",
            "Q_table[0,3]_old = 0.4959922648119139\n",
            "Q_table[(0, 3)]_new = 0.49836043032550836\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 1 step\n",
            "Delta Q = 0.9519673919947859\n",
            "Q_table[4,2]_old = 0.5147157190575278\n",
            "Q_table[(4, 2)]_new = 0.5152115391465608\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 2 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[4,1]_old = 0.5229803145048573\n",
            "Q_table[(4, 1)]_new = 0.5236311498449735\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 3 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[9,2]_old = 0.5236868958809822\n",
            "Q_table[(9, 2)]_new = 0.524267073083486\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 4 step\n",
            "Delta Q = 0.9519673919947859\n",
            "Q_table[9,3]_old = 0.5120508258535534\n",
            "Q_table[(9, 3)]_new = 0.5128131352629839\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 5 step\n",
            "Delta Q = 0.953064991825794\n",
            "Q_table[4,0]_old = 0.5249231514624833\n",
            "Q_table[(4, 0)]_new = 0.5254958281420289\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 6 step\n",
            "Delta Q = 0.9545354779855119\n",
            "Q_table[3,1]_old = 0.5360100184423632\n",
            "Q_table[(3, 1)]_new = 0.5369444945836387\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 7 step\n",
            "Delta Q = 0.9570607242086202\n",
            "Q_table[8,1]_old = 0.5508634139950691\n",
            "Q_table[(8, 1)]_new = 0.5528377968041824\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 8 step\n",
            "Delta Q = 0.9547309418836141\n",
            "Q_table[13,3]_old = 0.5146797573120412\n",
            "Q_table[(13, 3)]_new = 0.5179427234644511\n",
            "We are on 13 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 9 step\n",
            "Delta Q = 0.9570607242086202\n",
            "Q_table[8,1]_old = 0.5528377968041824\n",
            "Q_table[(8, 1)]_new = 0.5546147413323844\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 10 step\n",
            "Delta Q = 0.9599652406743633\n",
            "Q_table[13,1]_old = 0.5763709516022244\n",
            "Q_table[(13, 1)]_new = 0.5786990971163652\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 11 step\n",
            "Delta Q = 0.965271552710033\n",
            "Q_table[18,0]_old = 0.6057095017612447\n",
            "Q_table[(18, 0)]_new = 0.6104101042951532\n",
            "We are on 18 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 12 step\n",
            "Delta Q = 0.965271552710033\n",
            "Q_table[17,1]_old = 0.5263094423815229\n",
            "Q_table[(17, 1)]_new = 0.5389500508534035\n",
            "We are on 17 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 13 step\n",
            "Delta Q = 0.965271552710033\n",
            "Q_table[17,1]_old = 0.5389500508534035\n",
            "Q_table[(17, 1)]_new = 0.5503265984780961\n",
            "We are on 17 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 14 step\n",
            "Delta Q = 0.9556451274619968\n",
            "Q_table[17,3]_old = 0.4641457454757718\n",
            "Q_table[(17, 3)]_new = 0.47337629839019135\n",
            "We are on 17 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 15 step\n",
            "Delta Q = 0.9\n",
            "Q_table[12,3]_old = 0.0\n",
            "Q_table[(12, 3)]_new = 0.0\n",
            "We are on 12 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 0 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[0,1]_old = 0.5120627404672884\n",
            "Q_table[(0, 1)]_new = 0.5138053332111615\n",
            "We are on 0 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 1 step\n",
            "Delta Q = 0.9520240869860609\n",
            "Q_table[9,3]_old = 0.5128131352629839\n",
            "Q_table[(9, 3)]_new = 0.5135559087227464\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 2 step\n",
            "Delta Q = 0.9520240869860609\n",
            "Q_table[4,3]_old = 0.5126548586888339\n",
            "Q_table[(4, 3)]_new = 0.5134134598060114\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 3 step\n",
            "Delta Q = 0.9520240869860609\n",
            "Q_table[4,3]_old = 0.5134134598060114\n",
            "Q_table[(4, 3)]_new = 0.5140962008114711\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 4 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[4,1]_old = 0.5236311498449735\n",
            "Q_table[(4, 1)]_new = 0.5242169016510781\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 5 step\n",
            "Delta Q = 0.952948866790602\n",
            "Q_table[9,2]_old = 0.524267073083486\n",
            "Q_table[(9, 2)]_new = 0.5247892325657394\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 6 step\n",
            "Delta Q = 0.9549068593919061\n",
            "Q_table[9,0]_old = 0.5348370382889089\n",
            "Q_table[(9, 0)]_new = 0.5362601938519241\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 7 step\n",
            "Delta Q = 0.9572912106145202\n",
            "Q_table[8,1]_old = 0.5546147413323844\n",
            "Q_table[(8, 1)]_new = 0.5564444778136661\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 8 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[13,3]_old = 0.5179427234644511\n",
            "Q_table[(13, 3)]_new = 0.521236454421559\n",
            "We are on 13 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 0 step\n",
            "Delta Q = 0.9520240869860609\n",
            "Q_table[0,3]_old = 0.49836043032550836\n",
            "Q_table[(0, 3)]_new = 0.5005484742790184\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 1 step\n",
            "Delta Q = 0.9520240869860609\n",
            "Q_table[4,3]_old = 0.5140962008114711\n",
            "Q_table[(4, 3)]_new = 0.5147106677163849\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 2 step\n",
            "Delta Q = 0.9530897591913405\n",
            "Q_table[4,1]_old = 0.5242169016510781\n",
            "Q_table[(4, 1)]_new = 0.5248849706773109\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 3 step\n",
            "Delta Q = 0.9530897591913405\n",
            "Q_table[9,2]_old = 0.5247892325657394\n",
            "Q_table[(9, 2)]_new = 0.5254000685005059\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 4 step\n",
            "Delta Q = 0.9534507181548119\n",
            "Q_table[9,1]_old = 0.5260265921295296\n",
            "Q_table[(9, 1)]_new = 0.5268746510713885\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 5 step\n",
            "Delta Q = 0.9534507181548119\n",
            "Q_table[14,2]_old = 0.5138770226719679\n",
            "Q_table[(14, 2)]_new = 0.5159400385595829\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 6 step\n",
            "Delta Q = 0.9530897591913405\n",
            "Q_table[14,3]_old = 0.5083708318456994\n",
            "Q_table[(14, 3)]_new = 0.51062350785247\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 7 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[9,0]_old = 0.5362601938519241\n",
            "Q_table[(9, 0)]_new = 0.5377221777702846\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 8 step\n",
            "Delta Q = 0.9531575049637803\n",
            "Q_table[8,3]_old = 0.5017515313672236\n",
            "Q_table[(8, 3)]_new = 0.5047338831942815\n",
            "We are on 8 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 9 step\n",
            "Delta Q = 0.9531575049637803\n",
            "Q_table[3,3]_old = 0.5207368388316569\n",
            "Q_table[(3, 3)]_new = 0.5218206599122714\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 10 step\n",
            "Delta Q = 0.9520240869860609\n",
            "Q_table[3,2]_old = 0.5081927813703396\n",
            "Q_table[(3, 2)]_new = 0.5093975902193665\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 11 step\n",
            "Delta Q = 0.9520240869860609\n",
            "Q_table[4,3]_old = 0.5147106677163849\n",
            "Q_table[(4, 3)]_new = 0.5152636879308072\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 12 step\n",
            "Delta Q = 0.9520240869860609\n",
            "Q_table[4,2]_old = 0.5152115391465608\n",
            "Q_table[(4, 2)]_new = 0.5157144722179656\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 13 step\n",
            "Delta Q = 0.9532344955992582\n",
            "Q_table[4,1]_old = 0.5248849706773109\n",
            "Q_table[(4, 1)]_new = 0.525630969208838\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 14 step\n",
            "Delta Q = 0.9534507181548119\n",
            "Q_table[9,1]_old = 0.5268746510713885\n",
            "Q_table[(9, 1)]_new = 0.5276379041190615\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 15 step\n",
            "Delta Q = 0.9534507181548119\n",
            "Q_table[14,2]_old = 0.5159400385595829\n",
            "Q_table[(14, 2)]_new = 0.5177967528584365\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 16 step\n",
            "Delta Q = 0.9534507181548119\n",
            "Q_table[14,2]_old = 0.5177967528584365\n",
            "Q_table[(14, 2)]_new = 0.5194677957274048\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 17 step\n",
            "Delta Q = 0.9532344955992582\n",
            "Q_table[14,3]_old = 0.51062350785247\n",
            "Q_table[(14, 3)]_new = 0.5127956526664812\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 18 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[9,0]_old = 0.5377221777702846\n",
            "Q_table[(9, 0)]_new = 0.5390379632968091\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 19 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 0 step\n",
            "Delta Q = 0.9531575049637803\n",
            "Q_table[0,0]_old = 0.5049814378137062\n",
            "Q_table[(0, 0)]_new = 0.5076407989961158\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 1 step\n",
            "Delta Q = 0.952037465951675\n",
            "Q_table[3,2]_old = 0.5093975902193665\n",
            "Q_table[(3, 2)]_new = 0.5104952971491048\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 2 step\n",
            "Delta Q = 0.9531575049637803\n",
            "Q_table[4,0]_old = 0.5254958281420289\n",
            "Q_table[(4, 0)]_new = 0.5261037502916063\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 3 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[3,1]_old = 0.5369444945836387\n",
            "Q_table[(3, 1)]_new = 0.5383380484288277\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 0 step\n",
            "Delta Q = 0.9520842712788691\n",
            "Q_table[0,2]_old = 0.5016301137808507\n",
            "Q_table[(0, 2)]_new = 0.5035513736816346\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 1 step\n",
            "Delta Q = 0.9520842712788691\n",
            "Q_table[4,3]_old = 0.5152636879308072\n",
            "Q_table[(4, 3)]_new = 0.5158215904165956\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 2 step\n",
            "Delta Q = 0.9520842712788691\n",
            "Q_table[4,2]_old = 0.5157144722179656\n",
            "Q_table[(4, 2)]_new = 0.516227296275038\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 3 step\n",
            "Delta Q = 0.9520842712788691\n",
            "Q_table[4,3]_old = 0.5158215904165956\n",
            "Q_table[(4, 3)]_new = 0.5163237026538051\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 4 step\n",
            "Delta Q = 0.9520842712788691\n",
            "Q_table[4,2]_old = 0.516227296275038\n",
            "Q_table[(4, 2)]_new = 0.5166888379264033\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 5 step\n",
            "Delta Q = 0.953295466794454\n",
            "Q_table[4,0]_old = 0.5261037502916063\n",
            "Q_table[(4, 0)]_new = 0.5267888420568996\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 6 step\n",
            "Delta Q = 0.953295466794454\n",
            "Q_table[3,3]_old = 0.5218206599122714\n",
            "Q_table[(3, 3)]_new = 0.5229340607154982\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 7 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[3,1]_old = 0.5383380484288277\n",
            "Q_table[(3, 1)]_new = 0.5395922468894979\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 8 step\n",
            "Delta Q = 0.9534196324420603\n",
            "Q_table[8,3]_old = 0.5047338831942815\n",
            "Q_table[(8, 3)]_new = 0.5076801273169136\n",
            "We are on 8 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 9 step\n",
            "Delta Q = 0.9534196324420603\n",
            "Q_table[3,3]_old = 0.5229340607154982\n",
            "Q_table[(3, 3)]_new = 0.5240602870860087\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 10 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[3,1]_old = 0.5395922468894979\n",
            "Q_table[(3, 1)]_new = 0.5407210255041011\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 11 step\n",
            "Delta Q = 0.9533647583663841\n",
            "Q_table[8,2]_old = 0.5172503737607504\n",
            "Q_table[(8, 2)]_new = 0.5188900947510595\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 12 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[9,0]_old = 0.5390379632968091\n",
            "Q_table[(9, 0)]_new = 0.5402221702706811\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 13 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 0 step\n",
            "Delta Q = 0.953531381524906\n",
            "Q_table[0,0]_old = 0.5076407989961158\n",
            "Q_table[(0, 0)]_new = 0.5104081006214103\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 1 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[3,1]_old = 0.5407210255041011\n",
            "Q_table[(3, 1)]_new = 0.5417369262572439\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 0 step\n",
            "Delta Q = 0.9521520953636331\n",
            "Q_table[0,2]_old = 0.5035513736816346\n",
            "Q_table[(0, 2)]_new = 0.5053483316771042\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 1 step\n",
            "Delta Q = 0.9521520953636331\n",
            "Q_table[4,3]_old = 0.5163237026538051\n",
            "Q_table[(4, 3)]_new = 0.5168434277520577\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 2 step\n",
            "Delta Q = 0.9534819948567974\n",
            "Q_table[4,1]_old = 0.525630969208838\n",
            "Q_table[(4, 1)]_new = 0.5265498671447516\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 3 step\n",
            "Delta Q = 0.9534507181548119\n",
            "Q_table[9,1]_old = 0.5276379041190615\n",
            "Q_table[(9, 1)]_new = 0.5283248318619672\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 4 step\n",
            "Delta Q = 0.9572912106145202\n",
            "Q_table[14,0]_old = 0.5399062439879986\n",
            "Q_table[(14, 0)]_new = 0.5432068302037188\n",
            "We are on 14 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 5 step\n",
            "Delta Q = 0.9604306003252202\n",
            "Q_table[13,1]_old = 0.5786990971163652\n",
            "Q_table[(13, 1)]_new = 0.5812597877299489\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 6 step\n",
            "Delta Q = 0.9604306003252202\n",
            "Q_table[18,1]_old = 0.5451744352964636\n",
            "Q_table[(18, 1)]_new = 0.5510875920920374\n",
            "We are on 18 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 7 step\n",
            "Delta Q = 0.965271552710033\n",
            "Q_table[18,0]_old = 0.6104101042951532\n",
            "Q_table[(18, 0)]_new = 0.6146406465756709\n",
            "We are on 18 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 8 step\n",
            "Delta Q = 0.9556451274619968\n",
            "Q_table[17,3]_old = 0.47337629839019135\n",
            "Q_table[(17, 3)]_new = 0.48168379601316896\n",
            "We are on 17 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[12,0]_old = 0.0\n",
            "Q_table[(12, 0)]_new = 0.0\n",
            "We are on 12 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 0 step\n",
            "Delta Q = 0.9534819948567974\n",
            "Q_table[0,1]_old = 0.5138053332111615\n",
            "Q_table[(0, 1)]_new = 0.5159067947468428\n",
            "We are on 0 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 1 step\n",
            "Delta Q = 0.9534819948567974\n",
            "Q_table[9,2]_old = 0.5254000685005059\n",
            "Q_table[(9, 2)]_new = 0.5263420565072527\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 2 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[9,0]_old = 0.5402221702706811\n",
            "Q_table[(9, 0)]_new = 0.5412879565471659\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 3 step\n",
            "Delta Q = 0.9535875076981695\n",
            "Q_table[8,2]_old = 0.5188900947510595\n",
            "Q_table[(8, 2)]_new = 0.520588592974123\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 4 step\n",
            "Delta Q = 0.9521520953636331\n",
            "Q_table[9,3]_old = 0.5135559087227464\n",
            "Q_table[(9, 3)]_new = 0.5143524132141047\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 5 step\n",
            "Delta Q = 0.9535875076981695\n",
            "Q_table[4,1]_old = 0.5265498671447516\n",
            "Q_table[(4, 1)]_new = 0.5274823881284458\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 6 step\n",
            "Delta Q = 0.9535875076981695\n",
            "Q_table[9,2]_old = 0.5263420565072527\n",
            "Q_table[(9, 2)]_new = 0.5272953585546969\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 7 step\n",
            "Delta Q = 0.9537774761901682\n",
            "Q_table[9,1]_old = 0.5283248318619672\n",
            "Q_table[(9, 1)]_new = 0.5292698248659387\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 8 step\n",
            "Delta Q = 0.9535875076981695\n",
            "Q_table[14,3]_old = 0.5127956526664812\n",
            "Q_table[(14, 3)]_new = 0.5151035950980025\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 9 step\n",
            "Delta Q = 0.9535875076981695\n",
            "Q_table[9,2]_old = 0.5272953585546969\n",
            "Q_table[(9, 2)]_new = 0.5281533303973966\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 10 step\n",
            "Delta Q = 0.9537774761901682\n",
            "Q_table[9,1]_old = 0.5292698248659387\n",
            "Q_table[(9, 1)]_new = 0.530120318569513\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 11 step\n",
            "Delta Q = 0.9575447189852649\n",
            "Q_table[14,0]_old = 0.5432068302037188\n",
            "Q_table[(14, 0)]_new = 0.5464308661686119\n",
            "We are on 14 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 12 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[13,3]_old = 0.521236454421559\n",
            "Q_table[(13, 3)]_new = 0.524200812282956\n",
            "We are on 13 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 13 step\n",
            "Delta Q = 0.9536319556994671\n",
            "Q_table[8,3]_old = 0.5076801273169136\n",
            "Q_table[(8, 3)]_new = 0.5105440702846894\n",
            "We are on 8 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 14 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[3,1]_old = 0.5417369262572439\n",
            "Q_table[(3, 1)]_new = 0.5426512369350724\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 15 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 0 step\n",
            "Delta Q = 0.9537224724565722\n",
            "Q_table[0,0]_old = 0.5104081006214103\n",
            "Q_table[(0, 0)]_new = 0.5130897630158414\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 1 step\n",
            "Delta Q = 0.9522207564247162\n",
            "Q_table[3,2]_old = 0.5104952971491048\n",
            "Q_table[(3, 2)]_new = 0.5116665238589105\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 2 step\n",
            "Delta Q = 0.9522207564247162\n",
            "Q_table[4,3]_old = 0.5168434277520577\n",
            "Q_table[(4, 3)]_new = 0.5173798414015681\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 3 step\n",
            "Delta Q = 0.9522207564247162\n",
            "Q_table[4,3]_old = 0.5173798414015681\n",
            "Q_table[(4, 3)]_new = 0.5178626136861275\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 4 step\n",
            "Delta Q = 0.9522207564247162\n",
            "Q_table[4,2]_old = 0.5166888379264033\n",
            "Q_table[(4, 2)]_new = 0.5172407105584791\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 5 step\n",
            "Delta Q = 0.9522207564247162\n",
            "Q_table[4,3]_old = 0.5178626136861275\n",
            "Q_table[(4, 3)]_new = 0.5182971087422309\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 6 step\n",
            "Delta Q = 0.9537224724565722\n",
            "Q_table[4,0]_old = 0.5267888420568996\n",
            "Q_table[(4, 0)]_new = 0.5278324303077818\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 7 step\n",
            "Delta Q = 0.9537224724565722\n",
            "Q_table[3,3]_old = 0.5240602870860087\n",
            "Q_table[(3, 3)]_new = 0.5253767308339801\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 8 step\n",
            "Delta Q = 0.9489622779619988\n",
            "Q_table[3,0]_old = 0.4751229529085928\n",
            "Q_table[(3, 0)]_new = 0.4765729355797323\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 9 step\n",
            "Delta Q = 0.9537224724565722\n",
            "Q_table[2,2]_old = 0.4945684642626137\n",
            "Q_table[(2, 2)]_new = 0.4988340902929245\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 10 step\n",
            "Delta Q = 0.9493845749389995\n",
            "Q_table[3,0]_old = 0.4765729355797323\n",
            "Q_table[(3, 0)]_new = 0.47830021696075864\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 11 step\n",
            "Delta Q = 0.9537224724565722\n",
            "Q_table[2,2]_old = 0.4988340902929245\n",
            "Q_table[(2, 2)]_new = 0.5026731537202043\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 12 step\n",
            "Delta Q = 0.9537224724565722\n",
            "Q_table[3,3]_old = 0.5253767308339801\n",
            "Q_table[(3, 3)]_new = 0.5265615302071542\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 13 step\n",
            "Delta Q = 0.9537224724565722\n",
            "Q_table[3,3]_old = 0.5265615302071542\n",
            "Q_table[(3, 3)]_new = 0.527627849643011\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 14 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[3,1]_old = 0.5426512369350724\n",
            "Q_table[(3, 1)]_new = 0.5434741165451181\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 15 step\n",
            "Delta Q = 0.9538039375379668\n",
            "Q_table[8,3]_old = 0.5105440702846894\n",
            "Q_table[(8, 3)]_new = 0.5132936007941872\n",
            "We are on 8 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 16 step\n",
            "Delta Q = 0.9538039375379668\n",
            "Q_table[3,3]_old = 0.527627849643011\n",
            "Q_table[(3, 3)]_new = 0.5286690022166767\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 17 step\n",
            "Delta Q = 0.9522554106004704\n",
            "Q_table[3,2]_old = 0.5116665238589105\n",
            "Q_table[(3, 2)]_new = 0.51275528207349\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 18 step\n",
            "Delta Q = 0.9538039375379668\n",
            "Q_table[4,0]_old = 0.5278324303077818\n",
            "Q_table[(4, 0)]_new = 0.5288531248149704\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 19 step\n",
            "Delta Q = 0.9497646422183003\n",
            "Q_table[3,0]_old = 0.47830021696075864\n",
            "Q_table[(3, 0)]_new = 0.480234837482983\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 20 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 0 step\n",
            "Delta Q = 0.9538039375379668\n",
            "Q_table[0,0]_old = 0.5130897630158414\n",
            "Q_table[(0, 0)]_new = 0.515584724252224\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 1 step\n",
            "Delta Q = 0.9523564593566821\n",
            "Q_table[3,2]_old = 0.51275528207349\n",
            "Q_table[(3, 2)]_new = 0.513836213222823\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 2 step\n",
            "Delta Q = 0.9535875076981695\n",
            "Q_table[4,1]_old = 0.5274823881284458\n",
            "Q_table[(4, 1)]_new = 0.5283216570137707\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 3 step\n",
            "Delta Q = 0.9535875076981695\n",
            "Q_table[9,2]_old = 0.5281533303973966\n",
            "Q_table[(9, 2)]_new = 0.5289255050558264\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 4 step\n",
            "Delta Q = 0.9535875076981695\n",
            "Q_table[9,2]_old = 0.5289255050558264\n",
            "Q_table[(9, 2)]_new = 0.5296204622484132\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 5 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[9,0]_old = 0.5412879565471659\n",
            "Q_table[(9, 0)]_new = 0.5422471641960023\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 0 step\n",
            "Delta Q = 0.9538039375379668\n",
            "Q_table[0,0]_old = 0.515584724252224\n",
            "Q_table[(0, 0)]_new = 0.5178301893649684\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 1 step\n",
            "Delta Q = 0.9523564593566821\n",
            "Q_table[3,2]_old = 0.513836213222823\n",
            "Q_table[(3, 2)]_new = 0.5148090512572228\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 2 step\n",
            "Delta Q = 0.9523564593566821\n",
            "Q_table[4,3]_old = 0.5182971087422309\n",
            "Q_table[(4, 3)]_new = 0.5188238572246899\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 3 step\n",
            "Delta Q = 0.9523564593566821\n",
            "Q_table[4,2]_old = 0.5172407105584791\n",
            "Q_table[(4, 2)]_new = 0.5178730988593132\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 4 step\n",
            "Delta Q = 0.9536824692554042\n",
            "Q_table[4,1]_old = 0.5283216570137707\n",
            "Q_table[(4, 1)]_new = 0.5291719605677978\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 5 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[9,0]_old = 0.5422471641960023\n",
            "Q_table[(9, 0)]_new = 0.543110451079955\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 6 step\n",
            "Delta Q = 0.9538039375379668\n",
            "Q_table[8,3]_old = 0.5132936007941872\n",
            "Q_table[(8, 3)]_new = 0.5157681782527352\n",
            "We are on 8 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 7 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[3,1]_old = 0.5434741165451181\n",
            "Q_table[(3, 1)]_new = 0.5442147081941593\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 8 step\n",
            "Delta Q = 0.9537679346569156\n",
            "Q_table[8,2]_old = 0.520588592974123\n",
            "Q_table[(8, 2)]_new = 0.5222976683336262\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 9 step\n",
            "Delta Q = 0.952388024096212\n",
            "Q_table[9,3]_old = 0.5143524132141047\n",
            "Q_table[(9, 3)]_new = 0.5153051959889062\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 10 step\n",
            "Delta Q = 0.9537679346569156\n",
            "Q_table[4,1]_old = 0.5291719605677978\n",
            "Q_table[(4, 1)]_new = 0.5300226991679337\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 11 step\n",
            "Delta Q = 0.9524722472176255\n",
            "Q_table[9,3]_old = 0.5153051959889062\n",
            "Q_table[(9, 3)]_new = 0.516246923607641\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 12 step\n",
            "Delta Q = 0.9524722472176255\n",
            "Q_table[4,2]_old = 0.5178730988593132\n",
            "Q_table[(4, 2)]_new = 0.5185580361910073\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 13 step\n",
            "Delta Q = 0.9537679346569156\n",
            "Q_table[4,1]_old = 0.5300226991679337\n",
            "Q_table[(4, 1)]_new = 0.5307883639080558\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 14 step\n",
            "Delta Q = 0.9540966557506926\n",
            "Q_table[9,1]_old = 0.530120318569513\n",
            "Q_table[(9, 1)]_new = 0.5312049424632543\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 15 step\n",
            "Delta Q = 0.9\n",
            "Q_table[14,1]_old = 0.0\n",
            "Q_table[(14, 1)]_new = 0.0\n",
            "We are on 14 state\n",
            "And now we are on 19 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 0 step\n",
            "Delta Q = 0.9525480480268975\n",
            "Q_table[0,3]_old = 0.5005484742790184\n",
            "Q_table[(0, 3)]_new = 0.5030416748780141\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 1 step\n",
            "Delta Q = 0.9538772561112218\n",
            "Q_table[4,0]_old = 0.5288531248149704\n",
            "Q_table[(4, 0)]_new = 0.5298450684446951\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 2 step\n",
            "Delta Q = 0.9538772561112218\n",
            "Q_table[3,3]_old = 0.5286690022166767\n",
            "Q_table[(3, 3)]_new = 0.5296793581062308\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 3 step\n",
            "Delta Q = 0.9525480480268975\n",
            "Q_table[3,2]_old = 0.5148090512572228\n",
            "Q_table[(3, 2)]_new = 0.515876194158398\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 4 step\n",
            "Delta Q = 0.9525480480268975\n",
            "Q_table[4,3]_old = 0.5188238572246899\n",
            "Q_table[(4, 3)]_new = 0.5194895195291185\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 5 step\n",
            "Delta Q = 0.9525480480268975\n",
            "Q_table[4,2]_old = 0.5185580361910073\n",
            "Q_table[(4, 2)]_new = 0.5192502805988041\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 6 step\n",
            "Delta Q = 0.9525480480268975\n",
            "Q_table[4,3]_old = 0.5194895195291185\n",
            "Q_table[(4, 3)]_new = 0.5200886156031042\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 7 step\n",
            "Delta Q = 0.9537679346569156\n",
            "Q_table[4,1]_old = 0.5307883639080558\n",
            "Q_table[(4, 1)]_new = 0.5314774621741658\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 8 step\n",
            "Delta Q = 0.9526162687552424\n",
            "Q_table[9,3]_old = 0.516246923607641\n",
            "Q_table[(9, 3)]_new = 0.5172385000021194\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 9 step\n",
            "Delta Q = 0.9526162687552424\n",
            "Q_table[4,2]_old = 0.5192502805988041\n",
            "Q_table[(4, 2)]_new = 0.519941521294166\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 10 step\n",
            "Delta Q = 0.9537679346569156\n",
            "Q_table[4,1]_old = 0.5314774621741658\n",
            "Q_table[(4, 1)]_new = 0.5320976506136648\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 11 step\n",
            "Delta Q = 0.9550880033035529\n",
            "Q_table[9,0]_old = 0.543110451079955\n",
            "Q_table[(9, 0)]_new = 0.5438874092755125\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 12 step\n",
            "Delta Q = 0.9575447189852649\n",
            "Q_table[8,1]_old = 0.5564444778136661\n",
            "Q_table[(8, 1)]_new = 0.5583447490175645\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 13 step\n",
            "Delta Q = 0.9608494240109915\n",
            "Q_table[13,1]_old = 0.5812597877299489\n",
            "Q_table[(13, 1)]_new = 0.5839832329679455\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 14 step\n",
            "Delta Q = 0.9\n",
            "Q_table[18,2]_old = 0.0\n",
            "Q_table[(18, 2)]_new = 0.0\n",
            "We are on 18 state\n",
            "And now we are on 19 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 0 step\n",
            "Delta Q = 0.9538448535182757\n",
            "Q_table[0,1]_old = 0.5159067947468428\n",
            "Q_table[(0, 1)]_new = 0.5181609687904343\n",
            "We are on 0 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 1 step\n",
            "Delta Q = 0.9552761301527389\n",
            "Q_table[9,0]_old = 0.5438874092755125\n",
            "Q_table[(9, 0)]_new = 0.5447747985007001\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 2 step\n",
            "Delta Q = 0.9578143400638266\n",
            "Q_table[8,1]_old = 0.5583447490175645\n",
            "Q_table[(8, 1)]_new = 0.5603246141796346\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 3 step\n",
            "Delta Q = 0.9554721368037838\n",
            "Q_table[13,3]_old = 0.524200812282956\n",
            "Q_table[(13, 3)]_new = 0.5272528678584443\n",
            "We are on 13 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 4 step\n",
            "Delta Q = 0.9539327050515694\n",
            "Q_table[8,2]_old = 0.5222976683336262\n",
            "Q_table[(8, 2)]_new = 0.5240006065518329\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 5 step\n",
            "Delta Q = 0.9554721368037838\n",
            "Q_table[9,0]_old = 0.5447747985007001\n",
            "Q_table[(9, 0)]_new = 0.5457694554544139\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 0 step\n",
            "Delta Q = 0.9526776674107529\n",
            "Q_table[0,2]_old = 0.5053483316771042\n",
            "Q_table[(0, 2)]_new = 0.5074911659201466\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 1 step\n",
            "Delta Q = 0.9538772561112218\n",
            "Q_table[4,0]_old = 0.5298450684446951\n",
            "Q_table[(4, 0)]_new = 0.5307378177114475\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 2 step\n",
            "Delta Q = 0.9497646422183003\n",
            "Q_table[3,0]_old = 0.480234837482983\n",
            "Q_table[(3, 0)]_new = 0.48197599595298496\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 3 step\n",
            "Delta Q = 0.9416046168403542\n",
            "Q_table[2,0]_old = 0.3845572558350717\n",
            "Q_table[(2, 0)]_new = 0.3877061470919188\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 4 step\n",
            "Delta Q = 0.9416046168403542\n",
            "Q_table[1,3]_old = 0.35331649936666604\n",
            "Q_table[(1, 3)]_new = 0.3595894662703537\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 5 step\n",
            "Delta Q = 0.9416046168403542\n",
            "Q_table[1,3]_old = 0.3595894662703537\n",
            "Q_table[(1, 3)]_new = 0.3652351364836726\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 6 step\n",
            "Delta Q = 0.9416046168403542\n",
            "Q_table[1,3]_old = 0.3652351364836726\n",
            "Q_table[(1, 3)]_new = 0.37031623967565963\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 7 step\n",
            "Delta Q = 0.9497646422183003\n",
            "Q_table[1,2]_old = 0.41815497900816806\n",
            "Q_table[(1, 2)]_new = 0.4261041233256515\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 8 step\n",
            "Delta Q = 0.9421843082092395\n",
            "Q_table[2,0]_old = 0.3877061470919188\n",
            "Q_table[(2, 0)]_new = 0.39111984059196647\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 9 step\n",
            "Delta Q = 0.951297935910253\n",
            "Q_table[1,0]_old = 0.42024865495307334\n",
            "Q_table[(1, 0)]_new = 0.429521725368019\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 0 step\n",
            "Delta Q = 0.954031176089987\n",
            "Q_table[0,1]_old = 0.5181609687904343\n",
            "Q_table[(0, 1)]_new = 0.5203760480013778\n",
            "We are on 0 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 1 step\n",
            "Delta Q = 0.9554721368037838\n",
            "Q_table[9,0]_old = 0.5457694554544139\n",
            "Q_table[(9, 0)]_new = 0.5466646467127564\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 2 step\n",
            "Delta Q = 0.9578143400638266\n",
            "Q_table[8,1]_old = 0.5603246141796346\n",
            "Q_table[(8, 1)]_new = 0.5621064928254977\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 3 step\n",
            "Delta Q = 0.9608494240109915\n",
            "Q_table[13,1]_old = 0.5839832329679455\n",
            "Q_table[(13, 1)]_new = 0.5864343336821425\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 4 step\n",
            "Delta Q = 0.965271552710033\n",
            "Q_table[18,0]_old = 0.6146406465756709\n",
            "Q_table[(18, 0)]_new = 0.6184481346281367\n",
            "We are on 18 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 5 step\n",
            "Delta Q = 0.9763519754695886\n",
            "Q_table[17,0]_old = 0.6593086132326558\n",
            "Q_table[(17, 0)]_new = 0.6697297273789788\n",
            "We are on 17 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 6 step\n",
            "Delta Q = 1.0\n",
            "Q_table[16,0]_old = 0.7712320754503901\n",
            "Q_table[(16, 0)]_new = 0.7941088679053511\n",
            "We are on 16 state\n",
            "And now we are on 15 state\n",
            "We get 1.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 0 step\n",
            "Delta Q = 0.9538772561112218\n",
            "Q_table[0,0]_old = 0.5178301893649684\n",
            "Q_table[(0, 0)]_new = 0.5199244265396933\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 1 step\n",
            "Delta Q = 0.9538772561112218\n",
            "Q_table[3,3]_old = 0.5296793581062308\n",
            "Q_table[(3, 3)]_new = 0.5305886784068294\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 2 step\n",
            "Delta Q = 0.9556485427897243\n",
            "Q_table[3,1]_old = 0.5442147081941593\n",
            "Q_table[(3, 1)]_new = 0.5454417801644676\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 3 step\n",
            "Delta Q = 0.9580569990345321\n",
            "Q_table[8,1]_old = 0.5621064928254977\n",
            "Q_table[(8, 1)]_new = 0.5639528425774801\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 4 step\n",
            "Delta Q = 0.9540966557506926\n",
            "Q_table[13,2]_old = 0.48774905470867386\n",
            "Q_table[(13, 2)]_new = 0.4930708049884991\n",
            "We are on 13 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 5 step\n",
            "Delta Q = 0.9541198000245629\n",
            "Q_table[14,3]_old = 0.5151035950980025\n",
            "Q_table[(14, 3)]_new = 0.5177130356127652\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 6 step\n",
            "Delta Q = 0.9541198000245629\n",
            "Q_table[9,2]_old = 0.5296204622484132\n",
            "Q_table[(9, 2)]_new = 0.5307782160481348\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 7 step\n",
            "Delta Q = 0.9540966557506926\n",
            "Q_table[9,1]_old = 0.5312049424632543\n",
            "Q_table[(9, 1)]_new = 0.5321811039676215\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 8 step\n",
            "Delta Q = 0.9541198000245629\n",
            "Q_table[14,3]_old = 0.5177130356127652\n",
            "Q_table[(14, 3)]_new = 0.5200615320760515\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 9 step\n",
            "Delta Q = 0.9540966557506926\n",
            "Q_table[9,1]_old = 0.5321811039676215\n",
            "Q_table[(9, 1)]_new = 0.5330596493215519\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 10 step\n",
            "Delta Q = 0.9580569990345321\n",
            "Q_table[14,0]_old = 0.5464308661686119\n",
            "Q_table[(14, 0)]_new = 0.5498447785862829\n",
            "We are on 14 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 11 step\n",
            "Delta Q = 0.9544346330800421\n",
            "Q_table[13,2]_old = 0.4930708049884991\n",
            "Q_table[(13, 2)]_new = 0.4981983575696912\n",
            "We are on 13 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 12 step\n",
            "Delta Q = 0.9544346330800421\n",
            "Q_table[14,2]_old = 0.5194677957274048\n",
            "Q_table[(14, 2)]_new = 0.5219556492347063\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 13 step\n",
            "Delta Q = 0.9541198000245629\n",
            "Q_table[14,3]_old = 0.5200615320760515\n",
            "Q_table[(14, 3)]_new = 0.5221751788930092\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 14 step\n",
            "Delta Q = 0.9526776674107529\n",
            "Q_table[9,3]_old = 0.5172385000021194\n",
            "Q_table[(9, 3)]_new = 0.5181923174126603\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 15 step\n",
            "Delta Q = 0.9541198000245629\n",
            "Q_table[4,1]_old = 0.5320976506136648\n",
            "Q_table[(4, 1)]_new = 0.5330076855768612\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 16 step\n",
            "Delta Q = 0.9541198000245629\n",
            "Q_table[9,2]_old = 0.5307782160481348\n",
            "Q_table[(9, 2)]_new = 0.5318201944678842\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 17 step\n",
            "Delta Q = 0.9544346330800421\n",
            "Q_table[9,1]_old = 0.5330596493215519\n",
            "Q_table[(9, 1)]_new = 0.5341883174694387\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 18 step\n",
            "Delta Q = 0.9541198000245629\n",
            "Q_table[14,3]_old = 0.5221751788930092\n",
            "Q_table[(14, 3)]_new = 0.5240774610282712\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 19 step\n",
            "Delta Q = 0.9558313314151705\n",
            "Q_table[9,0]_old = 0.5466646467127564\n",
            "Q_table[(9, 0)]_new = 0.5478295134566513\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 20 step\n",
            "Delta Q = 0.9542351218322085\n",
            "Q_table[8,2]_old = 0.5240006065518329\n",
            "Q_table[(8, 2)]_new = 0.5258356677288581\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 21 step\n",
            "Delta Q = 0.9527677608721092\n",
            "Q_table[9,3]_old = 0.5181923174126603\n",
            "Q_table[(9, 3)]_new = 0.5191408465435035\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 22 step\n",
            "Delta Q = 0.9527677608721092\n",
            "Q_table[4,2]_old = 0.519941521294166\n",
            "Q_table[(4, 2)]_new = 0.5207151300368587\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 23 step\n",
            "Delta Q = 0.9527677608721092\n",
            "Q_table[4,3]_old = 0.5200886156031042\n",
            "Q_table[(4, 3)]_new = 0.520847514914903\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 24 step\n",
            "Delta Q = 0.9539987362362823\n",
            "Q_table[4,0]_old = 0.5307378177114475\n",
            "Q_table[(4, 0)]_new = 0.531662772176585\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 25 step\n",
            "Delta Q = 0.9539987362362823\n",
            "Q_table[3,3]_old = 0.5305886784068294\n",
            "Q_table[(3, 3)]_new = 0.5315285468024288\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 26 step\n",
            "Delta Q = 0.9497646422183003\n",
            "Q_table[3,0]_old = 0.48197599595298496\n",
            "Q_table[(3, 0)]_new = 0.4835430385759867\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 27 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 0 step\n",
            "Delta Q = 0.9539987362362823\n",
            "Q_table[0,0]_old = 0.5199244265396933\n",
            "Q_table[(0, 0)]_new = 0.5219307201220063\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 1 step\n",
            "Delta Q = 0.9558313314151705\n",
            "Q_table[3,1]_old = 0.5454417801644676\n",
            "Q_table[(3, 1)]_new = 0.5467289335631914\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 2 step\n",
            "Delta Q = 0.9580569990345321\n",
            "Q_table[8,1]_old = 0.5639528425774801\n",
            "Q_table[(8, 1)]_new = 0.5656145573542642\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 3 step\n",
            "Delta Q = 0.9612263653281856\n",
            "Q_table[13,1]_old = 0.5864343336821425\n",
            "Q_table[(13, 1)]_new = 0.5890172656421138\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 4 step\n",
            "Delta Q = 0.966303243010519\n",
            "Q_table[18,0]_old = 0.6184481346281367\n",
            "Q_table[(18, 0)]_new = 0.622906564175842\n",
            "We are on 18 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 5 step\n",
            "Delta Q = 0.9556451274619968\n",
            "Q_table[17,3]_old = 0.48168379601316896\n",
            "Q_table[(17, 3)]_new = 0.48916054387384883\n",
            "We are on 17 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 6 step\n",
            "Delta Q = 0.966303243010519\n",
            "Q_table[12,1]_old = 0.5620719945656237\n",
            "Q_table[(12, 1)]_new = 0.5721680381195803\n",
            "We are on 12 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 7 step\n",
            "Delta Q = 0.9786167779226298\n",
            "Q_table[17,0]_old = 0.6697297273789788\n",
            "Q_table[(17, 0)]_new = 0.6813735325637108\n",
            "We are on 17 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[16,3]_old = 0.0\n",
            "Q_table[(16, 3)]_new = 0.0\n",
            "We are on 16 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 0 step\n",
            "Delta Q = 0.9527677608721092\n",
            "Q_table[0,2]_old = 0.5074911659201466\n",
            "Q_table[(0, 2)]_new = 0.5095098102002412\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 1 step\n",
            "Delta Q = 0.954126164422756\n",
            "Q_table[4,0]_old = 0.531662772176585\n",
            "Q_table[(4, 0)]_new = 0.5326226593816824\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 2 step\n",
            "Delta Q = 0.9527677608721092\n",
            "Q_table[3,2]_old = 0.515876194158398\n",
            "Q_table[(3, 2)]_new = 0.5170563356146675\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 3 step\n",
            "Delta Q = 0.9527677608721092\n",
            "Q_table[4,2]_old = 0.5207151300368587\n",
            "Q_table[(4, 2)]_new = 0.521411377905282\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 4 step\n",
            "Delta Q = 0.9542351218322085\n",
            "Q_table[4,1]_old = 0.5330076855768612\n",
            "Q_table[(4, 1)]_new = 0.5339420388513836\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 5 step\n",
            "Delta Q = 0.9542351218322085\n",
            "Q_table[9,2]_old = 0.5318201944678842\n",
            "Q_table[(9, 2)]_new = 0.5328732968533043\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 6 step\n",
            "Delta Q = 0.9542351218322085\n",
            "Q_table[9,2]_old = 0.5328732968533043\n",
            "Q_table[(9, 2)]_new = 0.5338210890001824\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 7 step\n",
            "Delta Q = 0.9559958411780722\n",
            "Q_table[9,0]_old = 0.5478295134566513\n",
            "Q_table[(9, 0)]_new = 0.5490424032890584\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 8 step\n",
            "Delta Q = 0.9543551979256168\n",
            "Q_table[8,2]_old = 0.5258356677288581\n",
            "Q_table[(8, 2)]_new = 0.5276072988815892\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 9 step\n",
            "Delta Q = 0.9543551979256168\n",
            "Q_table[9,2]_old = 0.5338210890001824\n",
            "Q_table[(9, 2)]_new = 0.534794178025781\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 10 step\n",
            "Delta Q = 0.9544346330800421\n",
            "Q_table[9,1]_old = 0.5341883174694387\n",
            "Q_table[(9, 1)]_new = 0.5352041188025369\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 11 step\n",
            "Delta Q = 0.9544346330800421\n",
            "Q_table[14,2]_old = 0.5219556492347063\n",
            "Q_table[(14, 2)]_new = 0.5241947173912777\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[14,1]_old = 0.0\n",
            "Q_table[(14, 1)]_new = 0.0\n",
            "We are on 14 state\n",
            "And now we are on 19 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 0 step\n",
            "Delta Q = 0.954126164422756\n",
            "Q_table[0,0]_old = 0.5219307201220063\n",
            "Q_table[(0, 0)]_new = 0.5238638125325615\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 1 step\n",
            "Delta Q = 0.952860261846287\n",
            "Q_table[3,2]_old = 0.5170563356146675\n",
            "Q_table[(3, 2)]_new = 0.5182109638994877\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 2 step\n",
            "Delta Q = 0.9543551979256168\n",
            "Q_table[4,1]_old = 0.5339420388513836\n",
            "Q_table[(4, 1)]_new = 0.534903032891862\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 3 step\n",
            "Delta Q = 0.9543551979256168\n",
            "Q_table[9,2]_old = 0.534794178025781\n",
            "Q_table[(9, 2)]_new = 0.5356699581488197\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 4 step\n",
            "Delta Q = 0.9559958411780722\n",
            "Q_table[9,0]_old = 0.5490424032890584\n",
            "Q_table[(9, 0)]_new = 0.5501340041382248\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 5 step\n",
            "Delta Q = 0.9583127092985693\n",
            "Q_table[8,1]_old = 0.5656145573542642\n",
            "Q_table[(8, 1)]_new = 0.5673658109174071\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 6 step\n",
            "Delta Q = 0.9561692152808233\n",
            "Q_table[13,3]_old = 0.5272528678584443\n",
            "Q_table[(13, 3)]_new = 0.5306967963534232\n",
            "We are on 13 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 0 step\n",
            "Delta Q = 0.954126164422756\n",
            "Q_table[0,0]_old = 0.5238638125325615\n",
            "Q_table[(0, 0)]_new = 0.5256035957020614\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 1 step\n",
            "Delta Q = 0.9529554002562943\n",
            "Q_table[3,2]_old = 0.5182109638994877\n",
            "Q_table[(3, 2)]_new = 0.5193452677658333\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 2 step\n",
            "Delta Q = 0.9544632664096843\n",
            "Q_table[4,1]_old = 0.534903032891862\n",
            "Q_table[(4, 1)]_new = 0.5358759960123601\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 3 step\n",
            "Delta Q = 0.9544346330800421\n",
            "Q_table[9,1]_old = 0.5352041188025369\n",
            "Q_table[(9, 1)]_new = 0.5361183400023253\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 4 step\n",
            "Delta Q = 0.9583127092985693\n",
            "Q_table[14,0]_old = 0.5498447785862829\n",
            "Q_table[(14, 0)]_new = 0.5531730100262239\n",
            "We are on 14 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 5 step\n",
            "Delta Q = 0.9616677498534084\n",
            "Q_table[13,1]_old = 0.5890172656421138\n",
            "Q_table[(13, 1)]_new = 0.5917832889313108\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[18,2]_old = 0.0\n",
            "Q_table[(18, 2)]_new = 0.0\n",
            "We are on 18 state\n",
            "And now we are on 19 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 0 step\n",
            "Delta Q = 0.9544632664096843\n",
            "Q_table[0,1]_old = 0.5203760480013778\n",
            "Q_table[(0, 1)]_new = 0.5228017096109243\n",
            "We are on 0 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 1 step\n",
            "Delta Q = 0.9561692152808233\n",
            "Q_table[9,0]_old = 0.5501340041382248\n",
            "Q_table[(9, 0)]_new = 0.5512898190052256\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 2 step\n",
            "Delta Q = 0.9545776920815173\n",
            "Q_table[8,2]_old = 0.5276072988815892\n",
            "Q_table[(8, 2)]_new = 0.5294242610749477\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 3 step\n",
            "Delta Q = 0.9561692152808233\n",
            "Q_table[9,0]_old = 0.5512898190052256\n",
            "Q_table[(9, 0)]_new = 0.5523300523855263\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 4 step\n",
            "Delta Q = 0.9546806751861672\n",
            "Q_table[8,2]_old = 0.5294242610749477\n",
            "Q_table[(8, 2)]_new = 0.53116251015362\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 5 step\n",
            "Delta Q = 0.9530517236052237\n",
            "Q_table[9,3]_old = 0.5191408465435035\n",
            "Q_table[(9, 3)]_new = 0.5202784854943768\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 6 step\n",
            "Delta Q = 0.9546806751861672\n",
            "Q_table[4,1]_old = 0.5358759960123601\n",
            "Q_table[(4, 1)]_new = 0.5369690715972912\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 7 step\n",
            "Delta Q = 0.9547641279925962\n",
            "Q_table[9,1]_old = 0.5361183400023253\n",
            "Q_table[(9, 1)]_new = 0.5372706339946889\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 8 step\n",
            "Delta Q = 0.9546806751861672\n",
            "Q_table[14,3]_old = 0.5240774610282712\n",
            "Q_table[(14, 3)]_new = 0.5263503901116112\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 9 step\n",
            "Delta Q = 0.9531599380881318\n",
            "Q_table[9,3]_old = 0.5202784854943768\n",
            "Q_table[(9, 3)]_new = 0.521410575033071\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 10 step\n",
            "Delta Q = 0.954126164422756\n",
            "Q_table[4,0]_old = 0.5326226593816824\n",
            "Q_table[(4, 0)]_new = 0.5334865578662701\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 11 step\n",
            "Delta Q = 0.954126164422756\n",
            "Q_table[3,3]_old = 0.5315285468024288\n",
            "Q_table[(3, 3)]_new = 0.5325018565449419\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 12 step\n",
            "Delta Q = 0.9561692152808233\n",
            "Q_table[3,1]_old = 0.5467289335631914\n",
            "Q_table[(3, 1)]_new = 0.5482252554876956\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 13 step\n",
            "Delta Q = 0.9542743002932819\n",
            "Q_table[8,3]_old = 0.5157681782527352\n",
            "Q_table[(8, 3)]_new = 0.5184656607207436\n",
            "We are on 8 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 14 step\n",
            "Delta Q = 0.9531599380881318\n",
            "Q_table[3,2]_old = 0.5193452677658333\n",
            "Q_table[(3, 2)]_new = 0.5205706790773819\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 15 step\n",
            "Delta Q = 0.9531599380881318\n",
            "Q_table[4,2]_old = 0.521411377905282\n",
            "Q_table[(4, 2)]_new = 0.5224301782028856\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 16 step\n",
            "Delta Q = 0.9531599380881318\n",
            "Q_table[4,2]_old = 0.5224301782028856\n",
            "Q_table[(4, 2)]_new = 0.5233470984707289\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 17 step\n",
            "Delta Q = 0.9531599380881318\n",
            "Q_table[4,2]_old = 0.5233470984707289\n",
            "Q_table[(4, 2)]_new = 0.5241723267117878\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 18 step\n",
            "Delta Q = 0.9531599380881318\n",
            "Q_table[4,3]_old = 0.520847514914903\n",
            "Q_table[(4, 3)]_new = 0.5219227015115445\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 19 step\n",
            "Delta Q = 0.9546806751861672\n",
            "Q_table[4,1]_old = 0.5369690715972912\n",
            "Q_table[(4, 1)]_new = 0.5379528396237292\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 20 step\n",
            "Delta Q = 0.9547641279925962\n",
            "Q_table[9,1]_old = 0.5372706339946889\n",
            "Q_table[(9, 1)]_new = 0.5383076985878161\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 21 step\n",
            "Delta Q = 0.9547641279925962\n",
            "Q_table[14,2]_old = 0.5241947173912777\n",
            "Q_table[(14, 2)]_new = 0.5265393736447461\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 22 step\n",
            "Delta Q = 0.9585865456041998\n",
            "Q_table[14,0]_old = 0.5531730100262239\n",
            "Q_table[(14, 0)]_new = 0.5564422546278013\n",
            "We are on 14 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 23 step\n",
            "Delta Q = 0.9616677498534084\n",
            "Q_table[13,1]_old = 0.5917832889313108\n",
            "Q_table[(13, 1)]_new = 0.5942727098915882\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 24 step\n",
            "Delta Q = 0.9674559797238074\n",
            "Q_table[18,0]_old = 0.622906564175842\n",
            "Q_table[(18, 0)]_new = 0.6280718874820652\n",
            "We are on 18 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 25 step\n",
            "Delta Q = 0.9566446357738385\n",
            "Q_table[17,3]_old = 0.48916054387384883\n",
            "Q_table[(17, 3)]_new = 0.4968891252603024\n",
            "We are on 17 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 26 step\n",
            "Delta Q = 0.9674559797238074\n",
            "Q_table[12,1]_old = 0.5721680381195803\n",
            "Q_table[(12, 1)]_new = 0.5824072140314296\n",
            "We are on 12 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 27 step\n",
            "Delta Q = 0.9576583141891115\n",
            "Q_table[17,3]_old = 0.4968891252603024\n",
            "Q_table[(17, 3)]_new = 0.5048585269233836\n",
            "We are on 17 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 28 step\n",
            "Delta Q = 0.9\n",
            "Q_table[12,0]_old = 0.0\n",
            "Q_table[(12, 0)]_new = 0.0\n",
            "We are on 12 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 0 step\n",
            "Delta Q = 0.9532573311227492\n",
            "Q_table[0,3]_old = 0.5030416748780141\n",
            "Q_table[(0, 3)]_new = 0.5059948385129619\n",
            "We are on 0 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 1 step\n",
            "Delta Q = 0.9546806751861672\n",
            "Q_table[4,1]_old = 0.5379528396237292\n",
            "Q_table[(4, 1)]_new = 0.5388382308475234\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 2 step\n",
            "Delta Q = 0.9550877832081524\n",
            "Q_table[9,1]_old = 0.5383076985878161\n",
            "Q_table[(9, 1)]_new = 0.5395647119371869\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 3 step\n",
            "Delta Q = 0.9550877832081524\n",
            "Q_table[14,2]_old = 0.5265393736447461\n",
            "Q_table[(14, 2)]_new = 0.5289732194884238\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 4 step\n",
            "Delta Q = 0.9546806751861672\n",
            "Q_table[14,3]_old = 0.5263503901116112\n",
            "Q_table[(14, 3)]_new = 0.5283960262866172\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 5 step\n",
            "Delta Q = 0.9561692152808233\n",
            "Q_table[9,0]_old = 0.5523300523855263\n",
            "Q_table[(9, 0)]_new = 0.5532662624277971\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 6 step\n",
            "Delta Q = 0.9542743002932819\n",
            "Q_table[8,3]_old = 0.5184656607207436\n",
            "Q_table[(8, 3)]_new = 0.5208933949419512\n",
            "We are on 8 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 7 step\n",
            "Delta Q = 0.9533449848539048\n",
            "Q_table[3,2]_old = 0.5205706790773819\n",
            "Q_table[(3, 2)]_new = 0.5218585960235484\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 8 step\n",
            "Delta Q = 0.954773359980352\n",
            "Q_table[4,1]_old = 0.5388382308475234\n",
            "Q_table[(4, 1)]_new = 0.5397277677431229\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 9 step\n",
            "Delta Q = 0.9550877832081524\n",
            "Q_table[9,1]_old = 0.5395647119371869\n",
            "Q_table[(9, 1)]_new = 0.5406960239516205\n",
            "We are on 9 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 10 step\n",
            "Delta Q = 0.9550877832081524\n",
            "Q_table[14,2]_old = 0.5289732194884238\n",
            "Q_table[(14, 2)]_new = 0.5311636807477338\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 11 step\n",
            "Delta Q = 0.954773359980352\n",
            "Q_table[14,3]_old = 0.5283960262866172\n",
            "Q_table[(14, 3)]_new = 0.5303297836383074\n",
            "We are on 14 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 12 step\n",
            "Delta Q = 0.954773359980352\n",
            "Q_table[9,2]_old = 0.5356699581488197\n",
            "Q_table[(9, 2)]_new = 0.5368763223142896\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 13 step\n",
            "Delta Q = 0.9561692152808233\n",
            "Q_table[9,0]_old = 0.5532662624277971\n",
            "Q_table[(9, 0)]_new = 0.5541088514658408\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 14 step\n",
            "Delta Q = 0.9588329982792673\n",
            "Q_table[8,1]_old = 0.5673658109174071\n",
            "Q_table[(8, 1)]_new = 0.5694622281049336\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 15 step\n",
            "Delta Q = 0.9621791168607244\n",
            "Q_table[13,1]_old = 0.5942727098915882\n",
            "Q_table[(13, 1)]_new = 0.5970245557631538\n",
            "We are on 13 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 16 step\n",
            "Delta Q = 0.9621791168607244\n",
            "Q_table[18,1]_old = 0.5510875920920374\n",
            "Q_table[(18, 1)]_new = 0.5581579497435581\n",
            "We are on 18 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 17 step\n",
            "Delta Q = 0.9591054310205522\n",
            "Q_table[18,3]_old = 0.4554616068093921\n",
            "Q_table[(18, 3)]_new = 0.46902087714900514\n",
            "We are on 18 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 18 step\n",
            "Delta Q = 0.9576583141891115\n",
            "Q_table[13,0]_old = 0.5231820774548437\n",
            "Q_table[(13, 0)]_new = 0.5285221838984708\n",
            "We are on 13 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 19 step\n",
            "Delta Q = 0.9591054310205522\n",
            "Q_table[12,2]_old = 0.4573401631981149\n",
            "Q_table[(12, 2)]_new = 0.4707115778988556\n",
            "We are on 12 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 20 step\n",
            "Delta Q = 0.9563767605823884\n",
            "Q_table[13,3]_old = 0.5306967963534232\n",
            "Q_table[(13, 3)]_new = 0.5340038773004693\n",
            "We are on 13 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 21 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 0 step\n",
            "Delta Q = 0.9542743002932819\n",
            "Q_table[0,0]_old = 0.5256035957020614\n",
            "Q_table[(0, 0)]_new = 0.5273175364251371\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 1 step\n",
            "Delta Q = 0.9534330490065692\n",
            "Q_table[3,2]_old = 0.5218585960235484\n",
            "Q_table[(3, 2)]_new = 0.5231057854277628\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 2 step\n",
            "Delta Q = 0.9534330490065692\n",
            "Q_table[4,2]_old = 0.5241723267117878\n",
            "Q_table[(4, 2)]_new = 0.5251881430471782\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 3 step\n",
            "Delta Q = 0.9534330490065692\n",
            "Q_table[4,2]_old = 0.5251881430471782\n",
            "Q_table[(4, 2)]_new = 0.5261023777490296\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 4 step\n",
            "Delta Q = 0.9534330490065692\n",
            "Q_table[4,3]_old = 0.5219227015115445\n",
            "Q_table[(4, 3)]_new = 0.5231634803669593\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 5 step\n",
            "Delta Q = 0.9542743002932819\n",
            "Q_table[4,0]_old = 0.5334865578662701\n",
            "Q_table[(4, 0)]_new = 0.534412202372925\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 6 step\n",
            "Delta Q = 0.9534330490065692\n",
            "Q_table[3,2]_old = 0.5231057854277628\n",
            "Q_table[(3, 2)]_new = 0.5242282558915556\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 7 step\n",
            "Delta Q = 0.9534330490065692\n",
            "Q_table[4,2]_old = 0.5261023777490296\n",
            "Q_table[(4, 2)]_new = 0.5269251889806958\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 8 step\n",
            "Delta Q = 0.9542743002932819\n",
            "Q_table[4,0]_old = 0.534412202372925\n",
            "Q_table[(4, 0)]_new = 0.5352452824289143\n",
            "We are on 4 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 9 step\n",
            "Delta Q = 0.9534330490065692\n",
            "Q_table[3,2]_old = 0.5242282558915556\n",
            "Q_table[(3, 2)]_new = 0.5252384793089693\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 10 step\n",
            "Delta Q = 0.9548567762951182\n",
            "Q_table[4,1]_old = 0.5397277677431229\n",
            "Q_table[(4, 1)]_new = 0.5406117672639289\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 11 step\n",
            "Delta Q = 0.9548567762951182\n",
            "Q_table[9,2]_old = 0.5368763223142896\n",
            "Q_table[(9, 2)]_new = 0.5380454663779789\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 12 step\n",
            "Delta Q = 0.9563767605823884\n",
            "Q_table[9,0]_old = 0.5541088514658408\n",
            "Q_table[(9, 0)]_new = 0.5550747269016452\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 13 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 0 step\n",
            "Delta Q = 0.9549523979632629\n",
            "Q_table[0,1]_old = 0.5228017096109243\n",
            "Q_table[(0, 1)]_new = 0.5254739366130947\n",
            "We are on 0 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 1 step\n",
            "Delta Q = 0.9563767605823884\n",
            "Q_table[9,0]_old = 0.5550747269016452\n",
            "Q_table[(9, 0)]_new = 0.5559440147938691\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 2 step\n",
            "Delta Q = 0.9591054310205522\n",
            "Q_table[8,1]_old = 0.5694622281049336\n",
            "Q_table[(8, 1)]_new = 0.5716214363149925\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 3 step\n",
            "Delta Q = 0.9576583141891115\n",
            "Q_table[13,0]_old = 0.5285221838984708\n",
            "Q_table[(13, 0)]_new = 0.5333282796977353\n",
            "We are on 13 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 4 step\n",
            "Delta Q = 0.9674559797238074\n",
            "Q_table[12,1]_old = 0.5824072140314296\n",
            "Q_table[(12, 1)]_new = 0.591622472352094\n",
            "We are on 12 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 5 step\n",
            "Delta Q = 0.9786167779226298\n",
            "Q_table[17,0]_old = 0.6813735325637108\n",
            "Q_table[(17, 0)]_new = 0.6918529572299695\n",
            "We are on 17 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 6 step\n",
            "Delta Q = 0.9786167779226298\n",
            "Q_table[16,1]_old = 0.4145693070579799\n",
            "Q_table[(16, 1)]_new = 0.4517291542748117\n",
            "We are on 16 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 7 step\n",
            "Delta Q = 0.9786167779226298\n",
            "Q_table[16,1]_old = 0.4517291542748117\n",
            "Q_table[(16, 1)]_new = 0.48517301676996033\n",
            "We are on 16 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[16,3]_old = 0.0\n",
            "Q_table[(16, 3)]_new = 0.0\n",
            "We are on 16 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j45ghrMbmYMW",
        "outputId": "c2c076b4-4604-4161-b014-c988ebb9b274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg) (67.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio"
      ],
      "metadata": {
        "id": "NKpgHiejml6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_video(env, q_table, out_directory, fps=1):\n",
        "  images = []\n",
        "  done = False\n",
        "  state = env.reset(seed=random.randint(0,500))\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action = np.argmax(q_table[state][:])\n",
        "    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ],
      "metadata": {
        "id": "Vi8Mq4tEl4Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path=\"/content/replay.gif\"\n",
        "video_fps=1\n",
        "record_video(env, q_table, video_path, video_fps)\n",
        "\n",
        "from IPython.display import Image\n",
        "Image('./replay.gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "turRjFNxmFal",
        "outputId": "75a30db8-d763-4566-8de6-e8c470d8cb89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/gif": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}